<!DOCTYPE html>
<html lang="zh-cn" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="Further Experiments">
<title>Deep Learning attempt for RNA inverse design?</title>

<link rel='canonical' href='https://mosfish.github.io/p/deep-learning-attempt-for-rna-inverse-design/'>

<link rel="stylesheet" href="/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css"><meta property='og:title' content="Deep Learning attempt for RNA inverse design?">
<meta property='og:description' content="Further Experiments">
<meta property='og:url' content='https://mosfish.github.io/p/deep-learning-attempt-for-rna-inverse-design/'>
<meta property='og:site_name' content='Mosfish&#39;s Blog'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2025-09-30T19:45:11&#43;08:00'/><meta property='article:modified_time' content='2025-09-30T19:45:11&#43;08:00'/>
<meta name="twitter:title" content="Deep Learning attempt for RNA inverse design?">
<meta name="twitter:description" content="Further Experiments">
    <link rel="shortcut icon" href="/favicon.ico" />

    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "dark");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="切换菜单">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/head_hu_c416b63add1b23cc.webp" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Mosfish&#39;s Blog</a></h1>
            <h2 class="site-description">I still feel like it has something to do with those fries on the pier.</h2>
        </div>
    </header><ol class="menu-social">
            
                <li>
                    <a 
                        href='mailto:wenxy59@mail2.sysu.edu.cn'
                        target="_blank"
                        title="Email"
                        rel="me"
                    >
                        
                        
                            <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-mail"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 7a2 2 0 0 1 2 -2h14a2 2 0 0 1 2 2v10a2 2 0 0 1 -2 2h-14a2 2 0 0 1 -2 -2v-10z" /><path d="M3 7l9 6l9 -6" /></svg>
                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://github.com/Mosfish'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://mosfish.github.io/'
                        target="_blank"
                        title="Homepage"
                        rel="me"
                    >
                        
                        
                            <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-building-bank"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 21l18 0" /><path d="M3 10l18 0" /><path d="M5 6l7 -3l7 3" /><path d="M4 10l0 11" /><path d="M20 10l0 11" /><path d="M8 14l0 3" /><path d="M12 14l0 3" /><path d="M16 14l0 3" /></svg>
                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://www.linkedin.com/in/xiangyuwen-mosfish/'
                        target="_blank"
                        title="Linkedin"
                        rel="me"
                    >
                        
                        
                            <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-brand-linkedin"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M8 11v5" /><path d="M8 8v.01" /><path d="M12 16v-5" /><path d="M16 16v-3a2 2 0 1 0 -4 0" /><path d="M3 7a4 4 0 0 1 4 -4h10a4 4 0 0 1 4 4v10a4 4 0 0 1 -4 4h-10a4 4 0 0 1 -4 -4z" /></svg>
                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>主页 | Home</span>
            </a>
        </li>
        
        
        <li >
            <a href='https://wenxy59.github.io/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>关于 | About</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>归档 | Archives</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>搜索 | Search</span>
            </a>
        </li>
        
        
        <li >
            <a href='/%E6%8A%80%E6%9C%AF%E9%93%BE%E6%8E%A5friends-links/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5" />
  <path d="M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5" />
</svg>



                
                <span>技术链接&amp;friends | Links</span>
            </a>
        </li>
        
        <li class="menu-bottom-section">
            <ol class="menu">

                
                    <li id="dark-mode-toggle">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <span>暗色模式</span>
                    </li>
                
            </ol>
        </li>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">目录</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#graph-mamba的模块添加">Graph-Mamba的模块添加</a>
      <ol>
        <li><a href="#文献graph-mamba-towards-long-range-graph-sequence-modeling-with--selective-state-spaces">文献：Graph-Mamba: Towards Long-Range Graph Sequence Modeling with  Selective State Spaces</a></li>
        <li><a href="#输入输出匹配与debug修改">输入输出匹配与debug修改</a></li>
        <li><a href="#实验测试">实验测试</a></li>
      </ol>
    </li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/ai4s/" style="background-color: #800020; color: #fff;">
                AI4S
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/p/deep-learning-attempt-for-rna-inverse-design/">Deep Learning attempt for RNA inverse design?</a>
        </h2>
    
        
        <h3 class="article-subtitle">
            Further Experiments
        </h3>
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Sep 30, 2025</time>
            </div>
        

        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <h1 id="正式修改与实验">正式修改与实验
</h1><p>在测试集均匀划分后，我首先对gRNAde模型进行了重新训练与测试，此时我发现结果不稳定，但是问题不大。简单画图如下：</p>
<div align=center><img src="grnanew.png" width=600/></div>
<center><font size=2>在测试集的结果</font></center>
<h2 id="graph-mamba的模块添加">Graph-Mamba的模块添加
</h2><h3 id="文献graph-mamba-towards-long-range-graph-sequence-modeling-with--selective-state-spaces">文献：Graph-Mamba: Towards Long-Range Graph Sequence Modeling with  Selective State Spaces
</h3><p>文献的source code在：https://github.com/bowang-lab/Graph-Mamba.</p>
<p>本文提出了基于mamba的gnn。</p>
<h3 id="输入输出匹配与debug修改">输入输出匹配与debug修改
</h3><p>把grnade的GVP-GNN层替换为graphmamba论文提到的gps_layer，同时由于本层使用的是其加载的gatedgnn本地模型，在向量标量与维度问题上面容易有不匹配的问题，所以需要进行修改。</p>
<p>首先是main.py，我也忘了改动哪里了，先放上来：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span><span class="lnt">165
</span><span class="lnt">166
</span><span class="lnt">167
</span><span class="lnt">168
</span><span class="lnt">169
</span><span class="lnt">170
</span><span class="lnt">171
</span><span class="lnt">172
</span><span class="lnt">173
</span><span class="lnt">174
</span><span class="lnt">175
</span><span class="lnt">176
</span><span class="lnt">177
</span><span class="lnt">178
</span><span class="lnt">179
</span><span class="lnt">180
</span><span class="lnt">181
</span><span class="lnt">182
</span><span class="lnt">183
</span><span class="lnt">184
</span><span class="lnt">185
</span><span class="lnt">186
</span><span class="lnt">187
</span><span class="lnt">188
</span><span class="lnt">189
</span><span class="lnt">190
</span><span class="lnt">191
</span><span class="lnt">192
</span><span class="lnt">193
</span><span class="lnt">194
</span><span class="lnt">195
</span><span class="lnt">196
</span><span class="lnt">197
</span><span class="lnt">198
</span><span class="lnt">199
</span><span class="lnt">200
</span><span class="lnt">201
</span><span class="lnt">202
</span><span class="lnt">203
</span><span class="lnt">204
</span><span class="lnt">205
</span><span class="lnt">206
</span><span class="lnt">207
</span><span class="lnt">208
</span><span class="lnt">209
</span><span class="lnt">210
</span><span class="lnt">211
</span><span class="lnt">212
</span><span class="lnt">213
</span><span class="lnt">214
</span><span class="lnt">215
</span><span class="lnt">216
</span><span class="lnt">217
</span><span class="lnt">218
</span><span class="lnt">219
</span><span class="lnt">220
</span><span class="lnt">221
</span><span class="lnt">222
</span><span class="lnt">223
</span><span class="lnt">224
</span><span class="lnt">225
</span><span class="lnt">226
</span><span class="lnt">227
</span><span class="lnt">228
</span><span class="lnt">229
</span><span class="lnt">230
</span><span class="lnt">231
</span><span class="lnt">232
</span><span class="lnt">233
</span><span class="lnt">234
</span><span class="lnt">235
</span><span class="lnt">236
</span><span class="lnt">237
</span><span class="lnt">238
</span><span class="lnt">239
</span><span class="lnt">240
</span><span class="lnt">241
</span><span class="lnt">242
</span><span class="lnt">243
</span><span class="lnt">244
</span><span class="lnt">245
</span><span class="lnt">246
</span><span class="lnt">247
</span><span class="lnt">248
</span><span class="lnt">249
</span><span class="lnt">250
</span><span class="lnt">251
</span><span class="lnt">252
</span><span class="lnt">253
</span><span class="lnt">254
</span><span class="lnt">255
</span><span class="lnt">256
</span><span class="lnt">257
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">dotenv</span>
</span></span><span class="line"><span class="cl"><span class="n">dotenv</span><span class="o">.</span><span class="n">load_dotenv</span><span class="p">(</span><span class="s2">&#34;.env&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">warnings</span>
</span></span><span class="line"><span class="cl"><span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&#34;ignore&#34;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&#34;ignore&#34;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">RuntimeWarning</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&#34;ignore&#34;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">random</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">argparse</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">wandb</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch_geometric</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch_geometric.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">src.trainer</span> <span class="kn">import</span> <span class="n">train</span><span class="p">,</span> <span class="n">evaluate</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">src.data.dataset</span> <span class="kn">import</span> <span class="n">RNADesignDataset</span><span class="p">,</span> <span class="n">BatchSampler</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">src.models</span> <span class="kn">import</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">AutoregressiveMultiGNNv1</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">    <span class="n">NonAutoregressiveMultiGNNv1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">src.constants</span> <span class="kn">import</span> <span class="n">DATA_PATH</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Main function for training and evaluating gRNAde.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Set seed</span>
</span></span><span class="line"><span class="cl">    <span class="n">set_seed</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Initialise model</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">config</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">total_param</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">total_param</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">MODEL</span><span class="se">\n</span><span class="s1">    </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="se">\n</span><span class="s1">    Total parameters: </span><span class="si">{</span><span class="n">total_param</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="s2">&#34;total_param&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">total_param</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Load checkpoint</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">model_path</span> <span class="o">!=</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">model_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">evaluate</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Load test set</span>
</span></span><span class="line"><span class="cl">        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">test_list</span> <span class="o">=</span> <span class="n">get_data_splits</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">split_type</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">split</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">testset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">test_list</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&#34;test&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">testset</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Run evaluator + save designed structures</span>
</span></span><span class="line"><span class="cl">        <span class="n">results</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">model</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">config</span><span class="o">.</span><span class="n">n_samples</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">config</span><span class="o">.</span><span class="n">temperature</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">device</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">model_name</span><span class="o">=</span><span class="s2">&#34;test&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;recovery&#39;</span><span class="p">,</span> <span class="s1">&#39;perplexity&#39;</span><span class="p">,</span> <span class="s1">&#39;sc_score_eternafold&#39;</span><span class="p">,</span> <span class="s1">&#39;sc_score_ribonanzanet&#39;</span><span class="p">,</span> <span class="s1">&#39;sc_score_rhofold&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">            <span class="n">save_designs</span><span class="o">=</span><span class="kc">True</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">df</span><span class="p">,</span> <span class="n">samples_list</span><span class="p">,</span> <span class="n">recovery_list</span><span class="p">,</span> <span class="n">perplexity_list</span><span class="p">,</span> \
</span></span><span class="line"><span class="cl">        <span class="n">scscore_list</span><span class="p">,</span> <span class="n">scscore_ribonanza_list</span><span class="p">,</span> \
</span></span><span class="line"><span class="cl">        <span class="n">scscore_rmsd_list</span><span class="p">,</span> <span class="n">scscore_tm_list</span><span class="p">,</span> <span class="n">scscore_gdt_list</span><span class="p">,</span> \
</span></span><span class="line"><span class="cl">        <span class="n">rmsd_within_thresh</span><span class="p">,</span> <span class="n">tm_within_thresh</span><span class="p">,</span> <span class="n">gdt_within_thresh</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Save results</span>
</span></span><span class="line"><span class="cl">        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&#34;test_results.pt&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Update wandb summary metrics</span>
</span></span><span class="line"><span class="cl">        <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_test_recovery&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">recovery_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_test_perplexity&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">perplexity_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_test_scscore&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_test_scscore_ribonanza&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_ribonanza_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_test_scscore_rmsd&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_rmsd_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_test_scscore_tm&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_tm_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_test_scscore_gdt&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_gdt_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_test_rmsd_within_thresh&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rmsd_within_thresh</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_test_tm_within_thresh&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">tm_within_thresh</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_test_gdt_within_thresh&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">gdt_within_thresh</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;BEST test recovery: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">recovery_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                perplexity: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">perplexity_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                scscore: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                scscore_ribonanza: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_ribonanza_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                scscore_rmsd: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_rmsd_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                scscore_tm: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_tm_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                scscore_gdt: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_gdt_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                rmsd_within_thresh: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rmsd_within_thresh</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                tm_within_thresh: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">tm_within_thresh</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                gdt_within_thresh: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">gdt_within_thresh</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Get train, val, test data samples as lists</span>
</span></span><span class="line"><span class="cl">        <span class="n">train_list</span><span class="p">,</span> <span class="n">val_list</span><span class="p">,</span> <span class="n">test_list</span> <span class="o">=</span> <span class="n">get_data_splits</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">split_type</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">split</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Load datasets</span>
</span></span><span class="line"><span class="cl">        <span class="n">trainset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">train_list</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&#34;train&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">valset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">val_list</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&#34;val&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">testset</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">test_list</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&#34;test&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Prepare dataloaders</span>
</span></span><span class="line"><span class="cl">        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">trainset</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">val_loader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">valset</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">test_loader</span> <span class="o">=</span> <span class="n">get_dataloader</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">testset</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># Run trainer</span>
</span></span><span class="line"><span class="cl">        <span class="n">train</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_data_splits</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">split_type</span><span class="o">=</span><span class="s2">&#34;structsim_v2&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Returns train, val, test data splits as lists.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="c1">#data_list = list(torch.load(os.path.join(DATA_PATH, &#34;processed.pt&#34;)).values())</span>
</span></span><span class="line"><span class="cl">    <span class="n">data_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="p">,</span> <span class="s2">&#34;processed.pt&#34;</span><span class="p">),</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">index_list_by_indices</span><span class="p">(</span><span class="n">lst</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># return [lst[index] if 0 &lt;= index &lt; len(lst) else None for index in indices]</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="p">[</span><span class="n">lst</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Pre-compute using notebooks/split_{split_type}.ipynb</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_idx_list</span><span class="p">,</span> <span class="n">val_idx_list</span><span class="p">,</span> <span class="n">test_idx_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">split_type</span><span class="si">}</span><span class="s2">_split.pt&#34;</span><span class="p">))</span> 
</span></span><span class="line"><span class="cl">    <span class="n">train_list</span> <span class="o">=</span> <span class="n">index_list_by_indices</span><span class="p">(</span><span class="n">data_list</span><span class="p">,</span> <span class="n">train_idx_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">val_list</span> <span class="o">=</span> <span class="n">index_list_by_indices</span><span class="p">(</span><span class="n">data_list</span><span class="p">,</span> <span class="n">val_idx_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">test_list</span> <span class="o">=</span> <span class="n">index_list_by_indices</span><span class="p">(</span><span class="n">data_list</span><span class="p">,</span> <span class="n">test_idx_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">train_list</span><span class="p">,</span> <span class="n">val_list</span><span class="p">,</span> <span class="n">test_list</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_dataset</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">data_list</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&#34;train&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Returns a Dataset for a given split.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">RNADesignDataset</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">data_list</span> <span class="o">=</span> <span class="n">data_list</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">split</span> <span class="o">=</span> <span class="n">split</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">radius</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">radius</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">top_k</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">top_k</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">num_rbf</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_rbf</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">num_posenc</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_posenc</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">max_num_conformers</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">max_num_conformers</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">noise_scale</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">noise_scale</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_dataloader</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">config</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">dataset</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">exclude_keys</span><span class="o">=</span><span class="p">[],</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Returns a DataLoader for a given Dataset.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">    Args:
</span></span></span><span class="line"><span class="cl"><span class="s2">        dataset (RNADesignDataset): dataset object
</span></span></span><span class="line"><span class="cl"><span class="s2">        config (dict): wandb configuration dictionary
</span></span></span><span class="line"><span class="cl"><span class="s2">        shuffle (bool): whether to shuffle the dataset
</span></span></span><span class="line"><span class="cl"><span class="s2">        pin_memory (bool): whether to pin memory
</span></span></span><span class="line"><span class="cl"><span class="s2">        exclue_keys (list): list of keys to exclude during batching
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">dataset</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">num_workers</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">batch_sampler</span> <span class="o">=</span> <span class="n">BatchSampler</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">node_counts</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">node_counts</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">max_nodes_batch</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">max_nodes_batch</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">max_nodes_sample</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">max_nodes_sample</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">pin_memory</span> <span class="o">=</span> <span class="n">pin_memory</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">exclude_keys</span> <span class="o">=</span> <span class="n">exclude_keys</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Returns a Model for a given config.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">model_class</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;ARv1&#39;</span> <span class="p">:</span> <span class="n">AutoregressiveMultiGNNv1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;NARv1&#39;</span><span class="p">:</span> <span class="n">NonAutoregressiveMultiGNNv1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">}[</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model_class</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">node_in_dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">node_in_dim</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">node_h_dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">node_h_dim</span><span class="p">),</span> 
</span></span><span class="line"><span class="cl">        <span class="n">edge_in_dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">edge_in_dim</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">edge_h_dim</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">edge_h_dim</span><span class="p">),</span> 
</span></span><span class="line"><span class="cl">        <span class="n">num_layers</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">drop_rate</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">drop_rate</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">out_dim</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">out_dim</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">device_type</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Sets random seed for reproducibility.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">device_type</span> <span class="o">==</span> <span class="s1">&#39;xpu&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="kn">import</span> <span class="nn">intel_extension_for_pytorch</span> <span class="k">as</span> <span class="nn">ipex</span>
</span></span><span class="line"><span class="cl">        <span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--config&#39;</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="s1">&#39;config&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;configs/default.yaml&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--expt_name&#39;</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="s1">&#39;expt_name&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--tags&#39;</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="s1">&#39;tags&#39;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="p">[])</span>
</span></span><span class="line"><span class="cl">    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--no_wandb&#39;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s2">&#34;store_true&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">args</span><span class="p">,</span> <span class="n">unknown</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Initialise wandb</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">no_wandb</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">project</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&#34;WANDB_PROJECT&#34;</span><span class="p">),</span> 
</span></span><span class="line"><span class="cl">            <span class="n">entity</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&#34;WANDB_ENTITY&#34;</span><span class="p">),</span> 
</span></span><span class="line"><span class="cl">            <span class="n">config</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">name</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">expt_name</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;disabled&#39;</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">project</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&#34;WANDB_PROJECT&#34;</span><span class="p">),</span> 
</span></span><span class="line"><span class="cl">            <span class="n">entity</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&#34;WANDB_ENTITY&#34;</span><span class="p">),</span> 
</span></span><span class="line"><span class="cl">            <span class="n">config</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">name</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">expt_name</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">tags</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">tags</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;online&#39;</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">config</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">config</span>
</span></span><span class="line"><span class="cl">    <span class="n">config_str</span> <span class="o">=</span> <span class="s2">&#34;</span><span class="se">\n</span><span class="s2">CONFIG&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">config</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">config_str</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">    </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">val</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">config_str</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Set device (GPU/CPU/XPU)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="s1">&#39;xpu&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="kn">import</span> <span class="nn">intel_extension_for_pytorch</span> <span class="k">as</span> <span class="nn">ipex</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;[</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">]: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">device_count</span><span class="p">())]</span>
</span></span><span class="line"><span class="cl">        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&#34;xpu:</span><span class="si">{}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">xpu</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&#34;cuda:</span><span class="si">{}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&#34;cpu&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Run main function</span>
</span></span><span class="line"><span class="cl">    <span class="n">main</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>之后，需要把Graph-Mamba的文件拷贝到当前位置：
<img src="assets/image-20250930191543953.png" 
alt="image-20250930191543953" 
style="display: block; margin: 0 auto; zoom: 67%;" /></p>
<p>里面的adapters.py是来处理数据格式不匹配的问题。</p>
<ul>
<li>
<ol>
<li>创建了 <code>GVP_to_GPS_Adapter</code> 类，负责将 gRNAde 的 GVP 数据格式 <code>(标量, 向量)</code> 元组，转换为 <code>GPSLayer</code> 能识别的、带有 <code>.x</code> 和 <code>.edge_attr</code> 的标准 <code>Batch</code> 对象。</li>
<li>创建了 <code>GPS_to_GVP_Adapter</code> 类，负责反向操作，将 <code>GPSLayer</code> 的输出转换回 GVP 格式，以便后续的 gRNAde 解码器能够使用。</li>
<li><strong>后续升级1</strong>：为 <code>GVP_to_GPS_Adapter</code> 增加了<strong>展平 (flatten)</strong> 逻辑，使其能兼容训练和采样两种模式下维度不一致的输入。</li>
<li><strong>后续升级2</strong>：为 <code>GVP_to_GPS_Adapter</code> 增加了<strong>检查并创建 <code>batch.batch</code> 属性</strong>的逻辑。</li>
<li><strong>后续升级3</strong>：为 <code>GPS_to_GVP_Adapter</code> 增加了<strong>线性投射层</strong>，用于降维。</li>
</ol>
</li>
<li><strong>为什么这么做</strong>：
<ul>
<li><code>(1, 2)</code> 是为了解决 <strong>gRNAde 和 Graph-Mamba 之间最根本的数据格式不兼容</strong> 问题。</li>
<li><code>(3)</code> 是为了修复 <code>RuntimeError: Tensors must have same number of dimensions</code>，即拼接3D和2D张量的错误。</li>
<li><code>(4)</code> 是为了修复 <code>AttributeError: 'NoneType' object has no attribute 'gather'</code>，即 <code>lexsort</code> 函数找不到 <code>batch.batch</code> 属性的错误。</li>
<li><code>(5)</code> 是为了修复 <code>RuntimeError: shape '...' is invalid for input of size ...</code>，即 <code>GPSLayer</code> 输出的高维特征无法被正确拆分的错误。</li>
</ul>
</li>
</ul>
<p>adapters.py文件内容如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># File path: src/layers/adapters.py</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch_geometric.data</span> <span class="kn">import</span> <span class="n">Batch</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">GVP_to_GPS_Adapter</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gvp_node_dims</span><span class="p">,</span> <span class="n">gvp_edge_dims</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">node_s_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_v_dim</span> <span class="o">=</span> <span class="n">gvp_node_dims</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">edge_s_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_v_dim</span> <span class="o">=</span> <span class="n">gvp_edge_dims</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gvp_node_data</span><span class="p">,</span> <span class="n">gvp_edge_data</span><span class="p">,</span> <span class="n">batch_obj</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># --- Process node features ---</span>
</span></span><span class="line"><span class="cl">        <span class="n">s_node</span><span class="p">,</span> <span class="n">v_node</span> <span class="o">=</span> <span class="n">gvp_node_data</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># [Key modification] Flatten both scalar and vector parts to 2D</span>
</span></span><span class="line"><span class="cl">        <span class="n">s_node_flat</span> <span class="o">=</span> <span class="n">s_node</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">s_node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">v_node_flat</span> <span class="o">=</span> <span class="n">v_node</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">v_node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># Now both are 2D tensors, can safely concatenate</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">s_node_flat</span><span class="p">,</span> <span class="n">v_node_flat</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># --- Apply same processing to edge features for robustness ---</span>
</span></span><span class="line"><span class="cl">        <span class="n">s_edge</span><span class="p">,</span> <span class="n">v_edge</span> <span class="o">=</span> <span class="n">gvp_edge_data</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="n">s_edge_flat</span> <span class="o">=</span> <span class="n">s_edge</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">s_edge</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">v_edge_flat</span> <span class="o">=</span> <span class="n">v_edge</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">v_edge</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">edge_attr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">s_edge_flat</span><span class="p">,</span> <span class="n">v_edge_flat</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># --- Create new Batch object (logic unchanged) ---</span>
</span></span><span class="line"><span class="cl">        <span class="n">new_batch</span> <span class="o">=</span> <span class="n">batch_obj</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">new_batch</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
</span></span><span class="line"><span class="cl">        <span class="n">new_batch</span><span class="o">.</span><span class="n">edge_attr</span> <span class="o">=</span> <span class="n">edge_attr</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">new_batch</span><span class="p">,</span> <span class="s1">&#39;batch&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">new_batch</span><span class="o">.</span><span class="n">batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># If batch attribute doesn&#39;t exist or is None, create a zero tensor</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># This means all nodes in the batch belong to the same graph (graph 0)</span>
</span></span><span class="line"><span class="cl">            <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">new_batch</span><span class="o">.</span><span class="n">num_nodes</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">new_batch</span><span class="p">,</span> <span class="s1">&#39;num_nodes&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">new_batch</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">new_batch</span><span class="o">.</span><span class="n">batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_nodes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">new_batch</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">new_batch</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">GPS_to_GVP_Adapter</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gvp_node_dims</span><span class="p">,</span> <span class="n">gvp_edge_dims</span><span class="p">,</span> <span class="n">gps_node_dim</span><span class="p">,</span> <span class="n">gps_edge_dim</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">node_s_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_v_dim</span> <span class="o">=</span> <span class="n">gvp_node_dims</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">edge_s_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_v_dim</span> <span class="o">=</span> <span class="n">gvp_edge_dims</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># [Core modification] Create linear projection layers for dimensionality reduction</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Node feature projection layer</span>
</span></span><span class="line"><span class="cl">        <span class="n">gvp_node_total_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_s_dim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_v_dim</span> <span class="o">*</span> <span class="mi">3</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">node_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">gps_node_dim</span><span class="p">,</span> <span class="n">gvp_node_total_dim</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Edge feature projection layer</span>
</span></span><span class="line"><span class="cl">        <span class="n">gvp_edge_total_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_s_dim</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_v_dim</span> <span class="o">*</span> <span class="mi">3</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">edge_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">gps_edge_dim</span><span class="p">,</span> <span class="n">gvp_edge_total_dim</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gps_out_batch</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># --- Process node features ---</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">gps_out_batch</span><span class="o">.</span><span class="n">x</span> <span class="c1"># dimension: [n_nodes, 176]</span>
</span></span><span class="line"><span class="cl">        <span class="n">x_proj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># project to: [n_nodes, 176] (assuming node dimension unchanged)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="n">s_node</span> <span class="o">=</span> <span class="n">x_proj</span><span class="p">[:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">node_s_dim</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">v_node_flat</span> <span class="o">=</span> <span class="n">x_proj</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_s_dim</span><span class="p">:]</span>
</span></span><span class="line"><span class="cl">        <span class="n">v_node</span> <span class="o">=</span> <span class="n">v_node_flat</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">v_node_flat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_v_dim</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># --- Process edge features ---</span>
</span></span><span class="line"><span class="cl">        <span class="n">edge_attr</span> <span class="o">=</span> <span class="n">gps_out_batch</span><span class="o">.</span><span class="n">edge_attr</span> <span class="c1"># dimension: [n_edges, 176]</span>
</span></span><span class="line"><span class="cl">        <span class="n">edge_attr_proj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_proj</span><span class="p">(</span><span class="n">edge_attr</span><span class="p">)</span> <span class="c1"># [Core modification] project to: [n_edges, 76]</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="n">s_edge</span> <span class="o">=</span> <span class="n">edge_attr_proj</span><span class="p">[:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_s_dim</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">v_edge_flat</span> <span class="o">=</span> <span class="n">edge_attr_proj</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_s_dim</span><span class="p">:]</span>
</span></span><span class="line"><span class="cl">        <span class="n">v_edge</span> <span class="o">=</span> <span class="n">v_edge_flat</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">v_edge_flat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_v_dim</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="p">(</span><span class="n">s_node</span><span class="p">,</span> <span class="n">v_node</span><span class="p">),</span> <span class="p">(</span><span class="n">s_edge</span><span class="p">,</span> <span class="n">v_edge</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>以及trainer.py，在 <code>loop</code> 函数的 <code>for</code> 循环内部，<code>model(batch)</code> 调用之前，增加了一个 <code>if/else</code> 判断，为 <code>batch</code> 对象手动添加 <code>.split</code> 属性 (<code>'train'</code> 或 <code>'val'</code>)，来修复 <code>AttributeError: ... has no attribute 'split'</code>，因为 <code>GPSLayer</code> 需要这个属性来区分训练和评估模式，以执行不同的排序策略。具体：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span><span class="lnt">165
</span><span class="lnt">166
</span><span class="lnt">167
</span><span class="lnt">168
</span><span class="lnt">169
</span><span class="lnt">170
</span><span class="lnt">171
</span><span class="lnt">172
</span><span class="lnt">173
</span><span class="lnt">174
</span><span class="lnt">175
</span><span class="lnt">176
</span><span class="lnt">177
</span><span class="lnt">178
</span><span class="lnt">179
</span><span class="lnt">180
</span><span class="lnt">181
</span><span class="lnt">182
</span><span class="lnt">183
</span><span class="lnt">184
</span><span class="lnt">185
</span><span class="lnt">186
</span><span class="lnt">187
</span><span class="lnt">188
</span><span class="lnt">189
</span><span class="lnt">190
</span><span class="lnt">191
</span><span class="lnt">192
</span><span class="lnt">193
</span><span class="lnt">194
</span><span class="lnt">195
</span><span class="lnt">196
</span><span class="lnt">197
</span><span class="lnt">198
</span><span class="lnt">199
</span><span class="lnt">200
</span><span class="lnt">201
</span><span class="lnt">202
</span><span class="lnt">203
</span><span class="lnt">204
</span><span class="lnt">205
</span><span class="lnt">206
</span><span class="lnt">207
</span><span class="lnt">208
</span><span class="lnt">209
</span><span class="lnt">210
</span><span class="lnt">211
</span><span class="lnt">212
</span><span class="lnt">213
</span><span class="lnt">214
</span><span class="lnt">215
</span><span class="lnt">216
</span><span class="lnt">217
</span><span class="lnt">218
</span><span class="lnt">219
</span><span class="lnt">220
</span><span class="lnt">221
</span><span class="lnt">222
</span><span class="lnt">223
</span><span class="lnt">224
</span><span class="lnt">225
</span><span class="lnt">226
</span><span class="lnt">227
</span><span class="lnt">228
</span><span class="lnt">229
</span><span class="lnt">230
</span><span class="lnt">231
</span><span class="lnt">232
</span><span class="lnt">233
</span><span class="lnt">234
</span><span class="lnt">235
</span><span class="lnt">236
</span><span class="lnt">237
</span><span class="lnt">238
</span><span class="lnt">239
</span><span class="lnt">240
</span><span class="lnt">241
</span><span class="lnt">242
</span><span class="lnt">243
</span><span class="lnt">244
</span><span class="lnt">245
</span><span class="lnt">246
</span><span class="lnt">247
</span><span class="lnt">248
</span><span class="lnt">249
</span><span class="lnt">250
</span><span class="lnt">251
</span><span class="lnt">252
</span><span class="lnt">253
</span><span class="lnt">254
</span><span class="lnt">255
</span><span class="lnt">256
</span><span class="lnt">257
</span><span class="lnt">258
</span><span class="lnt">259
</span><span class="lnt">260
</span><span class="lnt">261
</span><span class="lnt">262
</span><span class="lnt">263
</span><span class="lnt">264
</span><span class="lnt">265
</span><span class="lnt">266
</span><span class="lnt">267
</span><span class="lnt">268
</span><span class="lnt">269
</span><span class="lnt">270
</span><span class="lnt">271
</span><span class="lnt">272
</span><span class="lnt">273
</span><span class="lnt">274
</span><span class="lnt">275
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">wandb</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">ReduceLROnPlateau</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">src.evaluator</span> <span class="kn">import</span> <span class="n">evaluate</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">src.constants</span> <span class="kn">import</span> <span class="n">NUM_TO_LETTER</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">config</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">train_loader</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">val_loader</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">test_loader</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="n">device</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Train RNA inverse folding model using the specified config and data loaders.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">    Args:
</span></span></span><span class="line"><span class="cl"><span class="s2">        config (dict): wandb configuration dictionary 
</span></span></span><span class="line"><span class="cl"><span class="s2">        model (nn.Module): RNA inverse folding model to be trained
</span></span></span><span class="line"><span class="cl"><span class="s2">        train_loader (DataLoader): training data loader
</span></span></span><span class="line"><span class="cl"><span class="s2">        val_loader (DataLoader): validation data loader
</span></span></span><span class="line"><span class="cl"><span class="s2">        test_loader (DataLoader): test data loader
</span></span></span><span class="line"><span class="cl"><span class="s2">        device (torch.device): device to train the model on
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Initialise loss function</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">label_smoothing</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">label_smoothing</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">eval_loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">label_smoothing</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Initialise optimizer and scheduler</span>
</span></span><span class="line"><span class="cl">    <span class="n">lr</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">lr</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_lr</span><span class="o">=</span><span class="mf">0.00001</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;xpu&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="kn">import</span> <span class="nn">intel_extension_for_pytorch</span> <span class="k">as</span> <span class="nn">ipex</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">ipex</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1">#=======</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Initialise save directory</span>
</span></span><span class="line"><span class="cl">    <span class="n">save_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__file__</span><span class="p">),</span> <span class="s2">&#34;..&#34;</span><span class="p">,</span> <span class="s2">&#34;mambagnnmodel&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1">#save_dir = os.path.abspath(save_dir)   </span>
</span></span><span class="line"><span class="cl">    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">save_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">#======</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Initialise lookup table mapping integers to nucleotides</span>
</span></span><span class="line"><span class="cl">    <span class="n">lookup</span> <span class="o">=</span> <span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">featurizer</span><span class="o">.</span><span class="n">num_to_letter</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Initialise best checkpoint information</span>
</span></span><span class="line"><span class="cl">    <span class="n">best_epoch</span><span class="p">,</span> <span class="n">best_val_loss</span><span class="p">,</span> <span class="n">best_val_acc</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1">##################################</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Training loop over mini-batches</span>
</span></span><span class="line"><span class="cl">    <span class="c1">##################################</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># Training iteration</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">train_confusion</span> <span class="o">=</span> <span class="n">loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">train_loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">print_and_log</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">train_confusion</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&#34;train&#34;</span><span class="p">,</span> <span class="n">lookup</span><span class="o">=</span><span class="n">lookup</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">config</span><span class="o">.</span><span class="n">val_every</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">==</span> <span class="n">config</span><span class="o">.</span><span class="n">epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            
</span></span><span class="line"><span class="cl">            <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> 
</span></span><span class="line"><span class="cl">                
</span></span><span class="line"><span class="cl">                <span class="c1"># Evaluate on validation set</span>
</span></span><span class="line"><span class="cl">                <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">val_confusion</span> <span class="o">=</span> <span class="n">loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">eval_loss_fn</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">print_and_log</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">val_confusion</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&#34;val&#34;</span><span class="p">,</span> <span class="n">lookup</span><span class="o">=</span><span class="n">lookup</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">                <span class="c1"># LR scheduler step</span>
</span></span><span class="line"><span class="cl">                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">val_acc</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">lr</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">                
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="n">val_acc</span> <span class="o">&gt;</span> <span class="n">best_val_acc</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="c1"># Update best checkpoint</span>
</span></span><span class="line"><span class="cl">                    <span class="n">best_epoch</span><span class="p">,</span> <span class="n">best_val_loss</span><span class="p">,</span> <span class="n">best_val_acc</span> <span class="o">=</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">                    <span class="c1"># Evaluate on test set</span>
</span></span><span class="line"><span class="cl">                    <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">,</span> <span class="n">test_confusion</span> <span class="o">=</span> <span class="n">loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">eval_loss_fn</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="n">print_and_log</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">,</span> <span class="n">test_confusion</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&#34;test&#34;</span><span class="p">,</span> <span class="n">lookup</span><span class="o">=</span><span class="n">lookup</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">                    <span class="c1"># Update wandb summary metrics</span>
</span></span><span class="line"><span class="cl">                    <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="s2">&#34;best_epoch&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_epoch</span>
</span></span><span class="line"><span class="cl">                    <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="s2">&#34;best_val_perp&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">best_val_loss</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="s2">&#34;best_val_acc&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_val_acc</span>
</span></span><span class="line"><span class="cl">                    <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="s2">&#34;best_test_perp&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">test_loss</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="s2">&#34;best_test_acc&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_acc</span>
</span></span><span class="line"><span class="cl">                    
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">save</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                        <span class="c1"># Save best checkpoint</span>
</span></span><span class="line"><span class="cl">                        <span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_dir</span><span class="p">,</span> <span class="s2">&#34;best_checkpoint.h5&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">checkpoint_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                        <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="s2">&#34;best_checkpoint&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">checkpoint_path</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">save</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Save current epoch checkpoint</span>
</span></span><span class="line"><span class="cl">            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_dir</span><span class="p">,</span> <span class="s2">&#34;current_checkpoint.h5&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># End of training</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">save</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Evaluate best checkpoint</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;EVALUATION: loading </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_dir</span><span class="p">,</span> <span class="s1">&#39;best_checkpoint.h5&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2"> (epoch </span><span class="si">{</span><span class="n">best_epoch</span><span class="si">}</span><span class="s2">)&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_dir</span><span class="p">,</span> <span class="s1">&#39;best_checkpoint.h5&#39;</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">loader</span><span class="p">,</span> <span class="n">set_name</span> <span class="ow">in</span> <span class="p">[(</span><span class="n">test_loader</span><span class="p">,</span> <span class="s2">&#34;test&#34;</span><span class="p">),</span> <span class="p">(</span><span class="n">val_loader</span><span class="p">,</span> <span class="s2">&#34;val&#34;</span><span class="p">)]:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Run evaluator</span>
</span></span><span class="line"><span class="cl">            <span class="n">results</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">model</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                <span class="n">loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                <span class="n">config</span><span class="o">.</span><span class="n">n_samples</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                <span class="n">config</span><span class="o">.</span><span class="n">temperature</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                <span class="n">device</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                <span class="n">model_name</span><span class="o">=</span><span class="n">set_name</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;recovery&#39;</span><span class="p">,</span> <span class="s1">&#39;perplexity&#39;</span><span class="p">,</span> <span class="s1">&#39;sc_score_eternafold&#39;</span><span class="p">,</span> <span class="s1">&#39;sc_score_ribonanzanet&#39;</span><span class="p">,</span> <span class="s1">&#39;sc_score_rhofold&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="n">save_designs</span><span class="o">=</span><span class="kc">True</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">df</span><span class="p">,</span> <span class="n">samples_list</span><span class="p">,</span> <span class="n">recovery_list</span><span class="p">,</span> <span class="n">perplexity_list</span><span class="p">,</span> \
</span></span><span class="line"><span class="cl">            <span class="n">scscore_list</span><span class="p">,</span> <span class="n">scscore_ribonanza_list</span><span class="p">,</span> \
</span></span><span class="line"><span class="cl">            <span class="n">scscore_rmsd_list</span><span class="p">,</span> <span class="n">scscore_tm_list</span><span class="p">,</span> <span class="n">scscore_gdt_list</span><span class="p">,</span> \
</span></span><span class="line"><span class="cl">            <span class="n">rmsd_within_thresh</span><span class="p">,</span> <span class="n">tm_within_thresh</span><span class="p">,</span> <span class="n">gdt_within_thresh</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Save results</span>
</span></span><span class="line"><span class="cl">            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">set_name</span><span class="si">}</span><span class="s2">_results.pt&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Update wandb summary metrics</span>
</span></span><span class="line"><span class="cl">            <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_</span><span class="si">{</span><span class="n">set_name</span><span class="si">}</span><span class="s2">_recovery&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">recovery_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_</span><span class="si">{</span><span class="n">set_name</span><span class="si">}</span><span class="s2">_perplexity&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">perplexity_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_</span><span class="si">{</span><span class="n">set_name</span><span class="si">}</span><span class="s2">_scscore&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_</span><span class="si">{</span><span class="n">set_name</span><span class="si">}</span><span class="s2">_scscore_ribonanza&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_ribonanza_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_</span><span class="si">{</span><span class="n">set_name</span><span class="si">}</span><span class="s2">_scscore_rmsd&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_rmsd_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_</span><span class="si">{</span><span class="n">set_name</span><span class="si">}</span><span class="s2">_scscore_tm&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_tm_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_</span><span class="si">{</span><span class="n">set_name</span><span class="si">}</span><span class="s2">_scscore_gdt&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_gdt_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_</span><span class="si">{</span><span class="n">set_name</span><span class="si">}</span><span class="s2">_rmsd_within_thresh&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rmsd_within_thresh</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_</span><span class="si">{</span><span class="n">set_name</span><span class="si">}</span><span class="s2">_tm_within_thresh&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">tm_within_thresh</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">wandb</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;best_</span><span class="si">{</span><span class="n">set_name</span><span class="si">}</span><span class="s2">_gdt_within_thresh&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">gdt_within_thresh</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;BEST </span><span class="si">{</span><span class="n">set_name</span><span class="si">}</span><span class="s2"> recovery: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">recovery_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                    perplexity: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">perplexity_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                    scscore: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                    scscore_ribonanza: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_ribonanza_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                    scscore_rmsd: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_rmsd_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                    scscore_tm: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_tm_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                    scscore_gdt: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scscore_gdt_list</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                    rmsd_within_thresh: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rmsd_within_thresh</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                    tm_within_thresh: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">tm_within_thresh</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span><span class="s2">                    gdt_within_thresh: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">gdt_within_thresh</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Training loop for a single epoch over the data loader.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">    Args:
</span></span></span><span class="line"><span class="cl"><span class="s2">        model (nn.Module): RNA inverse folding model
</span></span></span><span class="line"><span class="cl"><span class="s2">        dataloader (DataLoader): data loader for the current epoch
</span></span></span><span class="line"><span class="cl"><span class="s2">        loss_fn (nn.Module): loss function to compute the loss
</span></span></span><span class="line"><span class="cl"><span class="s2">        optimizer (torch.optim): optimizer to update model parameters
</span></span></span><span class="line"><span class="cl"><span class="s2">        device (torch.device): device to train the model on
</span></span></span><span class="line"><span class="cl"><span class="s2">    
</span></span></span><span class="line"><span class="cl"><span class="s2">    Note:
</span></span></span><span class="line"><span class="cl"><span class="s2">        This function is used for both training and evaluation loops.
</span></span></span><span class="line"><span class="cl"><span class="s2">        Not passing an optimizer will run the model in evaluation mode.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">    Returns:
</span></span></span><span class="line"><span class="cl"><span class="s2">        float: average loss over the epoch
</span></span></span><span class="line"><span class="cl"><span class="s2">        float: average accuracy over the epoch
</span></span></span><span class="line"><span class="cl"><span class="s2">        np.ndarray: confusion matrix over the epoch
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">confusion</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">model</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">out_dim</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">total_loss</span><span class="p">,</span> <span class="n">total_correct</span><span class="p">,</span> <span class="n">total_count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">t</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">t</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">optimizer</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">        <span class="c1"># move batch to device</span>
</span></span><span class="line"><span class="cl">        <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1">##############main change here##############</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># [Core modification] Add split attribute to batch object here</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">batch</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="s1">&#39;train&#39;</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">batch</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="s1">&#39;val&#39;</span> <span class="c1"># For evaluation mode, either &#39;val&#39; or &#39;test&#39; is fine</span>
</span></span><span class="line"><span class="cl">        <span class="c1">##########################################</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># forward pass</span>
</span></span><span class="line"><span class="cl">        <span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            
</span></span><span class="line"><span class="cl">        <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="s2">&#34;CUDA out of memory&#34;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span> <span class="k">raise</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Skipped batch due to OOM&#39;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="k">del</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span>  <span class="c1"># free some memory</span>
</span></span><span class="line"><span class="cl">            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="k">continue</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># compute loss</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss_value</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">seq</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">optimizer</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># backpropagate loss and update parameters</span>
</span></span><span class="line"><span class="cl">            <span class="n">loss_value</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># update metrics</span>
</span></span><span class="line"><span class="cl">        <span class="n">num_nodes</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">seq</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">total_loss</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss_value</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="o">*</span> <span class="n">num_nodes</span>
</span></span><span class="line"><span class="cl">        <span class="n">total_count</span> <span class="o">+=</span> <span class="n">num_nodes</span>
</span></span><span class="line"><span class="cl">        <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">true</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">seq</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">total_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">true</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">confusion</span> <span class="o">+=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">out_dim</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="n">t</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="s2">&#34;</span><span class="si">%.5f</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="nb">float</span><span class="p">(</span><span class="n">total_loss</span><span class="o">/</span><span class="n">total_count</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">total_count</span><span class="p">,</span> <span class="n">total_correct</span> <span class="o">/</span> <span class="n">total_count</span><span class="p">,</span> <span class="n">confusion</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">print_and_log</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">epoch</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">acc</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">confusion</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">recovery</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">lr</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">mode</span> <span class="o">=</span> <span class="s2">&#34;train&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">lookup</span> <span class="o">=</span> <span class="n">NUM_TO_LETTER</span><span class="p">,</span> <span class="c1"># reverse of {&#39;A&#39;: 0, &#39;G&#39;: 1, &#39;C&#39;: 2, &#39;U&#39;: 3}</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Create log string and wandb metrics dict</span>
</span></span><span class="line"><span class="cl">    <span class="n">log_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">EPOCH </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2"> loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> perp: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> acc: </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">wandb_metrics</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">/loss&#34;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">/perp&#34;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">loss</span><span class="p">),</span> 
</span></span><span class="line"><span class="cl">        <span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">/acc&#34;</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;epoch&#34;</span><span class="p">:</span> <span class="n">epoch</span> 
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">lr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Add learning rate to loggers</span>
</span></span><span class="line"><span class="cl">        <span class="n">log_str</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&#34; lr: </span><span class="si">{</span><span class="n">lr</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">wandb_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;lr&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">recovery</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Add mean sequence recovery to loggers</span>
</span></span><span class="line"><span class="cl">        <span class="n">log_str</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&#34; rec: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">recovery</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">wandb_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">/recovery&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">recovery</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">log_str</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">print_confusion</span><span class="p">(</span><span class="n">confusion</span><span class="p">,</span> <span class="n">lookup</span><span class="o">=</span><span class="n">lookup</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">wandb_metrics</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">print_confusion</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">lookup</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">counts</span> <span class="o">=</span> <span class="n">mat</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">mat</span> <span class="o">=</span> <span class="p">(</span><span class="n">counts</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="n">counts</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</span></span><span class="line"><span class="cl">    <span class="n">mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mat</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">res</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lookup</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
</span></span><span class="line"><span class="cl">        <span class="n">res</span> <span class="o">+=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lookup</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">res</span> <span class="o">+=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">Count</span><span class="se">\n</span><span class="s1">&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lookup</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
</span></span><span class="line"><span class="cl">        <span class="n">res</span> <span class="o">+=</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="se">\t</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lookup</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">res</span> <span class="o">+=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">mat</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">res</span> <span class="o">+=</span> <span class="s1">&#39;</span><span class="se">\t</span><span class="si">{}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>之后对models.py进行大改，只改autoregressive和上面一点的地方，</p>
<ol>
<li><strong>创建了 <code>EncoderBlock</code> 自定义模块</strong>，它将 <code>GVP_to_GPS_Adapter</code>、<code>GPSLayer</code> 和 <code>GPS_to_GVP_Adapter</code> 三个组件打包在一起，并定义了清晰的数据流。</li>
<li>在 <code>AutoregressiveMultiGNNv1</code> 的 <code>__init__</code> 函数中，用一个循环创建多个 <code>EncoderBlock</code> 实例，<strong>完全替换</strong>了原来创建 <code>MultiGVPConvLayer</code> 的 <code>self.encoder_layers</code>，为了解决 <code>nn.Sequential</code> 无法处理多输入的 <code>TypeError</code>。</li>
<li>在 <code>AutoregressiveMultiGNNv1</code> 的 <code>forward</code> 函数中，<strong>调整了运算顺序</strong>，将 <code>pool_multi_conf</code> 调用<strong>提前</strong>到编码器循环之前，以实现“先池化，再编码”的策略，让 <code>GPSLayer</code> 能正确处理多构象数据。</li>
<li>在 <code>AutoregressiveMultiGNNv1</code> 的 <code>sample</code> 函数中，<strong>完全同步</strong>了与 <code>forward</code> 函数一致的逻辑：添加 <code>.split</code> 属性、提前池化、并使用正确的参数调用新的 <code>EncoderBlock</code>。修复在<strong>推理/采样</strong>阶段出现的各种错误（<code>AttributeError</code>, <code>RuntimeError</code> 等），确保训练和推理两条代码路径的逻辑一致性。</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">#####models.py changes######</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">Categorical</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch_geometric</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Import layers</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">src.layers</span> <span class="kn">import</span> <span class="o">*</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">src.mgnn.gps_layer</span> <span class="kn">import</span> <span class="n">GPSLayer</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">src.mgnn.adapters</span> <span class="kn">import</span> <span class="n">GVP_to_GPS_Adapter</span><span class="p">,</span> <span class="n">GPS_to_GVP_Adapter</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># [Core modification] Create a custom EncoderBlock class to replace nn.Sequential</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">EncoderBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_h_dim</span><span class="p">,</span> <span class="n">edge_h_dim</span><span class="p">,</span> <span class="n">drop_rate</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">local_gnn_type</span><span class="p">,</span> <span class="n">global_model_type</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># Calculate various dimensions</span>
</span></span><span class="line"><span class="cl">        <span class="n">gvp_s_dim</span><span class="p">,</span> <span class="n">gvp_v_dim</span> <span class="o">=</span> <span class="n">node_h_dim</span>
</span></span><span class="line"><span class="cl">        <span class="n">gps_node_dim</span> <span class="o">=</span> <span class="n">gvp_s_dim</span> <span class="o">+</span> <span class="n">gvp_v_dim</span> <span class="o">*</span> <span class="mi">3</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">gvp_edge_s_dim</span><span class="p">,</span> <span class="n">gvp_edge_v_dim</span> <span class="o">=</span> <span class="n">edge_h_dim</span>
</span></span><span class="line"><span class="cl">        <span class="n">gps_edge_dim</span> <span class="o">=</span> <span class="n">gvp_edge_s_dim</span> <span class="o">+</span> <span class="n">gvp_edge_v_dim</span> <span class="o">*</span> <span class="mi">3</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Create three components internally</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">adapter_in</span> <span class="o">=</span> <span class="n">GVP_to_GPS_Adapter</span><span class="p">(</span><span class="n">gvp_node_dims</span><span class="o">=</span><span class="n">node_h_dim</span><span class="p">,</span> <span class="n">gvp_edge_dims</span><span class="o">=</span><span class="n">edge_h_dim</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">gps_layer</span> <span class="o">=</span> <span class="n">GPSLayer</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">dim_h</span><span class="o">=</span><span class="n">gps_node_dim</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">edge_dim_h</span><span class="o">=</span><span class="n">gps_edge_dim</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">local_gnn_type</span><span class="o">=</span><span class="n">local_gnn_type</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">global_model_type</span><span class="o">=</span><span class="n">global_model_type</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">dropout</span><span class="o">=</span><span class="n">drop_rate</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">adapter_out</span> <span class="o">=</span> <span class="n">GPS_to_GVP_Adapter</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">gvp_node_dims</span><span class="o">=</span><span class="n">node_h_dim</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">            <span class="n">gvp_edge_dims</span><span class="o">=</span><span class="n">edge_h_dim</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">gps_node_dim</span><span class="o">=</span><span class="n">gps_node_dim</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">gps_edge_dim</span><span class="o">=</span><span class="n">gps_node_dim</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h_V</span><span class="p">,</span> <span class="n">h_E</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Explicitly define data flow</span>
</span></span><span class="line"><span class="cl">        <span class="n">gps_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">adapter_in</span><span class="p">(</span><span class="n">h_V</span><span class="p">,</span> <span class="n">h_E</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">gps_out_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gps_layer</span><span class="p">(</span><span class="n">gps_batch</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">h_V_out</span><span class="p">,</span> <span class="n">h_E_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">adapter_out</span><span class="p">(</span><span class="n">gps_out_batch</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">h_V_out</span><span class="p">,</span> <span class="n">h_E_out</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>最后，修改gatedgcn文件，从 <code>graphmamba</code> 项目中拿来的 <code>GatedGCNLayer</code> 不够灵活，无法直接用于我们的混合维度场景。</p>
<ol>
<li>在 <code>GatedGCNLayer</code> 的 <code>__init__</code> 函数中，增加了一个 <code>edge_dim</code> 参数，并用它来初始化处理边特征的线性层 <code>self.C</code>，以修复 <code>RuntimeError: mat1 and mat2 shapes cannot be multiplied</code>，即边特征（76维）和线性层权重（期望176维）不匹配的错误。</li>
<li>同样在 <code>__init__</code> 中，增加了一个 <code>self.residual_e_proj</code> 线性投射层，它只在 <code>edge_dim</code> 和 <code>out_dim</code> 不相等时被创建；在 <code>forward</code> 函数的残差连接部分，增加了判断逻辑，如果 <code>self.residual_e_proj</code> 存在，就用它来对齐 <code>e_in</code> 的维度，然后再相加。这一点为了修复 <code>RuntimeError: The size of tensor a (76) must match...</code>，即边特征残差连接时，输入（76维）和输出（176维）维度不匹配的错误。</li>
</ol>
<p>具体代码如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch_geometric.nn</span> <span class="k">as</span> <span class="nn">pyg_nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch_geometric.graphgym.models.layer</span> <span class="kn">import</span> <span class="n">LayerConfig</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch_scatter</span> <span class="kn">import</span> <span class="n">scatter</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch_geometric.graphgym.config</span> <span class="kn">import</span> <span class="n">cfg</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch_geometric.graphgym.register</span> <span class="kn">import</span> <span class="n">register_layer</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">GatedGCNLayer</span><span class="p">(</span><span class="n">pyg_nn</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">MessagePassing</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">        GatedGCN layer
</span></span></span><span class="line"><span class="cl"><span class="s2">        Residual Gated Graph ConvNets
</span></span></span><span class="line"><span class="cl"><span class="s2">        https://arxiv.org/pdf/1711.07553.pdf
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">residual</span><span class="p">,</span> <span class="n">edge_dim</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">equivstable_pe</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">pyg_nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">=</span> <span class="n">pyg_nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">pyg_nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">edge_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">pyg_nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">E</span> <span class="o">=</span> <span class="n">pyg_nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># 【核心修改】如果边特征的输入输出维度不同，则添加一个投射层</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">residual_e_proj</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">edge_dim</span> <span class="o">!=</span> <span class="n">out_dim</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">residual_e_proj</span> <span class="o">=</span> <span class="n">pyg_nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">edge_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Handling for Equivariant and Stable PE using LapPE</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ICLR 2022 https://openreview.net/pdf?id=e95i1IHcWj</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">EquivStablePE</span> <span class="o">=</span> <span class="n">equivstable_pe</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">EquivStablePE</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">mlp_r_ij</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">out_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">bn_node_x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">out_dim</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">bn_edge_e</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">out_dim</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">residual</span> <span class="o">=</span> <span class="n">residual</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">e</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">edge_index</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">edge_attr</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">edge_index</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">        x               : [n_nodes, in_dim]
</span></span></span><span class="line"><span class="cl"><span class="s2">        e               : [n_edges, in_dim]
</span></span></span><span class="line"><span class="cl"><span class="s2">        edge_index      : [2, n_edges]
</span></span></span><span class="line"><span class="cl"><span class="s2">        &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">x_in</span> <span class="o">=</span> <span class="n">x</span>
</span></span><span class="line"><span class="cl">            <span class="n">e_in</span> <span class="o">=</span> <span class="n">e</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">Ax</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">Bx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">Ce</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">Dx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">Ex</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">E</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Handling for Equivariant and Stable PE using LapPE</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ICLR 2022 https://openreview.net/pdf?id=e95i1IHcWj</span>
</span></span><span class="line"><span class="cl">        <span class="n">pe_LapPE</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">pe_EquivStableLapPE</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">EquivStablePE</span> <span class="k">else</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">x</span><span class="p">,</span> <span class="n">e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                              <span class="n">Bx</span><span class="o">=</span><span class="n">Bx</span><span class="p">,</span> <span class="n">Dx</span><span class="o">=</span><span class="n">Dx</span><span class="p">,</span> <span class="n">Ex</span><span class="o">=</span><span class="n">Ex</span><span class="p">,</span> <span class="n">Ce</span><span class="o">=</span><span class="n">Ce</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                              <span class="n">e</span><span class="o">=</span><span class="n">e</span><span class="p">,</span> <span class="n">Ax</span><span class="o">=</span><span class="n">Ax</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                              <span class="n">PE</span><span class="o">=</span><span class="n">pe_LapPE</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn_node_x</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">e</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn_edge_e</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">e</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">e</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">x</span> <span class="o">=</span> <span class="n">x_in</span> <span class="o">+</span> <span class="n">x</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual_e_proj</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">e_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">residual_e_proj</span><span class="p">(</span><span class="n">e_in</span><span class="p">)</span> <span class="c1"># 将 76 维的 e_in 投射到 176 维</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">e</span> <span class="o">=</span> <span class="n">e_in</span> <span class="o">+</span> <span class="n">e</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">batch</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
</span></span><span class="line"><span class="cl">        <span class="n">batch</span><span class="o">.</span><span class="n">edge_attr</span> <span class="o">=</span> <span class="n">e</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">batch</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">message</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Dx_i</span><span class="p">,</span> <span class="n">Ex_j</span><span class="p">,</span> <span class="n">PE_i</span><span class="p">,</span> <span class="n">PE_j</span><span class="p">,</span> <span class="n">Ce</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">        </span><span class="si">{}</span><span class="s2">x_i           : [n_edges, out_dim]
</span></span></span><span class="line"><span class="cl"><span class="s2">        </span><span class="si">{}</span><span class="s2">x_j           : [n_edges, out_dim]
</span></span></span><span class="line"><span class="cl"><span class="s2">        </span><span class="si">{}</span><span class="s2">e             : [n_edges, out_dim]
</span></span></span><span class="line"><span class="cl"><span class="s2">        &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">e_ij</span> <span class="o">=</span> <span class="n">Dx_i</span> <span class="o">+</span> <span class="n">Ex_j</span> <span class="o">+</span> <span class="n">Ce</span>
</span></span><span class="line"><span class="cl">        <span class="n">sigma_ij</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">e_ij</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Handling for Equivariant and Stable PE using LapPE</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># ICLR 2022 https://openreview.net/pdf?id=e95i1IHcWj</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">EquivStablePE</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">r_ij</span> <span class="o">=</span> <span class="p">((</span><span class="n">PE_i</span> <span class="o">-</span> <span class="n">PE_j</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">r_ij</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp_r_ij</span><span class="p">(</span><span class="n">r_ij</span><span class="p">)</span>  <span class="c1"># the MLP is 1 dim --&gt; hidden_dim --&gt; 1 dim</span>
</span></span><span class="line"><span class="cl">            <span class="n">sigma_ij</span> <span class="o">=</span> <span class="n">sigma_ij</span> <span class="o">*</span> <span class="n">r_ij</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">e</span> <span class="o">=</span> <span class="n">e_ij</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">sigma_ij</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">aggregate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sigma_ij</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">Bx_j</span><span class="p">,</span> <span class="n">Bx</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">        sigma_ij        : [n_edges, out_dim]  ; is the output from message() function
</span></span></span><span class="line"><span class="cl"><span class="s2">        index           : [n_edges]
</span></span></span><span class="line"><span class="cl"><span class="s2">        </span><span class="si">{}</span><span class="s2">x_j           : [n_edges, out_dim]
</span></span></span><span class="line"><span class="cl"><span class="s2">        &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">dim_size</span> <span class="o">=</span> <span class="n">Bx</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># or None ??   &lt;--- Double check this</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">sum_sigma_x</span> <span class="o">=</span> <span class="n">sigma_ij</span> <span class="o">*</span> <span class="n">Bx_j</span>
</span></span><span class="line"><span class="cl">        <span class="n">numerator_eta_xj</span> <span class="o">=</span> <span class="n">scatter</span><span class="p">(</span><span class="n">sum_sigma_x</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">dim_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                   <span class="n">reduce</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">sum_sigma</span> <span class="o">=</span> <span class="n">sigma_ij</span>
</span></span><span class="line"><span class="cl">        <span class="n">denominator_eta_xj</span> <span class="o">=</span> <span class="n">scatter</span><span class="p">(</span><span class="n">sum_sigma</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">dim_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                     <span class="n">reduce</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">out</span> <span class="o">=</span> <span class="n">numerator_eta_xj</span> <span class="o">/</span> <span class="p">(</span><span class="n">denominator_eta_xj</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">out</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">aggr_out</span><span class="p">,</span> <span class="n">Ax</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">        aggr_out        : [n_nodes, out_dim] ; is the output from aggregate() function after the aggregation
</span></span></span><span class="line"><span class="cl"><span class="s2">        </span><span class="si">{}</span><span class="s2">x             : [n_nodes, out_dim]
</span></span></span><span class="line"><span class="cl"><span class="s2">        &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="n">Ax</span> <span class="o">+</span> <span class="n">aggr_out</span>
</span></span><span class="line"><span class="cl">        <span class="n">e_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">e</span>
</span></span><span class="line"><span class="cl">        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">e</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">e_out</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@register_layer</span><span class="p">(</span><span class="s1">&#39;gatedgcnconv&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">GatedGCNGraphGymLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;GatedGCN layer.
</span></span></span><span class="line"><span class="cl"><span class="s2">    Residual Gated Graph ConvNets
</span></span></span><span class="line"><span class="cl"><span class="s2">    https://arxiv.org/pdf/1711.07553.pdf
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_config</span><span class="p">:</span> <span class="n">LayerConfig</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">GatedGCNLayer</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="n">layer_config</span><span class="o">.</span><span class="n">dim_in</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                   <span class="n">out_dim</span><span class="o">=</span><span class="n">layer_config</span><span class="o">.</span><span class="n">dim_out</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                   <span class="n">dropout</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>  <span class="c1"># Dropout is handled by GraphGym&#39;s `GeneralLayer` wrapper</span>
</span></span><span class="line"><span class="cl">                                   <span class="n">residual</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># Residual connections are handled by GraphGym&#39;s `GNNStackStage` wrapper</span>
</span></span><span class="line"><span class="cl">                                   <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="实验测试">实验测试
</h3><p>根据同样50个epoch和数据集、split训练后进行测试，计算recovery和scc如下：</p>
<div align=center><img src="picture2.png" width=600/></div>
<center><font size=2>纳尼？情报系假嘚？</font></center>
<p>怎么会比sota指标低这么多，全线的低？我好菜。</p>
<p>于是问了问谷歌哈基米（gemini），也没感觉什么所以然来。可能是因为gpslayer和gatedgnn本来就不是为了rna识别而设计的，所以有一些逻辑可能直接拿来用也不是很ok。</p>
<p>emm，其实multi-scale attention也挺好对不啦？得了，明天汇报完再说吧。怎么论文里全是attention之类的奇奇怪怪的。</p>

</section>


    <footer class="article-footer">
    

    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI&#43;WdtXRGWt2kTvGFasHpSy3SV"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG&#43;vnGctmUb0ZY0l8"crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"integrity="sha384-&#43;VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4&#43;/RRE05"crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
	const mainArticleElement = document.querySelector(".main-article");
        renderMathInElement(mainArticleElement, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>

    
</article>

    

    

<aside class="related-content--wrapper">
    <h2 class="section-title">相关文章</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/p/%E6%9A%91%E7%A0%94%E5%B0%8F%E6%97%A5%E8%AE%B0/">
        
        

        <div class="article-details">
            <h2 class="article-title">暑研小日记？</h2>
        </div>
    </a>
</article>

            
                
<article class="has-image">
    <a href="/p/%E5%BE%9C%E5%BE%89%E5%9C%A8arxiv%E5%92%8Cbioarxiv%E7%9A%84%E6%B5%B7%E6%B4%8B%E9%87%8C/">
        
        
            <div class="article-image">
                <img src="/p/%E5%BE%9C%E5%BE%89%E5%9C%A8arxiv%E5%92%8Cbioarxiv%E7%9A%84%E6%B5%B7%E6%B4%8B%E9%87%8C/1.a2a284e858a6260395fb14d5b3e3f387_hu_7b1f37f7ffa701b7.jpg" 
                        width="250" 
                        height="150" 
                        loading="lazy"
                        alt="Featured image of post 徜徉在arxiv和bioarxiv的海洋里"
                        
                        data-hash="md5-oqKE6FimJgOV&#43;xTVs&#43;Pzhw==">
                
            </div>
        

        <div class="article-details">
            <h2 class="article-title">徜徉在arxiv和bioarxiv的海洋里</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/p/how-about-rna-inverse-folding-first-attempt./">
        
        

        <div class="article-details">
            <h2 class="article-title">How about RNA inverse folding? First attempt.</h2>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2024 - 
        
        2025 Xiangyu Wen
    </section>
    
    <section class="powerby">
        使用 <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> 构建 <br />
        主题 <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.30.0">Stack</a></b> 由 <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a> 设计
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>
<style>
  body {
    background: url(https://mosfish.github.io/background/bac.webp) no-repeat center top;
    background-size: cover;
    background-attachment: fixed;
  }
   @font-face {
    font-family: 'note';
    src: url(https://mosfish.github.io/font/suc.ttf) format('truetype');
  }

  :root {
    --base-font-family: 'note';
    --code-font-family: 'note';
  }
</style>
<style>
    .highlight {
         
        max-height: 400px;
        overflow: hidden;
    }

    .code-show {
        max-height: none !important;
    }

    .code-more-box {
        width: 100%;
        padding-top: 78px;
        background-image: -webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0)), to(#fff));
        position: absolute;
        left: 0;
        right: 0;
        bottom: 0;
        z-index: 1;
    }

    .code-more-btn {
        display: block;
        margin: auto;
        width: 44px;
        height: 22px;
        background: #f0f0f5;
        border-top-left-radius: 8px;
        border-top-right-radius: 8px;
        padding-top: 6px;
        cursor: pointer;
    }

    .code-more-img {
        cursor: pointer !important;
        display: block;
        margin: auto;
        width: 22px;
        height: 16px;
    }
</style>

<script>
  function initCodeMoreBox() {
    let codeBlocks = document.querySelectorAll(".highlight");
    if (!codeBlocks) {
      return;
    }
    codeBlocks.forEach(codeBlock => {
      
      if (codeBlock.scrollHeight <= codeBlock.clientHeight) {
        return;
      }
      
      
      let codeMoreBox = document.createElement('div');
      codeMoreBox.classList.add('code-more-box');
      
      let codeMoreBtn = document.createElement('span');
      codeMoreBtn.classList.add('code-more-btn');
      codeMoreBtn.addEventListener('click', () => {
        codeBlock.classList.add('code-show');
        codeMoreBox.style.display = 'none';
        
        window.dispatchEvent(new Event('resize'))
      })
      
      let img = document.createElement('img');
      img.classList.add('code-more-img');
      img.src = "https://mosfish.github.io/icons/codeMore.png"
      
      codeMoreBtn.appendChild(img);
      codeMoreBox.appendChild(codeMoreBtn);
      codeBlock.appendChild(codeMoreBox)
    })
  }
  
  initCodeMoreBox();
</script>



    </body>
</html>
