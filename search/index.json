[{"content":"正式修改与实验 在测试集均匀划分后，我首先对gRNAde模型进行了重新训练与测试，此时我发现结果不稳定，但是问题不大。简单画图如下：\n在测试集的结果 Graph-Mamba的模块添加 文献：Graph-Mamba: Towards Long-Range Graph Sequence Modeling with Selective State Spaces 文献的source code在：https://github.com/bowang-lab/Graph-Mamba.\n本文提出了基于mamba的gnn。\n输入输出匹配与debug修改 把grnade的GVP-GNN层替换为graphmamba论文提到的gps_layer，同时由于本层使用的是其加载的gatedgnn本地模型，在向量标量与维度问题上面容易有不匹配的问题，所以需要进行修改。\n首先是main.py，我也忘了改动哪里了，先放上来：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 import dotenv dotenv.load_dotenv(\u0026#34;.env\u0026#34;) import warnings warnings.filterwarnings(\u0026#34;ignore\u0026#34;, category=UserWarning) warnings.filterwarnings(\u0026#34;ignore\u0026#34;, category=RuntimeWarning) warnings.filterwarnings(\u0026#34;ignore\u0026#34;, category=FutureWarning) import os import random import argparse import wandb import numpy as np import torch import torch_geometric from torch_geometric.loader import DataLoader from src.trainer import train, evaluate from src.data.dataset import RNADesignDataset, BatchSampler from src.models import ( AutoregressiveMultiGNNv1, NonAutoregressiveMultiGNNv1, ) from src.constants import DATA_PATH def main(config, device): \u0026#34;\u0026#34;\u0026#34; Main function for training and evaluating gRNAde. \u0026#34;\u0026#34;\u0026#34; # Set seed set_seed(config.seed, device.type) # Initialise model model = get_model(config).to(device) total_param = 0 for param in model.parameters(): total_param += np.prod(list(param.data.size())) print(f\u0026#39;\\nMODEL\\n {model}\\n Total parameters: {total_param}\u0026#39;) wandb.run.summary[\u0026#34;total_param\u0026#34;] = total_param # Load checkpoint if config.model_path != \u0026#39;\u0026#39;: model.load_state_dict(torch.load(config.model_path, map_location=device)) if config.evaluate: # Load test set _, _, test_list = get_data_splits(config, split_type=config.split) testset = get_dataset(config, test_list, split=\u0026#34;test\u0026#34;) test_loader = get_dataloader(config, testset, shuffle=False) # Run evaluator + save designed structures results = evaluate( model, test_loader.dataset, config.n_samples, config.temperature, device, model_name=\u0026#34;test\u0026#34;, metrics=[\u0026#39;recovery\u0026#39;, \u0026#39;perplexity\u0026#39;, \u0026#39;sc_score_eternafold\u0026#39;, \u0026#39;sc_score_ribonanzanet\u0026#39;, \u0026#39;sc_score_rhofold\u0026#39;], save_designs=True ) df, samples_list, recovery_list, perplexity_list, \\ scscore_list, scscore_ribonanza_list, \\ scscore_rmsd_list, scscore_tm_list, scscore_gdt_list, \\ rmsd_within_thresh, tm_within_thresh, gdt_within_thresh = results.values() # Save results torch.save(results, os.path.join(wandb.run.dir, f\u0026#34;test_results.pt\u0026#34;)) # Update wandb summary metrics wandb.run.summary[f\u0026#34;best_test_recovery\u0026#34;] = np.mean(recovery_list) wandb.run.summary[f\u0026#34;best_test_perplexity\u0026#34;] = np.mean(perplexity_list) wandb.run.summary[f\u0026#34;best_test_scscore\u0026#34;] = np.mean(scscore_list) wandb.run.summary[f\u0026#34;best_test_scscore_ribonanza\u0026#34;] = np.mean(scscore_ribonanza_list) wandb.run.summary[f\u0026#34;best_test_scscore_rmsd\u0026#34;] = np.mean(scscore_rmsd_list) wandb.run.summary[f\u0026#34;best_test_scscore_tm\u0026#34;] = np.mean(scscore_tm_list) wandb.run.summary[f\u0026#34;best_test_scscore_gdt\u0026#34;] = np.mean(scscore_gdt_list) wandb.run.summary[f\u0026#34;best_test_rmsd_within_thresh\u0026#34;] = np.mean(rmsd_within_thresh) wandb.run.summary[f\u0026#34;best_test_tm_within_thresh\u0026#34;] = np.mean(tm_within_thresh) wandb.run.summary[f\u0026#34;best_test_gdt_within_thresh\u0026#34;] = np.mean(gdt_within_thresh) print(f\u0026#34;BEST test recovery: {np.mean(recovery_list):.4f}\\ perplexity: {np.mean(perplexity_list):.4f}\\ scscore: {np.mean(scscore_list):.4f}\\ scscore_ribonanza: {np.mean(scscore_ribonanza_list):.4f}\\ scscore_rmsd: {np.mean(scscore_rmsd_list):.4f}\\ scscore_tm: {np.mean(scscore_tm_list):.4f}\\ scscore_gdt: {np.mean(scscore_gdt_list):.4f}\\ rmsd_within_thresh: {np.mean(rmsd_within_thresh):.4f}\\ tm_within_thresh: {np.mean(tm_within_thresh):.4f}\\ gdt_within_thresh: {np.mean(gdt_within_thresh):.4f}\u0026#34;) else: # Get train, val, test data samples as lists train_list, val_list, test_list = get_data_splits(config, split_type=config.split) # Load datasets trainset = get_dataset(config, train_list, split=\u0026#34;train\u0026#34;) valset = get_dataset(config, val_list, split=\u0026#34;val\u0026#34;) testset = get_dataset(config, test_list, split=\u0026#34;test\u0026#34;) # Prepare dataloaders train_loader = get_dataloader(config, trainset, shuffle=True) val_loader = get_dataloader(config, valset, shuffle=False) test_loader = get_dataloader(config, testset, shuffle=False) # Run trainer train(config, model, train_loader, val_loader, test_loader, device) def get_data_splits(config, split_type=\u0026#34;structsim_v2\u0026#34;): \u0026#34;\u0026#34;\u0026#34; Returns train, val, test data splits as lists. \u0026#34;\u0026#34;\u0026#34; #data_list = list(torch.load(os.path.join(DATA_PATH, \u0026#34;processed.pt\u0026#34;)).values()) data_list = list(torch.load(os.path.join(DATA_PATH, \u0026#34;processed.pt\u0026#34;), weights_only=False).values()) def index_list_by_indices(lst, indices): # return [lst[index] if 0 \u0026lt;= index \u0026lt; len(lst) else None for index in indices] return [lst[index] for index in indices] # Pre-compute using notebooks/split_{split_type}.ipynb train_idx_list, val_idx_list, test_idx_list = torch.load( os.path.join(DATA_PATH, f\u0026#34;{split_type}_split.pt\u0026#34;)) train_list = index_list_by_indices(data_list, train_idx_list) val_list = index_list_by_indices(data_list, val_idx_list) test_list = index_list_by_indices(data_list, test_idx_list) return train_list, val_list, test_list def get_dataset(config, data_list, split=\u0026#34;train\u0026#34;): \u0026#34;\u0026#34;\u0026#34; Returns a Dataset for a given split. \u0026#34;\u0026#34;\u0026#34; return RNADesignDataset( data_list = data_list, split = split, radius = config.radius, top_k = config.top_k, num_rbf = config.num_rbf, num_posenc = config.num_posenc, max_num_conformers = config.max_num_conformers, noise_scale = config.noise_scale ) def get_dataloader( config, dataset, shuffle=True, pin_memory=True, exclude_keys=[], ): \u0026#34;\u0026#34;\u0026#34; Returns a DataLoader for a given Dataset. Args: dataset (RNADesignDataset): dataset object config (dict): wandb configuration dictionary shuffle (bool): whether to shuffle the dataset pin_memory (bool): whether to pin memory exclue_keys (list): list of keys to exclude during batching \u0026#34;\u0026#34;\u0026#34; return DataLoader( dataset, num_workers = config.num_workers, batch_sampler = BatchSampler( node_counts = dataset.node_counts, max_nodes_batch = config.max_nodes_batch, max_nodes_sample = config.max_nodes_sample, shuffle = shuffle, ), pin_memory = pin_memory, exclude_keys = exclude_keys ) def get_model(config): \u0026#34;\u0026#34;\u0026#34; Returns a Model for a given config. \u0026#34;\u0026#34;\u0026#34; model_class = { \u0026#39;ARv1\u0026#39; : AutoregressiveMultiGNNv1, \u0026#39;NARv1\u0026#39;: NonAutoregressiveMultiGNNv1, }[config.model] return model_class( node_in_dim = tuple(config.node_in_dim), node_h_dim = tuple(config.node_h_dim), edge_in_dim = tuple(config.edge_in_dim), edge_h_dim = tuple(config.edge_h_dim), num_layers=config.num_layers, drop_rate = config.drop_rate, out_dim = config.out_dim ) def set_seed(seed=0, device_type=\u0026#39;cpu\u0026#39;): \u0026#34;\u0026#34;\u0026#34; Sets random seed for reproducibility. \u0026#34;\u0026#34;\u0026#34; random.seed(seed) np.random.seed(seed) torch.manual_seed(seed) torch.cuda.manual_seed(seed) torch.cuda.manual_seed_all(seed) torch.backends.cudnn.deterministic = True torch.backends.cudnn.benchmark = False if device_type == \u0026#39;xpu\u0026#39;: import intel_extension_for_pytorch as ipex torch.xpu.manual_seed(seed) torch.xpu.manual_seed_all(seed) if __name__ == \u0026#34;__main__\u0026#34;: parser = argparse.ArgumentParser() parser.add_argument(\u0026#39;--config\u0026#39;, dest=\u0026#39;config\u0026#39;, default=\u0026#39;configs/default.yaml\u0026#39;, type=str) parser.add_argument(\u0026#39;--expt_name\u0026#39;, dest=\u0026#39;expt_name\u0026#39;, default=None, type=str) parser.add_argument(\u0026#39;--tags\u0026#39;, nargs=\u0026#39;+\u0026#39;, dest=\u0026#39;tags\u0026#39;, default=[]) parser.add_argument(\u0026#39;--no_wandb\u0026#39;, action=\u0026#34;store_true\u0026#34;) args, unknown = parser.parse_known_args() # Initialise wandb if args.no_wandb: wandb.init( project=os.environ.get(\u0026#34;WANDB_PROJECT\u0026#34;), entity=os.environ.get(\u0026#34;WANDB_ENTITY\u0026#34;), config=args.config, name=args.expt_name, mode=\u0026#39;disabled\u0026#39; ) else: wandb.init( project=os.environ.get(\u0026#34;WANDB_PROJECT\u0026#34;), entity=os.environ.get(\u0026#34;WANDB_ENTITY\u0026#34;), config=args.config, name=args.expt_name, tags=args.tags, mode=\u0026#39;online\u0026#39; ) config = wandb.config config_str = \u0026#34;\\nCONFIG\u0026#34; for key, val in config.items(): config_str += f\u0026#34;\\n {key}: {val}\u0026#34; print(config_str) # Set device (GPU/CPU/XPU) if config.device == \u0026#39;xpu\u0026#39;: import intel_extension_for_pytorch as ipex [print(f\u0026#39;[{i}]: {torch.xpu.get_device_properties(i)}\u0026#39;) for i in range(torch.xpu.device_count())] device = torch.device(\u0026#34;xpu:{}\u0026#34;.format(config.gpu) if torch.xpu.is_available() else \u0026#39;cpu\u0026#39;) else: device = torch.device(\u0026#34;cuda:{}\u0026#34;.format(config.gpu) if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) # Run main function main(config, device) 之后，需要把Graph-Mamba的文件拷贝到当前位置： 里面的adapters.py是来处理数据格式不匹配的问题。\n创建了 GVP_to_GPS_Adapter 类，负责将 gRNAde 的 GVP 数据格式 (标量, 向量) 元组，转换为 GPSLayer 能识别的、带有 .x 和 .edge_attr 的标准 Batch 对象。 创建了 GPS_to_GVP_Adapter 类，负责反向操作，将 GPSLayer 的输出转换回 GVP 格式，以便后续的 gRNAde 解码器能够使用。 后续升级1：为 GVP_to_GPS_Adapter 增加了展平 (flatten) 逻辑，使其能兼容训练和采样两种模式下维度不一致的输入。 后续升级2：为 GVP_to_GPS_Adapter 增加了检查并创建 batch.batch 属性的逻辑。 后续升级3：为 GPS_to_GVP_Adapter 增加了线性投射层，用于降维。 为什么这么做： (1, 2) 是为了解决 gRNAde 和 Graph-Mamba 之间最根本的数据格式不兼容 问题。 (3) 是为了修复 RuntimeError: Tensors must have same number of dimensions，即拼接3D和2D张量的错误。 (4) 是为了修复 AttributeError: 'NoneType' object has no attribute 'gather'，即 lexsort 函数找不到 batch.batch 属性的错误。 (5) 是为了修复 RuntimeError: shape '...' is invalid for input of size ...，即 GPSLayer 输出的高维特征无法被正确拆分的错误。 adapters.py文件内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 # File path: src/layers/adapters.py import torch import torch.nn as nn from torch_geometric.data import Batch class GVP_to_GPS_Adapter(nn.Module): def __init__(self, gvp_node_dims, gvp_edge_dims): super().__init__() self.node_s_dim, self.node_v_dim = gvp_node_dims self.edge_s_dim, self.edge_v_dim = gvp_edge_dims def forward(self, gvp_node_data, gvp_edge_data, batch_obj): # --- Process node features --- s_node, v_node = gvp_node_data # [Key modification] Flatten both scalar and vector parts to 2D s_node_flat = s_node.contiguous().view(s_node.shape[0], -1) v_node_flat = v_node.contiguous().view(v_node.shape[0], -1) # Now both are 2D tensors, can safely concatenate x = torch.cat([s_node_flat, v_node_flat], dim=-1) # --- Apply same processing to edge features for robustness --- s_edge, v_edge = gvp_edge_data s_edge_flat = s_edge.contiguous().view(s_edge.shape[0], -1) v_edge_flat = v_edge.contiguous().view(v_edge.shape[0], -1) edge_attr = torch.cat([s_edge_flat, v_edge_flat], dim=-1) # --- Create new Batch object (logic unchanged) --- new_batch = batch_obj.clone() new_batch.x = x new_batch.edge_attr = edge_attr if not hasattr(new_batch, \u0026#39;batch\u0026#39;) or new_batch.batch is None: # If batch attribute doesn\u0026#39;t exist or is None, create a zero tensor # This means all nodes in the batch belong to the same graph (graph 0) num_nodes = new_batch.num_nodes if hasattr(new_batch, \u0026#39;num_nodes\u0026#39;) else new_batch.x.size(0) new_batch.batch = torch.zeros(num_nodes, dtype=torch.long, device=new_batch.x.device) return new_batch class GPS_to_GVP_Adapter(nn.Module): def __init__(self, gvp_node_dims, gvp_edge_dims, gps_node_dim, gps_edge_dim): super().__init__() self.node_s_dim, self.node_v_dim = gvp_node_dims self.edge_s_dim, self.edge_v_dim = gvp_edge_dims # [Core modification] Create linear projection layers for dimensionality reduction # Node feature projection layer gvp_node_total_dim = self.node_s_dim + self.node_v_dim * 3 self.node_proj = nn.Linear(gps_node_dim, gvp_node_total_dim) # Edge feature projection layer gvp_edge_total_dim = self.edge_s_dim + self.edge_v_dim * 3 self.edge_proj = nn.Linear(gps_edge_dim, gvp_edge_total_dim) def forward(self, gps_out_batch): # --- Process node features --- x = gps_out_batch.x # dimension: [n_nodes, 176] x_proj = self.node_proj(x) # project to: [n_nodes, 176] (assuming node dimension unchanged) s_node = x_proj[:, :self.node_s_dim] v_node_flat = x_proj[:, self.node_s_dim:] v_node = v_node_flat.contiguous().view(v_node_flat.shape[0], self.node_v_dim, 3) # --- Process edge features --- edge_attr = gps_out_batch.edge_attr # dimension: [n_edges, 176] edge_attr_proj = self.edge_proj(edge_attr) # [Core modification] project to: [n_edges, 76] s_edge = edge_attr_proj[:, :self.edge_s_dim] v_edge_flat = edge_attr_proj[:, self.edge_s_dim:] v_edge = v_edge_flat.contiguous().view(v_edge_flat.shape[0], self.edge_v_dim, 3) return (s_node, v_node), (s_edge, v_edge) 以及trainer.py，在 loop 函数的 for 循环内部，model(batch) 调用之前，增加了一个 if/else 判断，为 batch 对象手动添加 .split 属性 ('train' 或 'val')，来修复 AttributeError: ... has no attribute 'split'，因为 GPSLayer 需要这个属性来区分训练和评估模式，以执行不同的排序策略。具体：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 import os import numpy as np from tqdm import tqdm import wandb from sklearn.metrics import confusion_matrix import torch from torch.optim import Adam from torch.optim.lr_scheduler import ReduceLROnPlateau from src.evaluator import evaluate from src.constants import NUM_TO_LETTER def train( config, model, train_loader, val_loader, test_loader, device ): \u0026#34;\u0026#34;\u0026#34; Train RNA inverse folding model using the specified config and data loaders. Args: config (dict): wandb configuration dictionary model (nn.Module): RNA inverse folding model to be trained train_loader (DataLoader): training data loader val_loader (DataLoader): validation data loader test_loader (DataLoader): test data loader device (torch.device): device to train the model on \u0026#34;\u0026#34;\u0026#34; # Initialise loss function train_loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=config.label_smoothing) eval_loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.0) # Initialise optimizer and scheduler lr = config.lr optimizer = Adam(model.parameters(), lr) scheduler = ReduceLROnPlateau(optimizer, mode=\u0026#39;max\u0026#39;, factor=0.9, patience=1, min_lr=0.00001) if device.type == \u0026#39;xpu\u0026#39;: import intel_extension_for_pytorch as ipex model, optimizer = ipex.optimize(model, optimizer=optimizer) #======= # Initialise save directory save_dir = os.path.join(os.path.dirname(__file__), \u0026#34;..\u0026#34;, \u0026#34;mambagnnmodel\u0026#34;) #save_dir = os.path.abspath(save_dir) os.makedirs(save_dir, exist_ok=True) #====== # Initialise lookup table mapping integers to nucleotides lookup = train_loader.dataset.featurizer.num_to_letter # Initialise best checkpoint information best_epoch, best_val_loss, best_val_acc = -1, np.inf, 0 ################################## # Training loop over mini-batches ################################## for epoch in range(config.epochs): # Training iteration model.train() train_loss, train_acc, train_confusion = loop(model, train_loader, train_loss_fn, optimizer, device) print_and_log(epoch, train_loss, train_acc, train_confusion, lr=lr, mode=\u0026#34;train\u0026#34;, lookup=lookup) if epoch % config.val_every == 0 or epoch == config.epochs - 1: model.eval() with torch.no_grad(): # Evaluate on validation set val_loss, val_acc, val_confusion = loop(model, val_loader, eval_loss_fn, None, device) print_and_log(epoch, val_loss, val_acc, val_confusion, mode=\u0026#34;val\u0026#34;, lookup=lookup) # LR scheduler step scheduler.step(val_acc) lr = optimizer.param_groups[0][\u0026#39;lr\u0026#39;] if val_acc \u0026gt; best_val_acc: # Update best checkpoint best_epoch, best_val_loss, best_val_acc = epoch, val_loss, val_acc # Evaluate on test set test_loss, test_acc, test_confusion = loop(model, test_loader, eval_loss_fn, None, device) print_and_log(epoch, test_loss, test_acc, test_confusion, mode=\u0026#34;test\u0026#34;, lookup=lookup) # Update wandb summary metrics wandb.run.summary[\u0026#34;best_epoch\u0026#34;] = best_epoch wandb.run.summary[\u0026#34;best_val_perp\u0026#34;] = np.exp(best_val_loss) wandb.run.summary[\u0026#34;best_val_acc\u0026#34;] = best_val_acc wandb.run.summary[\u0026#34;best_test_perp\u0026#34;] = np.exp(test_loss) wandb.run.summary[\u0026#34;best_test_acc\u0026#34;] = test_acc if config.save: # Save best checkpoint checkpoint_path = os.path.join(save_dir, \u0026#34;best_checkpoint.h5\u0026#34;) torch.save(model.state_dict(), checkpoint_path) wandb.run.summary[\u0026#34;best_checkpoint\u0026#34;] = checkpoint_path if config.save: # Save current epoch checkpoint torch.save(model.state_dict(), os.path.join(save_dir, \u0026#34;current_checkpoint.h5\u0026#34;)) # End of training if config.save: # Evaluate best checkpoint print(f\u0026#34;EVALUATION: loading {os.path.join(save_dir, \u0026#39;best_checkpoint.h5\u0026#39;)} (epoch {best_epoch})\u0026#34;) model.load_state_dict(torch.load(os.path.join(save_dir, \u0026#39;best_checkpoint.h5\u0026#39;))) for loader, set_name in [(test_loader, \u0026#34;test\u0026#34;), (val_loader, \u0026#34;val\u0026#34;)]: # Run evaluator results = evaluate( model, loader.dataset, config.n_samples, config.temperature, device, model_name=set_name, metrics=[\u0026#39;recovery\u0026#39;, \u0026#39;perplexity\u0026#39;, \u0026#39;sc_score_eternafold\u0026#39;, \u0026#39;sc_score_ribonanzanet\u0026#39;, \u0026#39;sc_score_rhofold\u0026#39;], save_designs=True ) df, samples_list, recovery_list, perplexity_list, \\ scscore_list, scscore_ribonanza_list, \\ scscore_rmsd_list, scscore_tm_list, scscore_gdt_list, \\ rmsd_within_thresh, tm_within_thresh, gdt_within_thresh = results.values() # Save results torch.save(results, os.path.join(save_dir, f\u0026#34;{set_name}_results.pt\u0026#34;)) # Update wandb summary metrics wandb.run.summary[f\u0026#34;best_{set_name}_recovery\u0026#34;] = np.mean(recovery_list) wandb.run.summary[f\u0026#34;best_{set_name}_perplexity\u0026#34;] = np.mean(perplexity_list) wandb.run.summary[f\u0026#34;best_{set_name}_scscore\u0026#34;] = np.mean(scscore_list) wandb.run.summary[f\u0026#34;best_{set_name}_scscore_ribonanza\u0026#34;] = np.mean(scscore_ribonanza_list) wandb.run.summary[f\u0026#34;best_{set_name}_scscore_rmsd\u0026#34;] = np.mean(scscore_rmsd_list) wandb.run.summary[f\u0026#34;best_{set_name}_scscore_tm\u0026#34;] = np.mean(scscore_tm_list) wandb.run.summary[f\u0026#34;best_{set_name}_scscore_gdt\u0026#34;] = np.mean(scscore_gdt_list) wandb.run.summary[f\u0026#34;best_{set_name}_rmsd_within_thresh\u0026#34;] = np.mean(rmsd_within_thresh) wandb.run.summary[f\u0026#34;best_{set_name}_tm_within_thresh\u0026#34;] = np.mean(tm_within_thresh) wandb.run.summary[f\u0026#34;best_{set_name}_gdt_within_thresh\u0026#34;] = np.mean(gdt_within_thresh) print(f\u0026#34;BEST {set_name} recovery: {np.mean(recovery_list):.4f}\\ perplexity: {np.mean(perplexity_list):.4f}\\ scscore: {np.mean(scscore_list):.4f}\\ scscore_ribonanza: {np.mean(scscore_ribonanza_list):.4f}\\ scscore_rmsd: {np.mean(scscore_rmsd_list):.4f}\\ scscore_tm: {np.mean(scscore_tm_list):.4f}\\ scscore_gdt: {np.mean(scscore_gdt_list):.4f}\\ rmsd_within_thresh: {np.mean(rmsd_within_thresh):.4f}\\ tm_within_thresh: {np.mean(tm_within_thresh):.4f}\\ gdt_within_thresh: {np.mean(gdt_within_thresh):.4f}\u0026#34;) def loop(model, dataloader, loss_fn, optimizer=None, device=\u0026#39;cpu\u0026#39;): \u0026#34;\u0026#34;\u0026#34; Training loop for a single epoch over the data loader. Args: model (nn.Module): RNA inverse folding model dataloader (DataLoader): data loader for the current epoch loss_fn (nn.Module): loss function to compute the loss optimizer (torch.optim): optimizer to update model parameters device (torch.device): device to train the model on Note: This function is used for both training and evaluation loops. Not passing an optimizer will run the model in evaluation mode. Returns: float: average loss over the epoch float: average accuracy over the epoch np.ndarray: confusion matrix over the epoch \u0026#34;\u0026#34;\u0026#34; confusion = np.zeros((model.out_dim, model.out_dim)) total_loss, total_correct, total_count = 0, 0, 0 t = tqdm(dataloader) for batch in t: if optimizer: optimizer.zero_grad() # move batch to device batch = batch.to(device) ##############main change here############## # [Core modification] Add split attribute to batch object here if optimizer is not None: batch.split = \u0026#39;train\u0026#39; else: batch.split = \u0026#39;val\u0026#39; # For evaluation mode, either \u0026#39;val\u0026#39; or \u0026#39;test\u0026#39; is fine ########################################## # forward pass try: logits = model(batch) except RuntimeError as e: if \u0026#34;CUDA out of memory\u0026#34; not in str(e): raise(e) print(\u0026#39;Skipped batch due to OOM\u0026#39;, flush=True) for p in model.parameters(): if p.grad is not None: del p.grad # free some memory torch.cuda.empty_cache() continue # compute loss loss_value = loss_fn(logits, batch.seq) if optimizer: # backpropagate loss and update parameters loss_value.backward() optimizer.step() # update metrics num_nodes = int(batch.seq.size(0)) total_loss += float(loss_value.item()) * num_nodes total_count += num_nodes pred = torch.argmax(logits, dim=-1).detach().cpu().numpy() true = batch.seq.detach().cpu().numpy() total_correct += (pred == true).sum() confusion += confusion_matrix(true, pred, labels=range(model.out_dim)) t.set_description(\u0026#34;%.5f\u0026#34; % float(total_loss/total_count)) return total_loss / total_count, total_correct / total_count, confusion def print_and_log( epoch, loss, acc, confusion, recovery = None, lr = None, mode = \u0026#34;train\u0026#34;, lookup = NUM_TO_LETTER, # reverse of {\u0026#39;A\u0026#39;: 0, \u0026#39;G\u0026#39;: 1, \u0026#39;C\u0026#39;: 2, \u0026#39;U\u0026#39;: 3} ): # Create log string and wandb metrics dict log_str = f\u0026#34;\\nEPOCH {epoch} {mode.upper()} loss: {loss:.4f} perp: {np.exp(loss):.4f} acc: {acc:.4f}\u0026#34; wandb_metrics = { f\u0026#34;{mode}/loss\u0026#34;: loss, f\u0026#34;{mode}/perp\u0026#34;: np.exp(loss), f\u0026#34;{mode}/acc\u0026#34;: acc, \u0026#34;epoch\u0026#34;: epoch } if lr is not None: # Add learning rate to loggers log_str += f\u0026#34; lr: {lr:.6f}\u0026#34; wandb_metrics[f\u0026#34;lr\u0026#34;] = lr if recovery is not None: # Add mean sequence recovery to loggers log_str += f\u0026#34; rec: {np.mean(recovery):.4f}\u0026#34; wandb_metrics[f\u0026#34;{mode}/recovery\u0026#34;] = np.mean(recovery) print(log_str) print_confusion(confusion, lookup=lookup) wandb.log(wandb_metrics) def print_confusion(mat, lookup): counts = mat.astype(np.int32) mat = (counts.T / counts.sum(axis=-1, keepdims=True).T).T mat = np.round(mat * 1000).astype(np.int32) res = \u0026#39;\\n\u0026#39; for i in range(len(lookup.keys())): res += \u0026#39;\\t{}\u0026#39;.format(lookup[i]) res += \u0026#39;\\tCount\\n\u0026#39; for i in range(len(lookup.keys())): res += \u0026#39;{}\\t\u0026#39;.format(lookup[i]) res += \u0026#39;\\t\u0026#39;.join(\u0026#39;{}\u0026#39;.format(n) for n in mat[i]) res += \u0026#39;\\t{}\\n\u0026#39;.format(sum(counts[i])) print(res) 之后对models.py进行大改，只改autoregressive和上面一点的地方，\n创建了 EncoderBlock 自定义模块，它将 GVP_to_GPS_Adapter、GPSLayer 和 GPS_to_GVP_Adapter 三个组件打包在一起，并定义了清晰的数据流。 在 AutoregressiveMultiGNNv1 的 __init__ 函数中，用一个循环创建多个 EncoderBlock 实例，完全替换了原来创建 MultiGVPConvLayer 的 self.encoder_layers，为了解决 nn.Sequential 无法处理多输入的 TypeError。 在 AutoregressiveMultiGNNv1 的 forward 函数中，调整了运算顺序，将 pool_multi_conf 调用提前到编码器循环之前，以实现“先池化，再编码”的策略，让 GPSLayer 能正确处理多构象数据。 在 AutoregressiveMultiGNNv1 的 sample 函数中，完全同步了与 forward 函数一致的逻辑：添加 .split 属性、提前池化、并使用正确的参数调用新的 EncoderBlock。修复在推理/采样阶段出现的各种错误（AttributeError, RuntimeError 等），确保训练和推理两条代码路径的逻辑一致性。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 #####models.py changes###### from typing import Optional import torch from torch import nn import torch.nn.functional as F from torch.distributions import Categorical import torch_geometric # Import layers from src.layers import * from src.mgnn.gps_layer import GPSLayer from src.mgnn.adapters import GVP_to_GPS_Adapter, GPS_to_GVP_Adapter # [Core modification] Create a custom EncoderBlock class to replace nn.Sequential class EncoderBlock(nn.Module): def __init__(self, node_h_dim, edge_h_dim, drop_rate, num_heads, local_gnn_type, global_model_type): super().__init__() # Calculate various dimensions gvp_s_dim, gvp_v_dim = node_h_dim gps_node_dim = gvp_s_dim + gvp_v_dim * 3 gvp_edge_s_dim, gvp_edge_v_dim = edge_h_dim gps_edge_dim = gvp_edge_s_dim + gvp_edge_v_dim * 3 # Create three components internally self.adapter_in = GVP_to_GPS_Adapter(gvp_node_dims=node_h_dim, gvp_edge_dims=edge_h_dim) self.gps_layer = GPSLayer( dim_h=gps_node_dim, edge_dim_h=gps_edge_dim, local_gnn_type=local_gnn_type, global_model_type=global_model_type, num_heads=num_heads, batch_norm=True, dropout=drop_rate ) self.adapter_out = GPS_to_GVP_Adapter( gvp_node_dims=node_h_dim, gvp_edge_dims=edge_h_dim, gps_node_dim=gps_node_dim, gps_edge_dim=gps_node_dim ) def forward(self, h_V, h_E, batch): # Explicitly define data flow gps_batch = self.adapter_in(h_V, h_E, batch) gps_out_batch = self.gps_layer(gps_batch) h_V_out, h_E_out = self.adapter_out(gps_out_batch) return h_V_out, h_E_out 最后，修改gatedgcn文件，从 graphmamba 项目中拿来的 GatedGCNLayer 不够灵活，无法直接用于我们的混合维度场景。\n在 GatedGCNLayer 的 __init__ 函数中，增加了一个 edge_dim 参数，并用它来初始化处理边特征的线性层 self.C，以修复 RuntimeError: mat1 and mat2 shapes cannot be multiplied，即边特征（76维）和线性层权重（期望176维）不匹配的错误。 同样在 __init__ 中，增加了一个 self.residual_e_proj 线性投射层，它只在 edge_dim 和 out_dim 不相等时被创建；在 forward 函数的残差连接部分，增加了判断逻辑，如果 self.residual_e_proj 存在，就用它来对齐 e_in 的维度，然后再相加。这一点为了修复 RuntimeError: The size of tensor a (76) must match...，即边特征残差连接时，输入（76维）和输出（176维）维度不匹配的错误。 具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 import torch import torch.nn as nn import torch.nn.functional as F import torch_geometric.nn as pyg_nn from torch_geometric.graphgym.models.layer import LayerConfig from torch_scatter import scatter from torch_geometric.graphgym.config import cfg from torch_geometric.graphgym.register import register_layer class GatedGCNLayer(pyg_nn.conv.MessagePassing): \u0026#34;\u0026#34;\u0026#34; GatedGCN layer Residual Gated Graph ConvNets https://arxiv.org/pdf/1711.07553.pdf \u0026#34;\u0026#34;\u0026#34; def __init__(self, in_dim, out_dim, dropout, residual, edge_dim, equivstable_pe=False, **kwargs): super().__init__(**kwargs) self.A = pyg_nn.Linear(in_dim, out_dim, bias=True) self.B = pyg_nn.Linear(in_dim, out_dim, bias=True) self.C = pyg_nn.Linear(edge_dim, out_dim, bias=True) self.D = pyg_nn.Linear(in_dim, out_dim, bias=True) self.E = pyg_nn.Linear(in_dim, out_dim, bias=True) # 【核心修改】如果边特征的输入输出维度不同，则添加一个投射层 self.residual_e_proj = None if edge_dim != out_dim: self.residual_e_proj = pyg_nn.Linear(edge_dim, out_dim, bias=True) # Handling for Equivariant and Stable PE using LapPE # ICLR 2022 https://openreview.net/pdf?id=e95i1IHcWj self.EquivStablePE = equivstable_pe if self.EquivStablePE: self.mlp_r_ij = nn.Sequential( nn.Linear(1, out_dim), nn.ReLU(), nn.Linear(out_dim, 1), nn.Sigmoid()) self.bn_node_x = nn.BatchNorm1d(out_dim) self.bn_edge_e = nn.BatchNorm1d(out_dim) self.dropout = dropout self.residual = residual self.e = None def forward(self, batch): x, e, edge_index = batch.x, batch.edge_attr, batch.edge_index \u0026#34;\u0026#34;\u0026#34; x : [n_nodes, in_dim] e : [n_edges, in_dim] edge_index : [2, n_edges] \u0026#34;\u0026#34;\u0026#34; if self.residual: x_in = x e_in = e Ax = self.A(x) Bx = self.B(x) Ce = self.C(e) Dx = self.D(x) Ex = self.E(x) # Handling for Equivariant and Stable PE using LapPE # ICLR 2022 https://openreview.net/pdf?id=e95i1IHcWj pe_LapPE = batch.pe_EquivStableLapPE if self.EquivStablePE else None x, e = self.propagate(edge_index, Bx=Bx, Dx=Dx, Ex=Ex, Ce=Ce, e=e, Ax=Ax, PE=pe_LapPE) x = self.bn_node_x(x) e = self.bn_edge_e(e) x = F.relu(x) e = F.relu(e) x = F.dropout(x, self.dropout, training=self.training) e = F.dropout(e, self.dropout, training=self.training) if self.residual: x = x_in + x if self.residual_e_proj is not None: e_in = self.residual_e_proj(e_in) # 将 76 维的 e_in 投射到 176 维 e = e_in + e batch.x = x batch.edge_attr = e return batch def message(self, Dx_i, Ex_j, PE_i, PE_j, Ce): \u0026#34;\u0026#34;\u0026#34; {}x_i : [n_edges, out_dim] {}x_j : [n_edges, out_dim] {}e : [n_edges, out_dim] \u0026#34;\u0026#34;\u0026#34; e_ij = Dx_i + Ex_j + Ce sigma_ij = torch.sigmoid(e_ij) # Handling for Equivariant and Stable PE using LapPE # ICLR 2022 https://openreview.net/pdf?id=e95i1IHcWj if self.EquivStablePE: r_ij = ((PE_i - PE_j) ** 2).sum(dim=-1, keepdim=True) r_ij = self.mlp_r_ij(r_ij) # the MLP is 1 dim --\u0026gt; hidden_dim --\u0026gt; 1 dim sigma_ij = sigma_ij * r_ij self.e = e_ij return sigma_ij def aggregate(self, sigma_ij, index, Bx_j, Bx): \u0026#34;\u0026#34;\u0026#34; sigma_ij : [n_edges, out_dim] ; is the output from message() function index : [n_edges] {}x_j : [n_edges, out_dim] \u0026#34;\u0026#34;\u0026#34; dim_size = Bx.shape[0] # or None ?? \u0026lt;--- Double check this sum_sigma_x = sigma_ij * Bx_j numerator_eta_xj = scatter(sum_sigma_x, index, 0, None, dim_size, reduce=\u0026#39;sum\u0026#39;) sum_sigma = sigma_ij denominator_eta_xj = scatter(sum_sigma, index, 0, None, dim_size, reduce=\u0026#39;sum\u0026#39;) out = numerator_eta_xj / (denominator_eta_xj + 1e-6) return out def update(self, aggr_out, Ax): \u0026#34;\u0026#34;\u0026#34; aggr_out : [n_nodes, out_dim] ; is the output from aggregate() function after the aggregation {}x : [n_nodes, out_dim] \u0026#34;\u0026#34;\u0026#34; x = Ax + aggr_out e_out = self.e del self.e return x, e_out @register_layer(\u0026#39;gatedgcnconv\u0026#39;) class GatedGCNGraphGymLayer(nn.Module): \u0026#34;\u0026#34;\u0026#34;GatedGCN layer. Residual Gated Graph ConvNets https://arxiv.org/pdf/1711.07553.pdf \u0026#34;\u0026#34;\u0026#34; def __init__(self, layer_config: LayerConfig, **kwargs): super().__init__() self.model = GatedGCNLayer(in_dim=layer_config.dim_in, out_dim=layer_config.dim_out, dropout=0., # Dropout is handled by GraphGym\u0026#39;s `GeneralLayer` wrapper residual=False, # Residual connections are handled by GraphGym\u0026#39;s `GNNStackStage` wrapper **kwargs) def forward(self, batch): return self.model(batch) 实验测试 根据同样50个epoch和数据集、split训练后进行测试，计算recovery和scc如下：\n纳尼？情报系假嘚？ 怎么会比sota指标低这么多，全线的低？我好菜。\n于是问了问谷歌哈基米（gemini），也没感觉什么所以然来。可能是因为gpslayer和gatedgnn本来就不是为了rna识别而设计的，所以有一些逻辑可能直接拿来用也不是很ok。\nemm，其实multi-scale attention也挺好对不啦？得了，明天汇报完再说吧。怎么论文里全是attention之类的奇奇怪怪的。\nTransformer GVP + PreLN 在0.0001和0.0002学习率分别利用早停法训练，作者没有用早停法，我们设置200个epoch，每4个epoch进行一次validation，连续20个epoch不更新就停止。\n于是，trainers.py需要修改为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 import os import numpy as np from tqdm import tqdm import wandb from sklearn.metrics import confusion_matrix import torch from torch.optim import Adam from torch.optim.lr_scheduler import ReduceLROnPlateau from src.evaluator import evaluate from src.constants import NUM_TO_LETTER def train( config, model, train_loader, val_loader, test_loader, device ): \u0026#34;\u0026#34;\u0026#34; Train RNA inverse folding model using the specified config and data loaders. Args: config (dict): wandb configuration dictionary model (nn.Module): RNA inverse folding model to be trained train_loader (DataLoader): training data loader val_loader (DataLoader): validation data loader test_loader (DataLoader): test data loader device (torch.device): device to train the model on \u0026#34;\u0026#34;\u0026#34; # Initialise loss function train_loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=config.label_smoothing) eval_loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.0) # Initialise optimizer and scheduler lr = config.lr optimizer = Adam(model.parameters(), lr) scheduler = ReduceLROnPlateau(optimizer, mode=\u0026#39;max\u0026#39;, factor=0.9, patience=1, min_lr=0.00001) if device.type == \u0026#39;xpu\u0026#39;: import intel_extension_for_pytorch as ipex model, optimizer = ipex.optimize(model, optimizer=optimizer) #======= # Initialise save directory save_dir = os.path.join(os.path.dirname(__file__), \u0026#34;..\u0026#34;, \u0026#34;mymodel\u0026#34;) #save_dir = os.path.abspath(save_dir) os.makedirs(save_dir, exist_ok=True) #====== # Initialise lookup table mapping integers to nucleotides lookup = train_loader.dataset.featurizer.num_to_letter # Initialise best checkpoint information best_epoch, best_val_loss, best_val_acc = -1, np.inf, 0 patience = getattr(config, \u0026#39;patience\u0026#39;, 5) early_stopping_counter = 0 ################################## # Training loop over mini-batches ################################## for epoch in range(config.epochs): # Training iteration model.train() train_loss, train_acc, train_confusion = loop(model, train_loader, train_loss_fn, optimizer, device) print_and_log(epoch, train_loss, train_acc, train_confusion, lr=lr, mode=\u0026#34;train\u0026#34;, lookup=lookup) if epoch % config.val_every == 0 or epoch == config.epochs - 1: model.eval() with torch.no_grad(): # Evaluate on validation set val_loss, val_acc, val_confusion = loop(model, val_loader, eval_loss_fn, None, device) print_and_log(epoch, val_loss, val_acc, val_confusion, mode=\u0026#34;val\u0026#34;, lookup=lookup) # LR scheduler step scheduler.step(val_acc) lr = optimizer.param_groups[0][\u0026#39;lr\u0026#39;] if val_acc \u0026gt; best_val_acc: # ============== 修改: 早停法逻辑 ============== print(f\u0026#34;Validation accuracy improved ({best_val_acc:.4f} --\u0026gt; {val_acc:.4f}). Saving model...\u0026#34;) early_stopping_counter = 0 # 重置计数器 # ============================================ # Update best checkpoint best_epoch, best_val_loss, best_val_acc = epoch, val_loss, val_acc # Evaluate on test set test_loss, test_acc, test_confusion = loop(model, test_loader, eval_loss_fn, None, device) print_and_log(epoch, test_loss, test_acc, test_confusion, mode=\u0026#34;test\u0026#34;, lookup=lookup) # Update wandb summary metrics wandb.run.summary[\u0026#34;best_epoch\u0026#34;] = best_epoch wandb.run.summary[\u0026#34;best_val_perp\u0026#34;] = np.exp(best_val_loss) wandb.run.summary[\u0026#34;best_val_acc\u0026#34;] = best_val_acc wandb.run.summary[\u0026#34;best_test_perp\u0026#34;] = np.exp(test_loss) wandb.run.summary[\u0026#34;best_test_acc\u0026#34;] = test_acc if config.save: # Save best checkpoint checkpoint_path = os.path.join(save_dir, \u0026#34;best_checkpoint.h5\u0026#34;) torch.save(model.state_dict(), checkpoint_path) wandb.run.summary[\u0026#34;best_checkpoint\u0026#34;] = checkpoint_path else: # ============== 新增: 早停法逻辑 ============== early_stopping_counter += 1 print(f\u0026#34;Validation accuracy did not improve. EarlyStopping counter: {early_stopping_counter}/{patience}\u0026#34;) if early_stopping_counter \u0026gt;= patience: print(f\u0026#34;Early stopping triggered after {patience} epochs of no improvement.\u0026#34;) break # 跳出训练循环 # ============================================ if config.save: # Save current epoch checkpoint torch.save(model.state_dict(), os.path.join(save_dir, \u0026#34;current_checkpoint.h5\u0026#34;)) # End of training (可能是跑满epochs结束，也可能是被早停法break) print(\u0026#34;--- End of Training ---\u0026#34;) if config.save: # Evaluate best checkpoint print(f\u0026#34;EVALUATION: loading {os.path.join(save_dir, \u0026#39;best_checkpoint.h5\u0026#39;)} (epoch {best_epoch})\u0026#34;) # 确保模型存在，如果训练过早停止可能没有保存过best checkpoint best_checkpoint_path = os.path.join(save_dir, \u0026#39;best_checkpoint.h5\u0026#39;) if not os.path.exists(best_checkpoint_path): print(\u0026#34;No best checkpoint was saved. Skipping final evaluation.\u0026#34;) return def loop(model, dataloader, loss_fn, optimizer=None, device=\u0026#39;cpu\u0026#39;): \u0026#34;\u0026#34;\u0026#34; Training loop for a single epoch over the data loader. Args: model (nn.Module): RNA inverse folding model dataloader (DataLoader): data loader for the current epoch loss_fn (nn.Module): loss function to compute the loss optimizer (torch.optim): optimizer to update model parameters device (torch.device): device to train the model on Note: This function is used for both training and evaluation loops. Not passing an optimizer will run the model in evaluation mode. Returns: float: average loss over the epoch float: average accuracy over the epoch np.ndarray: confusion matrix over the epoch \u0026#34;\u0026#34;\u0026#34; confusion = np.zeros((model.out_dim, model.out_dim)) total_loss, total_correct, total_count = 0, 0, 0 t = tqdm(dataloader) for batch in t: if optimizer: optimizer.zero_grad() # move batch to device batch = batch.to(device) try: logits = model(batch) except RuntimeError as e: if \u0026#34;CUDA out of memory\u0026#34; not in str(e): raise(e) print(\u0026#39;Skipped batch due to OOM\u0026#39;, flush=True) for p in model.parameters(): if p.grad is not None: del p.grad # free some memory torch.cuda.empty_cache() continue # compute loss loss_value = loss_fn(logits, batch.seq) if optimizer: # backpropagate loss and update parameters loss_value.backward() optimizer.step() # update metrics num_nodes = int(batch.seq.size(0)) total_loss += float(loss_value.item()) * num_nodes total_count += num_nodes pred = torch.argmax(logits, dim=-1).detach().cpu().numpy() true = batch.seq.detach().cpu().numpy() total_correct += (pred == true).sum() confusion += confusion_matrix(true, pred, labels=range(model.out_dim)) t.set_description(\u0026#34;%.5f\u0026#34; % float(total_loss/total_count)) return total_loss / total_count, total_correct / total_count, confusion def print_and_log( epoch, loss, acc, confusion, recovery = None, lr = None, mode = \u0026#34;train\u0026#34;, lookup = NUM_TO_LETTER, # reverse of {\u0026#39;A\u0026#39;: 0, \u0026#39;G\u0026#39;: 1, \u0026#39;C\u0026#39;: 2, \u0026#39;U\u0026#39;: 3} ): # Create log string and wandb metrics dict log_str = f\u0026#34;\\nEPOCH {epoch} {mode.upper()} loss: {loss:.4f} perp: {np.exp(loss):.4f} acc: {acc:.4f}\u0026#34; wandb_metrics = { f\u0026#34;{mode}/loss\u0026#34;: loss, f\u0026#34;{mode}/perp\u0026#34;: np.exp(loss), f\u0026#34;{mode}/acc\u0026#34;: acc, \u0026#34;epoch\u0026#34;: epoch } if lr is not None: # Add learning rate to loggers log_str += f\u0026#34; lr: {lr:.6f}\u0026#34; wandb_metrics[f\u0026#34;lr\u0026#34;] = lr if recovery is not None: # Add mean sequence recovery to loggers log_str += f\u0026#34; rec: {np.mean(recovery):.4f}\u0026#34; wandb_metrics[f\u0026#34;{mode}/recovery\u0026#34;] = np.mean(recovery) print(log_str) print_confusion(confusion, lookup=lookup) wandb.log(wandb_metrics) def print_confusion(mat, lookup): counts = mat.astype(np.int32) mat = (counts.T / counts.sum(axis=-1, keepdims=True).T).T mat = np.round(mat * 1000).astype(np.int32) res = \u0026#39;\\n\u0026#39; for i in range(len(lookup.keys())): res += \u0026#39;\\t{}\u0026#39;.format(lookup[i]) res += \u0026#39;\\tCount\\n\u0026#39; for i in range(len(lookup.keys())): res += \u0026#39;{}\\t\u0026#39;.format(lookup[i]) res += \u0026#39;\\t\u0026#39;.join(\u0026#39;{}\u0026#39;.format(n) for n in mat[i]) res += \u0026#39;\\t{}\\n\u0026#39;.format(sum(counts[i])) print(res) 模型加入了layers.py:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 ################################################################ # Generalisation of Geometric Vector Perceptron, Jing et al. # for explicit multi-state biomolecule representation learning. # Original repository: https://github.com/drorlab/gvp-pytorch # MODIFIED: Added HybridGVPTransformerLayer for deep fusion of # local geometric message passing and global self-attention, # with a robust Pre-LN Transformer block structure. ################################################################ import functools import torch from torch import nn import torch.nn.functional as F import torch_geometric from torch_geometric.nn import MessagePassing from torch_scatter import scatter_add ######################################################################### # 新增: 一个标准的 Position-wise Feed-Forward Network class PositionwiseFeedForward(nn.Module): \u0026#39;\u0026#39;\u0026#39; A two-layer Feed-Forward-Network. \u0026#39;\u0026#39;\u0026#39; def __init__(self, d_in, d_hid, dropout=0.1): super().__init__() self.w_1 = nn.Linear(d_in, d_hid) self.w_2 = nn.Linear(d_hid, d_in) self.dropout = nn.Dropout(dropout) self.activation = F.silu def forward(self, x): return self.w_2(self.dropout(self.activation(self.w_1(x)))) # 新增: 我们设计的核心混合层 (Hybrid Layer) - 优化版 class HybridGVPTransformerLayer(nn.Module): \u0026#39;\u0026#39;\u0026#39; 将GVP-GNN与Graph Transformer思想深度融合的混合层。 遵循标准的Pre-LN Transformer Block结构，以增强训练稳定性。 \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_dims, edge_dims, num_attn_head=4, n_message=3, drop_rate=.1, activations=(F.silu, torch.sigmoid), vector_gate=True, ): super(HybridGVPTransformerLayer, self).__init__() # 1. 几何局部路径：使用原始的MultiGVPConv作为消息传递模块 self.gvp_conv = MultiGVPConv(node_dims, node_dims, edge_dims, n_message, aggr=\u0026#34;mean\u0026#34;, activations=activations, vector_gate=vector_gate) self.dropout_gvp = Dropout(drop_rate) # 2. 全局交互路径 (Transformer Block) # 2.1. Attention 子层 self.norm_attn = nn.LayerNorm(node_dims[0]) # Pre-LN: Attention前的Norm (只作用于标量) self.attention = nn.MultiheadAttention( embed_dim=node_dims[0], num_heads=num_attn_head, dropout=drop_rate, batch_first=True ) self.dropout_attn = nn.Dropout(drop_rate) # 2.2. FFN 子层 self.norm_ffn = nn.LayerNorm(node_dims[0]) # Pre-LN: FFN前的Norm (只作用于标量) self.ffn = PositionwiseFeedForward(d_in=node_dims[0], d_hid=node_dims[0] * 4, dropout=drop_rate) self.dropout_ffn = nn.Dropout(drop_rate) def forward(self, x, edge_index, edge_attr): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor`. s shape: (n_nodes, n_conf, d_s), V shape: (n_nodes, n_conf, d_v, 3) :param edge_index: array of shape [2, n_edges] :param edge_attr: tuple (s, V) of `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; # --- 步骤1: 几何感知的局部消息传递 (GVP Path) --- dh_local = self.gvp_conv(x, edge_index, edge_attr) x_local = tuple_sum(x, self.dropout_gvp(dh_local)) s_local, v_local = x_local # --- 步骤2: 标准的Transformer Block (作用于标量特征) --- # 2.1 Attention Sub-layer with Pre-LN and Residual Connection s_res_attn = s_local s_norm_attn = self.norm_attn(s_local) n_nodes, n_conf, d_s = s_norm_attn.shape s_reshaped = s_norm_attn.permute(1, 0, 2) # -\u0026gt; (n_conf, n_nodes, d_s) s_attn_out, _ = self.attention(s_reshaped, s_reshaped, s_reshaped) s_attn_out = s_attn_out.permute(1, 0, 2) # -\u0026gt; (n_nodes, n_conf, d_s) s_after_attn = s_res_attn + self.dropout_attn(s_attn_out) # 2.2 Feed-Forward Sub-layer with Pre-LN and Residual Connection s_res_ffn = s_after_attn s_norm_ffn = self.norm_ffn(s_after_attn) s_ffn_out = self.ffn(s_norm_ffn) s_final = s_res_ffn + self.dropout_ffn(s_ffn_out) # --- 步骤3: 最终输出 --- # 矢量特征直接继承自局部路径 v_final = v_local return (s_final, v_final) ######################################################################### class GVPConvLayer(nn.Module): \u0026#39;\u0026#39;\u0026#39; Full graph convolution / message passing layer with Geometric Vector Perceptrons. Residually updates node embeddings with aggregated incoming messages, applies a pointwise feedforward network to node embeddings, and returns updated node embeddings. To only compute the aggregated messages, see `GVPConv`. :param node_dims: node embedding dimensions (n_scalar, n_vector) :param edge_dims: input edge embedding dimensions (n_scalar, n_vector) :param n_message: number of GVPs to use in message function :param n_feedforward: number of GVPs to use in feedforward function :param drop_rate: drop probability in all dropout layers :param autoregressive: if `True`, this `GVPConvLayer` will be used with a different set of input node embeddings for messages where src \u0026gt;= dst :param activations: tuple of functions (scalar_act, vector_act) to use in GVPs :param vector_gate: whether to use vector gating. (vector_act will be used as sigma^+ in vector gating if `True`) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_dims, edge_dims, n_message=3, n_feedforward=2, drop_rate=.1, autoregressive=False, activations=(F.silu, torch.sigmoid), vector_gate=True, residual=True, norm_first=False, ): super(GVPConvLayer, self).__init__() self.conv = GVPConv(node_dims, node_dims, edge_dims, n_message, aggr=\u0026#34;add\u0026#34; if autoregressive else \u0026#34;mean\u0026#34;, activations=activations, vector_gate=vector_gate) GVP_ = functools.partial(GVP, activations=activations, vector_gate=vector_gate) self.norm = nn.ModuleList([LayerNorm(node_dims) for _ in range(2)]) self.dropout = nn.ModuleList([Dropout(drop_rate) for _ in range(2)]) ff_func = [] if n_feedforward == 1: ff_func.append(GVP_(node_dims, node_dims)) else: hid_dims = 4*node_dims[0], 2*node_dims[1] ff_func.append(GVP_(node_dims, hid_dims)) for i in range(n_feedforward-2): ff_func.append(GVP_(hid_dims, hid_dims)) ff_func.append(GVP_(hid_dims, node_dims, activations=(None, None))) self.ff_func = nn.Sequential(*ff_func) self.residual = residual self.norm_first = norm_first def forward(self, x, edge_index, edge_attr, autoregressive_x=None, node_mask=None): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor` :param edge_index: array of shape [2, n_edges] :param edge_attr: tuple (s, V) of `torch.Tensor` :param autoregressive_x: tuple (s, V) of `torch.Tensor`. If not `None`, will be used as src node embeddings for forming messages where src \u0026gt;= dst. The current node embeddings `x` will still be the base of the update and the pointwise feedforward. :param node_mask: array of type `bool` to index into the first dim of node embeddings (s, V). If not `None`, only these nodes will be updated. \u0026#39;\u0026#39;\u0026#39; if autoregressive_x is not None: src, dst = edge_index mask = src \u0026lt; dst edge_index_forward = edge_index[:, mask] edge_index_backward = edge_index[:, ~mask] edge_attr_forward = tuple_index(edge_attr, mask) edge_attr_backward = tuple_index(edge_attr, ~mask) dh = tuple_sum( self.conv(x, edge_index_forward, edge_attr_forward), self.conv(autoregressive_x, edge_index_backward, edge_attr_backward) ) count = scatter_add(torch.ones_like(dst), dst, dim_size=dh[0].size(0)).clamp(min=1).unsqueeze(-1) dh = dh[0] / count, dh[1] / count.unsqueeze(-1) else: if self.norm_first: dh = self.conv(self.norm[0](x), edge_index, edge_attr) else: dh = self.conv(x, edge_index, edge_attr) if node_mask is not None: x_ = x x, dh = tuple_index(x, node_mask), tuple_index(dh, node_mask) if self.norm_first: x = tuple_sum(x, self.dropout[0](dh)) dh = self.ff_func(self.norm[1](x)) x = tuple_sum(x, self.dropout[1](dh)) else: x = self.norm[0](tuple_sum(x, self.dropout[0](dh))) if self.residual else dh dh = self.ff_func(x) x = self.norm[1](tuple_sum(x, self.dropout[1](dh))) if self.residual else dh if node_mask is not None: x_[0][node_mask], x_[1][node_mask] = x[0], x[1] x = x_ return x class GVPConv(MessagePassing): \u0026#39;\u0026#39;\u0026#39; Graph convolution / message passing with Geometric Vector Perceptrons. Takes in a graph with node and edge embeddings, and returns new node embeddings. This does NOT do residual updates and pointwise feedforward layers ---see `GVPConvLayer`. :param in_dims: input node embedding dimensions (n_scalar, n_vector) :param out_dims: output node embedding dimensions (n_scalar, n_vector) :param edge_dims: input edge embedding dimensions (n_scalar, n_vector) :param n_layers: number of GVPs in the message function :param module_list: preconstructed message function, overrides n_layers :param aggr: should be \u0026#34;add\u0026#34; if some incoming edges are masked, as in a masked autoregressive decoder architecture, otherwise \u0026#34;mean\u0026#34; :param activations: tuple of functions (scalar_act, vector_act) to use in GVPs :param vector_gate: whether to use vector gating. (vector_act will be used as sigma^+ in vector gating if `True`) \u0026#39;\u0026#39;\u0026#39; def __init__(self, in_dims, out_dims, edge_dims, n_layers=3, module_list=None, aggr=\u0026#34;mean\u0026#34;, activations=(F.silu, torch.sigmoid), vector_gate=True): super(GVPConv, self).__init__(aggr=aggr) self.si, self.vi = in_dims self.so, self.vo = out_dims self.se, self.ve = edge_dims GVP_ = functools.partial(GVP, activations=activations, vector_gate=vector_gate) module_list = module_list or [] if not module_list: if n_layers == 1: module_list.append( GVP_((2*self.si + self.se, 2*self.vi + self.ve), (self.so, self.vo))) else: module_list.append( GVP_((2*self.si + self.se, 2*self.vi + self.ve), out_dims) ) for i in range(n_layers - 2): module_list.append(GVP_(out_dims, out_dims)) module_list.append(GVP_(out_dims, out_dims, activations=(None, None))) self.message_func = nn.Sequential(*module_list) def forward(self, x, edge_index, edge_attr): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor` :param edge_index: array of shape [2, n_edges] :param edge_attr: tuple (s, V) of `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; x_s, x_v = x message = self.propagate(edge_index, s=x_s, v=x_v.contiguous().view(x_v.shape[0], x_v.shape[1] * 3), edge_attr=edge_attr) return _split(message, self.vo) def message(self, s_i, v_i, s_j, v_j, edge_attr): v_j = v_j.view(v_j.shape[0], v_j.shape[1]//3, 3) v_i = v_i.view(v_i.shape[0], v_i.shape[1]//3, 3) message = tuple_cat((s_j, v_j), edge_attr, (s_i, v_i)) message = self.message_func(message) return _merge(*message) ######################################################################### class MultiGVPConvLayer(nn.Module): \u0026#39;\u0026#39;\u0026#39; GVPConvLayer for handling multiple conformations (encoder-only) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_dims, edge_dims, n_message=3, n_feedforward=2, drop_rate=.1, activations=(F.silu, torch.sigmoid), vector_gate=True, residual=True, norm_first=False, ): super(MultiGVPConvLayer, self).__init__() self.conv = MultiGVPConv(node_dims, node_dims, edge_dims, n_message, aggr=\u0026#34;mean\u0026#34;, activations=activations, vector_gate=vector_gate) GVP_ = functools.partial(GVP, activations=activations, vector_gate=vector_gate) self.norm = nn.ModuleList([LayerNorm(node_dims) for _ in range(2)]) self.dropout = nn.ModuleList([Dropout(drop_rate) for _ in range(2)]) ff_func = [] if n_feedforward == 1: ff_func.append(GVP_(node_dims, node_dims)) else: hid_dims = 4*node_dims[0], 2*node_dims[1] ff_func.append(GVP_(node_dims, hid_dims)) for i in range(n_feedforward-2): ff_func.append(GVP_(hid_dims, hid_dims)) ff_func.append(GVP_(hid_dims, node_dims, activations=(None, None))) self.ff_func = nn.Sequential(*ff_func) self.residual = residual self.norm_first = norm_first def forward(self, x, edge_index, edge_attr): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor` :param edge_index: array of shape [2, n_edges] :param edge_attr: tuple (s, V) of `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; if self.norm_first: dh = self.conv(self.norm[0](x), edge_index, edge_attr) x = tuple_sum(x, self.dropout[0](dh)) dh = self.ff_func(self.norm[1](x)) x = tuple_sum(x, self.dropout[1](dh)) else: dh = self.conv(x, edge_index, edge_attr) x = self.norm[0](tuple_sum(x, self.dropout[0](dh))) if self.residual else dh dh = self.ff_func(x) x = self.norm[1](tuple_sum(x, self.dropout[1](dh))) if self.residual else dh return x class MultiGVPConv(MessagePassing): \u0026#39;\u0026#39;\u0026#39; GVPConv for handling multiple conformations \u0026#39;\u0026#39;\u0026#39; def __init__(self, in_dims, out_dims, edge_dims, n_layers=3, module_list=None, aggr=\u0026#34;mean\u0026#34;, activations=(F.silu, torch.sigmoid), vector_gate=True): super(MultiGVPConv, self).__init__(aggr=aggr) self.si, self.vi = in_dims self.so, self.vo = out_dims self.se, self.ve = edge_dims GVP_ = functools.partial(GVP, activations=activations, vector_gate=vector_gate) module_list = module_list or [] if not module_list: if n_layers == 1: module_list.append( GVP_((2*self.si + self.se, 2*self.vi + self.ve), (self.so, self.vo))) else: module_list.append( GVP_((2*self.si + self.se, 2*self.vi + self.ve), out_dims) ) for i in range(n_layers - 2): module_list.append(GVP_(out_dims, out_dims)) module_list.append(GVP_(out_dims, out_dims, activations=(None, None))) self.message_func = nn.Sequential(*module_list) def forward(self, x, edge_index, edge_attr): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor` :param edge_index: array of shape [2, n_edges] :param edge_attr: tuple (s, V) of `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; x_s, x_v = x n_conf = x_s.shape[1] # x_s: [n_nodes, n_conf, d] -\u0026gt; [n_nodes, n_conf * d] x_s = x_s.contiguous().view(x_s.shape[0], x_s.shape[1] * x_s.shape[2]) # x_v: [n_nodes, n_conf, d, 3] -\u0026gt; [n_nodes, n_conf * d * 3] x_v = x_v.contiguous().view(x_v.shape[0], x_v.shape[1] * x_v.shape[2] * 3) message = self.propagate(edge_index, s=x_s, v=x_v, edge_attr=edge_attr) return _split_multi(message, self.so, self.vo, n_conf) def message(self, s_i, v_i, s_j, v_j, edge_attr): # [n_nodes, n_conf * d] -\u0026gt; [n_nodes, n_conf, d] s_i = s_i.view(s_i.shape[0], s_i.shape[1]//self.si, self.si) s_j = s_j.view(s_j.shape[0], s_j.shape[1]//self.si, self.si) # [n_nodes, n_conf * d * 3] -\u0026gt; [n_nodes, n_conf, d, 3] v_i = v_i.view(v_i.shape[0], v_i.shape[1]//(self.vi * 3), self.vi, 3) v_j = v_j.view(v_j.shape[0], v_j.shape[1]//(self.vi * 3), self.vi, 3) message = tuple_cat((s_j, v_j), edge_attr, (s_i, v_i)) message = self.message_func(message) return _merge_multi(*message) ######################################################################### class GVP(nn.Module): \u0026#39;\u0026#39;\u0026#39; Geometric Vector Perceptron. See manuscript and README.md for more details. :param in_dims: tuple (n_scalar, n_vector) :param out_dims: tuple (n_scalar, n_vector) :param h_dim: intermediate number of vector channels, optional :param activations: tuple of functions (scalar_act, vector_act) :param vector_gate: whether to use vector gating. (vector_act will be used as sigma^+ in vector gating if `True`) \u0026#39;\u0026#39;\u0026#39; def __init__(self, in_dims, out_dims, h_dim=None, activations=(F.silu, torch.sigmoid), vector_gate=True): super(GVP, self).__init__() self.si, self.vi = in_dims self.so, self.vo = out_dims self.vector_gate = vector_gate if self.vi: self.h_dim = h_dim or max(self.vi, self.vo) self.wh = nn.Linear(self.vi, self.h_dim, bias=False) self.ws = nn.Linear(self.h_dim + self.si, self.so) if self.vo: self.wv = nn.Linear(self.h_dim, self.vo, bias=False) if self.vector_gate: self.wsv = nn.Linear(self.so, self.vo) else: self.ws = nn.Linear(self.si, self.so) self.scalar_act, self.vector_act = activations self.dummy_param = nn.Parameter(torch.empty(0)) def forward(self, x): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor`, or (if vectors_in is 0), a single `torch.Tensor` :return: tuple (s, V) of `torch.Tensor`, or (if vectors_out is 0), a single `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; if self.vi: s, v = x v = torch.transpose(v, -1, -2) vh = self.wh(v) vn = _norm_no_nan(vh, axis=-2) s = self.ws(torch.cat([s, vn], -1)) if self.vo: v = self.wv(vh) v = torch.transpose(v, -1, -2) if self.vector_gate: if self.vector_act: gate = self.wsv(self.vector_act(s)) else: gate = self.wsv(s) v = v * torch.sigmoid(gate).unsqueeze(-1) elif self.vector_act: v = v * self.vector_act( _norm_no_nan(v, axis=-1, keepdims=True)) else: s = self.ws(x) if self.vo: v = torch.zeros(s.shape[0], self.vo, 3, device=self.dummy_param.device) if self.scalar_act: s = self.scalar_act(s) return (s, v) if self.vo else s ######################################################################### class _VDropout(nn.Module): \u0026#39;\u0026#39;\u0026#39; Vector channel dropout where the elements of each vector channel are dropped together. \u0026#39;\u0026#39;\u0026#39; def __init__(self, drop_rate): super(_VDropout, self).__init__() self.drop_rate = drop_rate self.dummy_param = nn.Parameter(torch.empty(0)) def forward(self, x): \u0026#39;\u0026#39;\u0026#39; :param x: `torch.Tensor` corresponding to vector channels \u0026#39;\u0026#39;\u0026#39; device = self.dummy_param.device if not self.training: return x mask = torch.bernoulli( (1 - self.drop_rate) * torch.ones(x.shape[:-1], device=device) ).unsqueeze(-1) x = mask * x / (1 - self.drop_rate) return x class Dropout(nn.Module): \u0026#39;\u0026#39;\u0026#39; Combined dropout for tuples (s, V). Takes tuples (s, V) as input and as output. \u0026#39;\u0026#39;\u0026#39; def __init__(self, drop_rate): super(Dropout, self).__init__() self.sdropout = nn.Dropout(drop_rate) self.vdropout = _VDropout(drop_rate) def forward(self, x): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor`, or single `torch.Tensor` (will be assumed to be scalar channels) \u0026#39;\u0026#39;\u0026#39; if type(x) is torch.Tensor: return self.sdropout(x) s, v = x return self.sdropout(s), self.vdropout(v) class LayerNorm(nn.Module): \u0026#39;\u0026#39;\u0026#39; Combined LayerNorm for tuples (s, V). Takes tuples (s, V) as input and as output. \u0026#39;\u0026#39;\u0026#39; def __init__(self, dims): super(LayerNorm, self).__init__() self.s, self.v = dims self.scalar_norm = nn.LayerNorm(self.s) def forward(self, x): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor`, or single `torch.Tensor` (will be assumed to be scalar channels) \u0026#39;\u0026#39;\u0026#39; if not self.v: return self.scalar_norm(x) s, v = x vn = _norm_no_nan(v, axis=-1, keepdims=True, sqrt=False) vn = torch.sqrt(torch.mean(vn, dim=-2, keepdim=True)) return self.scalar_norm(s), v / vn def tuple_sum(*args): \u0026#39;\u0026#39;\u0026#39; Sums any number of tuples (s, V) elementwise. \u0026#39;\u0026#39;\u0026#39; return tuple(map(sum, zip(*args))) def tuple_cat(*args, dim=-1): \u0026#39;\u0026#39;\u0026#39; Concatenates any number of tuples (s, V) elementwise. :param dim: dimension along which to concatenate when viewed as the `dim` index for the scalar-channel tensors. This means that `dim=-1` will be applied as `dim=-2` for the vector-channel tensors. \u0026#39;\u0026#39;\u0026#39; dim %= len(args[0][0].shape) s_args, v_args = list(zip(*args)) return torch.cat(s_args, dim=dim), torch.cat(v_args, dim=dim) def tuple_index(x, idx): \u0026#39;\u0026#39;\u0026#39; Indexes into a tuple (s, V) along the first dimension. :param idx: any object which can be used to index into a `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; return x[0][idx], x[1][idx] def randn(n, dims, device=\u0026#34;cpu\u0026#34;): \u0026#39;\u0026#39;\u0026#39; Returns random tuples (s, V) drawn elementwise from a normal distribution. :param n: number of data points :param dims: tuple of dimensions (n_scalar, n_vector) :return: (s, V) with s.shape = (n, n_scalar) and V.shape = (n, n_vector, 3) \u0026#39;\u0026#39;\u0026#39; return torch.randn(n, dims[0], device=device), \\ torch.randn(n, dims[1], 3, device=device) def _norm_no_nan(x, axis=-1, keepdims=False, eps=1e-8, sqrt=True): \u0026#39;\u0026#39;\u0026#39; L2 norm of tensor clamped above a minimum value `eps`. :param sqrt: if `False`, returns the square of the L2 norm \u0026#39;\u0026#39;\u0026#39; out = torch.clamp(torch.sum(torch.square(x), axis, keepdims), min=eps) return torch.sqrt(out) if sqrt else out def _split(x, nv): \u0026#39;\u0026#39;\u0026#39; Splits a merged representation of (s, V) back into a tuple. Should be used only with `_merge(s, V)` and only if the tuple representation cannot be used. :param x: the `torch.Tensor` returned from `_merge` :param nv: the number of vector channels in the input to `_merge` \u0026#39;\u0026#39;\u0026#39; s = x[..., :-3 * nv] v = x[..., -3 * nv:].contiguous().view(x.shape[0], nv, 3) return s, v def _merge(s, v): \u0026#39;\u0026#39;\u0026#39; Merges a tuple (s, V) into a single `torch.Tensor`, where the vector channels are flattened and appended to the scalar channels. Should be used only if the tuple representation cannot be used. Use `_split(x, nv)` to reverse. \u0026#39;\u0026#39;\u0026#39; v = v.contiguous().view(v.shape[0], v.shape[1] * 3) return torch.cat([s, v], -1) def _split_multi(x, ns, nv, n_conf=5): \u0026#39;\u0026#39;\u0026#39; _split for multiple conformers \u0026#39;\u0026#39;\u0026#39; s = x[..., :-3 * nv * n_conf].contiguous().view(x.shape[0], n_conf, ns) v = x[..., -3 * nv * n_conf:].contiguous().view(x.shape[0], n_conf, nv, 3) return s, v def _merge_multi(s, v): \u0026#39;\u0026#39;\u0026#39; _merge for multiple conformers \u0026#39;\u0026#39;\u0026#39; # s: [n_nodes, n_conf, d] -\u0026gt; [n_nodes, n_conf * d] s = s.contiguous().view(s.shape[0], s.shape[1] * s.shape[2]) # v: [n_nodes, n_conf, d, 3] -\u0026gt; [n_nodes, n_conf * d * 3] v = v.contiguous().view(v.shape[0], v.shape[1] * v.shape[2] * 3) return torch.cat([s, v], -1) 然后更新models.py，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 ################################################################ # Generalisation of Geometric Vector Perceptron, Jing et al. # for explicit multi-state biomolecule representation learning. # Original repository: https://github.com/drorlab/gvp-pytorch ################################################################ from typing import Optional import torch from torch import nn import torch.nn.functional as F from torch.distributions import Categorical import torch_geometric from src.layers import * class AutoregressiveMultiGNNv1(torch.nn.Module): \u0026#39;\u0026#39;\u0026#39; Autoregressive GVP-GNN for **multiple** structure-conditioned RNA design. Takes in RNA structure graphs of type `torch_geometric.data.Data` or `torch_geometric.data.Batch` and returns a categorical distribution over 4 bases at each position in a `torch.Tensor` of shape [n_nodes, 4]. The standard forward pass requires sequence information as input and should be used for training or evaluating likelihood. For sampling or design, use `self.sample`. Args: node_in_dim (tuple): node dimensions in input graph node_h_dim (tuple): node dimensions to use in GVP-GNN layers node_in_dim (tuple): edge dimensions in input graph edge_h_dim (tuple): edge dimensions to embed in GVP-GNN layers num_layers (int): number of GVP-GNN layers in encoder/decoder drop_rate (float): rate to use in all dropout layers out_dim (int): output dimension (4 bases) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_in_dim = (64, 4), node_h_dim = (128, 16), edge_in_dim = (32, 1), edge_h_dim = (32, 1), num_layers = 3, drop_rate = 0.1, out_dim = 4, ######### 新增: 注意力头数 num_attn_head = 4, ): super().__init__() self.node_in_dim = node_in_dim self.node_h_dim = node_h_dim self.edge_in_dim = edge_in_dim self.edge_h_dim = edge_h_dim self.num_layers = num_layers self.out_dim = out_dim activations = (F.silu, None) # Node input embedding self.W_v = torch.nn.Sequential( LayerNorm(self.node_in_dim), GVP(self.node_in_dim, self.node_h_dim, activations=(None, None), vector_gate=True) ) # Edge input embedding self.W_e = torch.nn.Sequential( LayerNorm(self.edge_in_dim), GVP(self.edge_in_dim, self.edge_h_dim, activations=(None, None), vector_gate=True) ) # Encoder layers (supports multiple conformations) # 修改: 将 MultiGVPConvLayer 替换为我们设计的新混合层 self.encoder_layers = nn.ModuleList( HybridGVPTransformerLayer( node_dims=self.node_h_dim, edge_dims=self.edge_h_dim, num_attn_head=num_attn_head, drop_rate=drop_rate, ) for _ in range(num_layers)) # Decoder layers self.W_s = nn.Embedding(self.out_dim, self.out_dim) self.edge_h_dim = (self.edge_h_dim[0] + self.out_dim, self.edge_h_dim[1]) self.decoder_layers = nn.ModuleList( GVPConvLayer(self.node_h_dim, self.edge_h_dim, activations=activations, vector_gate=True, drop_rate=drop_rate, autoregressive=True, norm_first=True) for _ in range(num_layers)) # Output self.W_out = GVP(self.node_h_dim, (self.out_dim, 0), activations=(None, None)) def forward(self, batch): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index seq = batch.seq h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features: # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) encoder_embeddings = h_V h_S = self.W_s(seq) h_S = h_S[edge_index[0]] h_S[edge_index[0] \u0026gt;= edge_index[1]] = 0 h_E = (torch.cat([h_E[0], h_S], dim=-1), h_E[1]) for layer in self.decoder_layers: h_V = layer(h_V, edge_index, h_E, autoregressive_x = encoder_embeddings) logits = self.W_out(h_V) return logits @torch.no_grad() def sample( self, batch, n_samples, temperature: Optional[float] = 0.1, logit_bias: Optional[torch.Tensor] = None, return_logits: Optional[bool] = False ): \u0026#39;\u0026#39;\u0026#39; Samples sequences autoregressively from the distribution learned by the model. Args: batch (torch_geometric.data.Data): mini-batch containing one RNA backbone to design sequences for n_samples (int): number of samples temperature (float): temperature to use in softmax over the categorical distribution logit_bias (torch.Tensor): bias to add to logits during sampling to manually fix or control nucleotides in designed sequences, of shape [n_nodes, 4] return_logits (bool): whether to return logits or not Returns: seq (torch.Tensor): int tensor of shape [n_samples, n_nodes] based on the residue-to-int mapping of the original training data logits (torch.Tensor): logits of shape [n_samples, n_nodes, 4] (only if return_logits is True) \u0026#39;\u0026#39;\u0026#39; h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index device = edge_index.device num_nodes = h_V[0].shape[0] h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) # Repeat features for sampling n_samples times h_V = (h_V[0].repeat(n_samples, 1), h_V[1].repeat(n_samples, 1, 1)) h_E = (h_E[0].repeat(n_samples, 1), h_E[1].repeat(n_samples, 1, 1)) # Expand edge index for autoregressive decoding edge_index = edge_index.expand(n_samples, -1, -1) offset = num_nodes * torch.arange(n_samples, device=device).view(-1, 1, 1) edge_index = torch.cat(tuple(edge_index + offset), dim=-1) # This is akin to \u0026#39;batching\u0026#39; (in PyG style) n_samples copies of the graph seq = torch.zeros(n_samples * num_nodes, device=device, dtype=torch.int) h_S = torch.zeros(n_samples * num_nodes, self.out_dim, device=device) logits = torch.zeros(n_samples * num_nodes, self.out_dim, device=device) h_V_cache = [(h_V[0].clone(), h_V[1].clone()) for _ in self.decoder_layers] # Decode one token at a time for i in range(num_nodes): h_S_ = h_S[edge_index[0]] h_S_[edge_index[0] \u0026gt;= edge_index[1]] = 0 h_E_ = (torch.cat([h_E[0], h_S_], dim=-1), h_E[1]) edge_mask = edge_index[1] % num_nodes == i # True for all edges where dst is node i edge_index_ = edge_index[:, edge_mask] # subset all incoming edges to node i h_E_ = tuple_index(h_E_, edge_mask) node_mask = torch.zeros(n_samples * num_nodes, device=device, dtype=torch.bool) node_mask[i::num_nodes] = True # True for all nodes i and its repeats for j, layer in enumerate(self.decoder_layers): out = layer(h_V_cache[j], edge_index_, h_E_, autoregressive_x=h_V_cache[0], node_mask=node_mask) out = tuple_index(out, node_mask) # subset out to only node i and its repeats if j \u0026lt; len(self.decoder_layers)-1: h_V_cache[j+1][0][i::num_nodes] = out[0] h_V_cache[j+1][1][i::num_nodes] = out[1] lgts = self.W_out(out) # Add logit bias if provided to fix or bias positions if logit_bias is not None: lgts += logit_bias[i] # Sample from logits seq[i::num_nodes] = Categorical(logits=lgts / temperature).sample() h_S[i::num_nodes] = self.W_s(seq[i::num_nodes]) logits[i::num_nodes] = lgts if return_logits: return seq.view(n_samples, num_nodes), logits.view(n_samples, num_nodes, self.out_dim) else: return seq.view(n_samples, num_nodes) def pool_multi_conf(self, h_V, h_E, mask_confs, edge_index): if mask_confs.size(1) == 1: # Number of conformations is 1, no need to pool return (h_V[0][:, 0], h_V[1][:, 0]), (h_E[0][:, 0], h_E[1][:, 0]) # True num_conf for masked mean pooling n_conf_true = mask_confs.sum(1, keepdim=True) # (n_nodes, 1) # Mask scalar features mask = mask_confs.unsqueeze(2) # (n_nodes, n_conf, 1) h_V0 = h_V[0] * mask h_E0 = h_E[0] * mask[edge_index[0]] # Mask vector features mask = mask.unsqueeze(3) # (n_nodes, n_conf, 1, 1) h_V1 = h_V[1] * mask h_E1 = h_E[1] * mask[edge_index[0]] # Average pooling multi-conformation features h_V = (h_V0.sum(dim=1) / n_conf_true, # (n_nodes, d_s) h_V1.sum(dim=1) / n_conf_true.unsqueeze(2)) # (n_nodes, d_v, 3) h_E = (h_E0.sum(dim=1) / n_conf_true[edge_index[0]], # (n_edges, d_se) h_E1.sum(dim=1) / n_conf_true[edge_index[0]].unsqueeze(2)) # (n_edges, d_ve, 3) return h_V, h_E class NonAutoregressiveMultiGNNv1(torch.nn.Module): \u0026#39;\u0026#39;\u0026#39; Non-Autoregressive GVP-GNN for **multiple** structure-conditioned RNA design. Takes in RNA structure graphs of type `torch_geometric.data.Data` or `torch_geometric.data.Batch` and returns a categorical distribution over 4 bases at each position in a `torch.Tensor` of shape [n_nodes, 4]. The standard forward pass requires sequence information as input and should be used for training or evaluating likelihood. For sampling or design, use `self.sample`. Args: node_in_dim (tuple): node dimensions in input graph node_h_dim (tuple): node dimensions to use in GVP-GNN layers node_in_dim (tuple): edge dimensions in input graph edge_h_dim (tuple): edge dimensions to embed in GVP-GNN layers num_layers (int): number of GVP-GNN layers in encoder/decoder drop_rate (float): rate to use in all dropout layers out_dim (int): output dimension (4 bases) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_in_dim = (64, 4), node_h_dim = (128, 16), edge_in_dim = (32, 1), edge_h_dim = (32, 1), num_layers = 3, drop_rate = 0.1, out_dim = 4, ): super().__init__() self.node_in_dim = node_in_dim self.node_h_dim = node_h_dim self.edge_in_dim = edge_in_dim self.edge_h_dim = edge_h_dim self.num_layers = num_layers self.out_dim = out_dim activations = (F.silu, None) # Node input embedding self.W_v = torch.nn.Sequential( LayerNorm(self.node_in_dim), GVP(self.node_in_dim, self.node_h_dim, activations=(None, None), vector_gate=True) ) # Edge input embedding self.W_e = torch.nn.Sequential( LayerNorm(self.edge_in_dim), GVP(self.edge_in_dim, self.edge_h_dim, activations=(None, None), vector_gate=True) ) # Encoder layers (supports multiple conformations) self.encoder_layers = nn.ModuleList( MultiGVPConvLayer(self.node_h_dim, self.edge_h_dim, activations=activations, vector_gate=True, drop_rate=drop_rate, norm_first=True) for _ in range(num_layers)) # Output self.W_out = torch.nn.Sequential( LayerNorm(self.node_h_dim), GVP(self.node_h_dim, self.node_h_dim, activations=(None, None), vector_gate=True), GVP(self.node_h_dim, (self.out_dim, 0), activations=(None, None)) ) def forward(self, batch): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features: # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) # h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) h_V = (h_V[0].mean(dim=1), h_V[1].mean(dim=1)) logits = self.W_out(h_V) # (n_nodes, out_dim) return logits def sample(self, batch, n_samples, temperature=0.1, return_logits=False): with torch.no_grad(): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features # h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) h_V = (h_V[0].mean(dim=1), h_V[1].mean(dim=1)) logits = self.W_out(h_V) # (n_nodes, out_dim) probs = F.softmax(logits / temperature, dim=-1) seq = torch.multinomial(probs, n_samples, replacement=True) # (n_nodes, n_samples) if return_logits: return seq.permute(1, 0).contiguous(), logits.unsqueeze(0).repeat(n_samples, 1, 1) else: return seq.permute(1, 0).contiguous() def pool_multi_conf(self, h_V, h_E, mask_confs, edge_index): if mask_confs.size(1) == 1: # Number of conformations is 1, no need to pool return (h_V[0][:, 0], h_V[1][:, 0]), (h_E[0][:, 0], h_E[1][:, 0]) # True num_conf for masked mean pooling n_conf_true = mask_confs.sum(1, keepdim=True) # (n_nodes, 1) # Mask scalar features mask = mask_confs.unsqueeze(2) # (n_nodes, n_conf, 1) h_V0 = h_V[0] * mask h_E0 = h_E[0] * mask[edge_index[0]] # Mask vector features mask = mask.unsqueeze(3) # (n_nodes, n_conf, 1, 1) h_V1 = h_V[1] * mask h_E1 = h_E[1] * mask[edge_index[0]] # Average pooling multi-conformation features h_V = (h_V0.sum(dim=1) / n_conf_true, # (n_nodes, d_s) h_V1.sum(dim=1) / n_conf_true.unsqueeze(2)) # (n_nodes, d_v, 3) h_E = (h_E0.sum(dim=1) / n_conf_true[edge_index[0]], # (n_edges, d_se) h_E1.sum(dim=1) / n_conf_true[edge_index[0]].unsqueeze(2)) # (n_edges, d_ve, 3) return h_V, h_E Long-short Transformer GVP 同样，layers.py:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 ################################################################ # Generalisation of Geometric Vector Perceptron, Jing et al. # for explicit multi-state biomolecule representation learning. # Original repository: https://github.com/drorlab/gvp-pytorch # MODIFIED: Added HybridGVPLongShortLayer for deep fusion of # local geometric message passing and an efficient long-short attention mechanism. # VERSION 3: Final robust version incorporating all valid feedback. ################################################################ import functools import torch from torch import nn import torch.nn.functional as F import torch_geometric from torch_geometric.nn import MessagePassing from torch_scatter import scatter_add ######################################################################### # FINAL VERSION: 辅助函数 def _create_batch_mask(batch, dtype, device): \u0026#34;\u0026#34;\u0026#34;根据 torch_geometric 的 batch 向量创建块对角注意力掩码。\u0026#34;\u0026#34;\u0026#34; if batch is None: return None # 返回None，在主函数中处理 num_nodes = batch.size(0) same_graph = batch.unsqueeze(1) == batch.unsqueeze(0) mask = torch.zeros((num_nodes, num_nodes), device=device, dtype=dtype) mask.masked_fill_(~same_graph, torch.finfo(dtype).min) return mask def _create_window_mask(seq_len: int, window_size: int, device: torch.device, dtype: torch.dtype) -\u0026gt; torch.Tensor: \u0026#34;\u0026#34;\u0026#34; 高效的向量化窗口掩码生成 \u0026#34;\u0026#34;\u0026#34; half = window_size // 2 idx = torch.arange(seq_len, device=device) dist = (idx.unsqueeze(1) - idx.unsqueeze(0)).abs() mask = torch.zeros((seq_len, seq_len), device=device, dtype=dtype) mask.masked_fill_(dist \u0026gt; half, torch.finfo(dtype).min) return mask # FINAL VERSION: Long-Short Attention 模块 class LongShortAttention(nn.Module): \u0026#34;\u0026#34;\u0026#34; 实现了Long-Short Transformer思想的注意力模块. - 短程: 滑动窗口自注意力 - 长程: 动态投影 - 融合: DualLN + 拼接注意力得分 \u0026#34;\u0026#34;\u0026#34; def __init__(self, embed_dim, num_heads, window_size, proj_rank, dropout=0.1): super().__init__() assert embed_dim % num_heads == 0, \u0026#34;embed_dim 必须能被 num_heads 整除\u0026#34; self.embed_dim = embed_dim self.num_heads = num_heads self.head_dim = embed_dim // num_heads self.window_size = window_size self.proj_rank = proj_rank self.q_proj = nn.Linear(embed_dim, embed_dim) self.k_proj = nn.Linear(embed_dim, embed_dim) self.v_proj = nn.Linear(embed_dim, embed_dim) self.out_proj = nn.Linear(embed_dim, embed_dim) self.d_proj_matrix_proj = nn.Linear(embed_dim, proj_rank) self.ln_q = nn.LayerNorm(embed_dim) # 采纳建议：为K和V使用独立的LN self.ln_k_short = nn.LayerNorm(embed_dim) self.ln_v_short = nn.LayerNorm(embed_dim) self.ln_k_long = nn.LayerNorm(embed_dim) self.ln_v_long = nn.LayerNorm(embed_dim) self.dropout = nn.Dropout(dropout) def forward(self, x, batch=None): bsz, seq_len, _ = x.shape x_norm = self.ln_q(x) q = self.q_proj(x_norm) k = self.k_proj(x) v = self.v_proj(x) k_short, v_short = self.ln_k_short(k), self.ln_v_short(v) k_long, v_long = self.ln_k_long(k), self.ln_v_long(v) q_s = q.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2) k_s = k_short.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2) v_s = v_short.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2) window_mask = _create_window_mask(seq_len, self.window_size, x.device, x.dtype) batch_mask = _create_batch_mask(batch, x.dtype, x.device) # 采纳建议：在主函数中处理None if batch_mask is not None: attn_mask = window_mask + batch_mask else: attn_mask = window_mask attn_scores_short = torch.matmul(q_s, k_s.transpose(-2, -1)) / (self.head_dim ** 0.5) # 在使用时添加广播维度 attn_scores_short = attn_scores_short + attn_mask.unsqueeze(0) proj_matrix = F.softmax(self.d_proj_matrix_proj(k_long), dim=1).transpose(1, 2) k_compressed = torch.matmul(proj_matrix, k_long) v_compressed = torch.matmul(proj_matrix, v_long) q_l = q.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2) k_c = k_compressed.view(bsz, self.proj_rank, self.num_heads, self.head_dim).transpose(1, 2) v_c = v_compressed.view(bsz, self.proj_rank, self.num_heads, self.head_dim).transpose(1, 2) attn_scores_long = torch.matmul(q_l, k_c.transpose(-2, -1)) / (self.head_dim ** 0.5) attn_scores_fused = torch.cat([attn_scores_short, attn_scores_long], dim=-1) attn_probs = F.softmax(attn_scores_fused, dim=-1) attn_probs = self.dropout(attn_probs) attn_probs_short = attn_probs[..., :seq_len] attn_probs_long = attn_probs[..., seq_len:] output_short = torch.matmul(attn_probs_short, v_s) output_long = torch.matmul(attn_probs_long, v_c) output = output_short + output_long output = output.transpose(1, 2).contiguous().view(bsz, seq_len, self.embed_dim) return self.out_proj(output) # (PositionwiseFeedForward 类保持不变) class PositionwiseFeedForward(nn.Module): \u0026#39;\u0026#39;\u0026#39; A two-layer Feed-Forward-Network. \u0026#39;\u0026#39;\u0026#39; def __init__(self, d_in, d_hid, dropout=0.1): super().__init__() self.w_1 = nn.Linear(d_in, d_hid) self.w_2 = nn.Linear(d_hid, d_in) self.dropout = nn.Dropout(dropout) self.activation = F.silu def forward(self, x): return self.w_2(self.dropout(self.activation(self.w_1(x)))) # FINAL VERSION: HybridGVPLongShortLayer class HybridGVPLongShortLayer(nn.Module): \u0026#39;\u0026#39;\u0026#39; 将GVP-GNN与Long-Short Attention思想深度融合的混合层。 \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_dims, edge_dims, num_attn_head=4, ls_window_size=50, ls_proj_rank=32, n_message=3, drop_rate=.1, activations=(F.silu, torch.sigmoid), vector_gate=True, ): super(HybridGVPLongShortLayer, self).__init__() self.norm_gvp = LayerNorm(node_dims) self.gvp_conv = MultiGVPConv(node_dims, node_dims, edge_dims, n_message, aggr=\u0026#34;mean\u0026#34;, activations=activations, vector_gate=vector_gate) self.dropout_gvp = Dropout(drop_rate) self.norm_attn = nn.LayerNorm(node_dims[0]) self.ls_attention = LongShortAttention(embed_dim=node_dims[0], num_heads=num_attn_head, window_size=ls_window_size, proj_rank=ls_proj_rank, dropout=drop_rate) self.dropout_attn = nn.Dropout(drop_rate) self.norm_ffn = nn.LayerNorm(node_dims[0]) self.ffn = PositionwiseFeedForward(d_in=node_dims[0], d_hid=node_dims[0] * 4, dropout=drop_rate) self.dropout_ffn = nn.Dropout(drop_rate) def forward(self, x, edge_index, edge_attr, batch=None): x_res_gvp = x x_norm_gvp = self.norm_gvp(x) dh_local = self.gvp_conv(x_norm_gvp, edge_index, edge_attr) x_local = tuple_sum(x_res_gvp, self.dropout_gvp(dh_local)) s_local, v_local = x_local s_res_attn = s_local s_norm_attn = self.norm_attn(s_local) n_nodes, n_conf, d_s = s_norm_attn.shape s_reshaped = s_norm_attn.permute(1, 0, 2) s_attn_out = self.ls_attention(s_reshaped, batch=batch) s_attn_out = s_attn_out.permute(1, 0, 2) s_after_attn = s_res_attn + self.dropout_attn(s_attn_out) s_res_ffn = s_after_attn s_norm_ffn = self.norm_ffn(s_after_attn) s_ffn_out = self.ffn(s_norm_ffn) s_final = s_res_ffn + self.dropout_ffn(s_ffn_out) v_final = v_local return (s_final, v_final) class GVPConvLayer(nn.Module): \u0026#39;\u0026#39;\u0026#39; Full graph convolution / message passing layer with Geometric Vector Perceptrons. Residually updates node embeddings with aggregated incoming messages, applies a pointwise feedforward network to node embeddings, and returns updated node embeddings. To only compute the aggregated messages, see `GVPConv`. :param node_dims: node embedding dimensions (n_scalar, n_vector) :param edge_dims: input edge embedding dimensions (n_scalar, n_vector) :param n_message: number of GVPs to use in message function :param n_feedforward: number of GVPs to use in feedforward function :param drop_rate: drop probability in all dropout layers :param autoregressive: if `True`, this `GVPConvLayer` will be used with a different set of input node embeddings for messages where src \u0026gt;= dst :param activations: tuple of functions (scalar_act, vector_act) to use in GVPs :param vector_gate: whether to use vector gating. (vector_act will be used as sigma^+ in vector gating if `True`) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_dims, edge_dims, n_message=3, n_feedforward=2, drop_rate=.1, autoregressive=False, activations=(F.silu, torch.sigmoid), vector_gate=True, residual=True, norm_first=False, ): super(GVPConvLayer, self).__init__() self.conv = GVPConv(node_dims, node_dims, edge_dims, n_message, aggr=\u0026#34;add\u0026#34; if autoregressive else \u0026#34;mean\u0026#34;, activations=activations, vector_gate=vector_gate) GVP_ = functools.partial(GVP, activations=activations, vector_gate=vector_gate) self.norm = nn.ModuleList([LayerNorm(node_dims) for _ in range(2)]) self.dropout = nn.ModuleList([Dropout(drop_rate) for _ in range(2)]) ff_func = [] if n_feedforward == 1: ff_func.append(GVP_(node_dims, node_dims)) else: hid_dims = 4*node_dims[0], 2*node_dims[1] ff_func.append(GVP_(node_dims, hid_dims)) for i in range(n_feedforward-2): ff_func.append(GVP_(hid_dims, hid_dims)) ff_func.append(GVP_(hid_dims, node_dims, activations=(None, None))) self.ff_func = nn.Sequential(*ff_func) self.residual = residual self.norm_first = norm_first def forward(self, x, edge_index, edge_attr, autoregressive_x=None, node_mask=None): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor` :param edge_index: array of shape [2, n_edges] :param edge_attr: tuple (s, V) of `torch.Tensor` :param autoregressive_x: tuple (s, V) of `torch.Tensor`. If not `None`, will be used as src node embeddings for forming messages where src \u0026gt;= dst. The current node embeddings `x` will still be the base of the update and the pointwise feedforward. :param node_mask: array of type `bool` to index into the first dim of node embeddings (s, V). If not `None`, only these nodes will be updated. \u0026#39;\u0026#39;\u0026#39; if autoregressive_x is not None: src, dst = edge_index mask = src \u0026lt; dst edge_index_forward = edge_index[:, mask] edge_index_backward = edge_index[:, ~mask] edge_attr_forward = tuple_index(edge_attr, mask) edge_attr_backward = tuple_index(edge_attr, ~mask) dh = tuple_sum( self.conv(x, edge_index_forward, edge_attr_forward), self.conv(autoregressive_x, edge_index_backward, edge_attr_backward) ) count = scatter_add(torch.ones_like(dst), dst, dim_size=dh[0].size(0)).clamp(min=1).unsqueeze(-1) dh = dh[0] / count, dh[1] / count.unsqueeze(-1) else: if self.norm_first: dh = self.conv(self.norm[0](x), edge_index, edge_attr) else: dh = self.conv(x, edge_index, edge_attr) if node_mask is not None: x_ = x x, dh = tuple_index(x, node_mask), tuple_index(dh, node_mask) if self.norm_first: x = tuple_sum(x, self.dropout[0](dh)) dh = self.ff_func(self.norm[1](x)) x = tuple_sum(x, self.dropout[1](dh)) else: x = self.norm[0](tuple_sum(x, self.dropout[0](dh))) if self.residual else dh dh = self.ff_func(x) x = self.norm[1](tuple_sum(x, self.dropout[1](dh))) if self.residual else dh if node_mask is not None: x_[0][node_mask], x_[1][node_mask] = x[0], x[1] x = x_ return x class GVPConv(MessagePassing): \u0026#39;\u0026#39;\u0026#39; Graph convolution / message passing with Geometric Vector Perceptrons. Takes in a graph with node and edge embeddings, and returns new node embeddings. This does NOT do residual updates and pointwise feedforward layers ---see `GVPConvLayer`. :param in_dims: input node embedding dimensions (n_scalar, n_vector) :param out_dims: output node embedding dimensions (n_scalar, n_vector) :param edge_dims: input edge embedding dimensions (n_scalar, n_vector) :param n_layers: number of GVPs in the message function :param module_list: preconstructed message function, overrides n_layers :param aggr: should be \u0026#34;add\u0026#34; if some incoming edges are masked, as in a masked autoregressive decoder architecture, otherwise \u0026#34;mean\u0026#34; :param activations: tuple of functions (scalar_act, vector_act) to use in GVPs :param vector_gate: whether to use vector gating. (vector_act will be used as sigma^+ in vector gating if `True`) \u0026#39;\u0026#39;\u0026#39; def __init__(self, in_dims, out_dims, edge_dims, n_layers=3, module_list=None, aggr=\u0026#34;mean\u0026#34;, activations=(F.silu, torch.sigmoid), vector_gate=True): super(GVPConv, self).__init__(aggr=aggr) self.si, self.vi = in_dims self.so, self.vo = out_dims self.se, self.ve = edge_dims GVP_ = functools.partial(GVP, activations=activations, vector_gate=vector_gate) module_list = module_list or [] if not module_list: if n_layers == 1: module_list.append( GVP_((2*self.si + self.se, 2*self.vi + self.ve), (self.so, self.vo))) else: module_list.append( GVP_((2*self.si + self.se, 2*self.vi + self.ve), out_dims) ) for i in range(n_layers - 2): module_list.append(GVP_(out_dims, out_dims)) module_list.append(GVP_(out_dims, out_dims, activations=(None, None))) self.message_func = nn.Sequential(*module_list) def forward(self, x, edge_index, edge_attr): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor` :param edge_index: array of shape [2, n_edges] :param edge_attr: tuple (s, V) of `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; x_s, x_v = x message = self.propagate(edge_index, s=x_s, v=x_v.contiguous().view(x_v.shape[0], x_v.shape[1] * 3), edge_attr=edge_attr) return _split(message, self.vo) def message(self, s_i, v_i, s_j, v_j, edge_attr): v_j = v_j.view(v_j.shape[0], v_j.shape[1]//3, 3) v_i = v_i.view(v_i.shape[0], v_i.shape[1]//3, 3) message = tuple_cat((s_j, v_j), edge_attr, (s_i, v_i)) message = self.message_func(message) return _merge(*message) ######################################################################### class MultiGVPConvLayer(nn.Module): \u0026#39;\u0026#39;\u0026#39; GVPConvLayer for handling multiple conformations (encoder-only) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_dims, edge_dims, n_message=3, n_feedforward=2, drop_rate=.1, activations=(F.silu, torch.sigmoid), vector_gate=True, residual=True, norm_first=False, ): super(MultiGVPConvLayer, self).__init__() self.conv = MultiGVPConv(node_dims, node_dims, edge_dims, n_message, aggr=\u0026#34;mean\u0026#34;, activations=activations, vector_gate=vector_gate) GVP_ = functools.partial(GVP, activations=activations, vector_gate=vector_gate) self.norm = nn.ModuleList([LayerNorm(node_dims) for _ in range(2)]) self.dropout = nn.ModuleList([Dropout(drop_rate) for _ in range(2)]) ff_func = [] if n_feedforward == 1: ff_func.append(GVP_(node_dims, node_dims)) else: hid_dims = 4*node_dims[0], 2*node_dims[1] ff_func.append(GVP_(node_dims, hid_dims)) for i in range(n_feedforward-2): ff_func.append(GVP_(hid_dims, hid_dims)) ff_func.append(GVP_(hid_dims, node_dims, activations=(None, None))) self.ff_func = nn.Sequential(*ff_func) self.residual = residual self.norm_first = norm_first def forward(self, x, edge_index, edge_attr): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor` :param edge_index: array of shape [2, n_edges] :param edge_attr: tuple (s, V) of `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; if self.norm_first: dh = self.conv(self.norm[0](x), edge_index, edge_attr) x = tuple_sum(x, self.dropout[0](dh)) dh = self.ff_func(self.norm[1](x)) x = tuple_sum(x, self.dropout[1](dh)) else: dh = self.conv(x, edge_index, edge_attr) x = self.norm[0](tuple_sum(x, self.dropout[0](dh))) if self.residual else dh dh = self.ff_func(x) x = self.norm[1](tuple_sum(x, self.dropout[1](dh))) if self.residual else dh return x class MultiGVPConv(MessagePassing): \u0026#39;\u0026#39;\u0026#39; GVPConv for handling multiple conformations \u0026#39;\u0026#39;\u0026#39; def __init__(self, in_dims, out_dims, edge_dims, n_layers=3, module_list=None, aggr=\u0026#34;mean\u0026#34;, activations=(F.silu, torch.sigmoid), vector_gate=True): super(MultiGVPConv, self).__init__(aggr=aggr) self.si, self.vi = in_dims self.so, self.vo = out_dims self.se, self.ve = edge_dims GVP_ = functools.partial(GVP, activations=activations, vector_gate=vector_gate) module_list = module_list or [] if not module_list: if n_layers == 1: module_list.append( GVP_((2*self.si + self.se, 2*self.vi + self.ve), (self.so, self.vo))) else: module_list.append( GVP_((2*self.si + self.se, 2*self.vi + self.ve), out_dims) ) for i in range(n_layers - 2): module_list.append(GVP_(out_dims, out_dims)) module_list.append(GVP_(out_dims, out_dims, activations=(None, None))) self.message_func = nn.Sequential(*module_list) def forward(self, x, edge_index, edge_attr): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor` :param edge_index: array of shape [2, n_edges] :param edge_attr: tuple (s, V) of `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; x_s, x_v = x n_conf = x_s.shape[1] # x_s: [n_nodes, n_conf, d] -\u0026gt; [n_nodes, n_conf * d] x_s = x_s.contiguous().view(x_s.shape[0], x_s.shape[1] * x_s.shape[2]) # x_v: [n_nodes, n_conf, d, 3] -\u0026gt; [n_nodes, n_conf * d * 3] x_v = x_v.contiguous().view(x_v.shape[0], x_v.shape[1] * x_v.shape[2] * 3) message = self.propagate(edge_index, s=x_s, v=x_v, edge_attr=edge_attr) return _split_multi(message, self.so, self.vo, n_conf) def message(self, s_i, v_i, s_j, v_j, edge_attr): # [n_nodes, n_conf * d] -\u0026gt; [n_nodes, n_conf, d] s_i = s_i.view(s_i.shape[0], s_i.shape[1]//self.si, self.si) s_j = s_j.view(s_j.shape[0], s_j.shape[1]//self.si, self.si) # [n_nodes, n_conf * d * 3] -\u0026gt; [n_nodes, n_conf, d, 3] v_i = v_i.view(v_i.shape[0], v_i.shape[1]//(self.vi * 3), self.vi, 3) v_j = v_j.view(v_j.shape[0], v_j.shape[1]//(self.vi * 3), self.vi, 3) message = tuple_cat((s_j, v_j), edge_attr, (s_i, v_i)) message = self.message_func(message) return _merge_multi(*message) ######################################################################### class GVP(nn.Module): \u0026#39;\u0026#39;\u0026#39; Geometric Vector Perceptron. See manuscript and README.md for more details. :param in_dims: tuple (n_scalar, n_vector) :param out_dims: tuple (n_scalar, n_vector) :param h_dim: intermediate number of vector channels, optional :param activations: tuple of functions (scalar_act, vector_act) :param vector_gate: whether to use vector gating. (vector_act will be used as sigma^+ in vector gating if `True`) \u0026#39;\u0026#39;\u0026#39; def __init__(self, in_dims, out_dims, h_dim=None, activations=(F.silu, torch.sigmoid), vector_gate=True): super(GVP, self).__init__() self.si, self.vi = in_dims self.so, self.vo = out_dims self.vector_gate = vector_gate if self.vi: self.h_dim = h_dim or max(self.vi, self.vo) self.wh = nn.Linear(self.vi, self.h_dim, bias=False) self.ws = nn.Linear(self.h_dim + self.si, self.so) if self.vo: self.wv = nn.Linear(self.h_dim, self.vo, bias=False) if self.vector_gate: self.wsv = nn.Linear(self.so, self.vo) else: self.ws = nn.Linear(self.si, self.so) self.scalar_act, self.vector_act = activations self.dummy_param = nn.Parameter(torch.empty(0)) def forward(self, x): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor`, or (if vectors_in is 0), a single `torch.Tensor` :return: tuple (s, V) of `torch.Tensor`, or (if vectors_out is 0), a single `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; if self.vi: s, v = x v = torch.transpose(v, -1, -2) vh = self.wh(v) vn = _norm_no_nan(vh, axis=-2) s = self.ws(torch.cat([s, vn], -1)) if self.vo: v = self.wv(vh) v = torch.transpose(v, -1, -2) if self.vector_gate: if self.vector_act: gate = self.wsv(self.vector_act(s)) else: gate = self.wsv(s) v = v * torch.sigmoid(gate).unsqueeze(-1) elif self.vector_act: v = v * self.vector_act( _norm_no_nan(v, axis=-1, keepdims=True)) else: s = self.ws(x) if self.vo: v = torch.zeros(s.shape[0], self.vo, 3, device=self.dummy_param.device) if self.scalar_act: s = self.scalar_act(s) return (s, v) if self.vo else s ######################################################################### class _VDropout(nn.Module): \u0026#39;\u0026#39;\u0026#39; Vector channel dropout where the elements of each vector channel are dropped together. \u0026#39;\u0026#39;\u0026#39; def __init__(self, drop_rate): super(_VDropout, self).__init__() self.drop_rate = drop_rate self.dummy_param = nn.Parameter(torch.empty(0)) def forward(self, x): \u0026#39;\u0026#39;\u0026#39; :param x: `torch.Tensor` corresponding to vector channels \u0026#39;\u0026#39;\u0026#39; device = self.dummy_param.device if not self.training: return x mask = torch.bernoulli( (1 - self.drop_rate) * torch.ones(x.shape[:-1], device=device) ).unsqueeze(-1) x = mask * x / (1 - self.drop_rate) return x class Dropout(nn.Module): \u0026#39;\u0026#39;\u0026#39; Combined dropout for tuples (s, V). Takes tuples (s, V) as input and as output. \u0026#39;\u0026#39;\u0026#39; def __init__(self, drop_rate): super(Dropout, self).__init__() self.sdropout = nn.Dropout(drop_rate) self.vdropout = _VDropout(drop_rate) def forward(self, x): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor`, or single `torch.Tensor` (will be assumed to be scalar channels) \u0026#39;\u0026#39;\u0026#39; if type(x) is torch.Tensor: return self.sdropout(x) s, v = x return self.sdropout(s), self.vdropout(v) class LayerNorm(nn.Module): \u0026#39;\u0026#39;\u0026#39; Combined LayerNorm for tuples (s, V). Takes tuples (s, V) as input and as output. \u0026#39;\u0026#39;\u0026#39; def __init__(self, dims): super(LayerNorm, self).__init__() self.s, self.v = dims self.scalar_norm = nn.LayerNorm(self.s) def forward(self, x): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor`, or single `torch.Tensor` (will be assumed to be scalar channels) \u0026#39;\u0026#39;\u0026#39; if not self.v: return self.scalar_norm(x) s, v = x vn = _norm_no_nan(v, axis=-1, keepdims=True, sqrt=False) vn = torch.sqrt(torch.mean(vn, dim=-2, keepdim=True)) return self.scalar_norm(s), v / vn def tuple_sum(*args): \u0026#39;\u0026#39;\u0026#39; Sums any number of tuples (s, V) elementwise. \u0026#39;\u0026#39;\u0026#39; return tuple(map(sum, zip(*args))) def tuple_cat(*args, dim=-1): \u0026#39;\u0026#39;\u0026#39; Concatenates any number of tuples (s, V) elementwise. :param dim: dimension along which to concatenate when viewed as the `dim` index for the scalar-channel tensors. This means that `dim=-1` will be applied as `dim=-2` for the vector-channel tensors. \u0026#39;\u0026#39;\u0026#39; dim %= len(args[0][0].shape) s_args, v_args = list(zip(*args)) return torch.cat(s_args, dim=dim), torch.cat(v_args, dim=dim) def tuple_index(x, idx): \u0026#39;\u0026#39;\u0026#39; Indexes into a tuple (s, V) along the first dimension. :param idx: any object which can be used to index into a `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; return x[0][idx], x[1][idx] def randn(n, dims, device=\u0026#34;cpu\u0026#34;): \u0026#39;\u0026#39;\u0026#39; Returns random tuples (s, V) drawn elementwise from a normal distribution. :param n: number of data points :param dims: tuple of dimensions (n_scalar, n_vector) :return: (s, V) with s.shape = (n, n_scalar) and V.shape = (n, n_vector, 3) \u0026#39;\u0026#39;\u0026#39; return torch.randn(n, dims[0], device=device), \\ torch.randn(n, dims[1], 3, device=device) def _norm_no_nan(x, axis=-1, keepdims=False, eps=1e-8, sqrt=True): \u0026#39;\u0026#39;\u0026#39; L2 norm of tensor clamped above a minimum value `eps`. :param sqrt: if `False`, returns the square of the L2 norm \u0026#39;\u0026#39;\u0026#39; out = torch.clamp(torch.sum(torch.square(x), axis, keepdims), min=eps) return torch.sqrt(out) if sqrt else out def _split(x, nv): \u0026#39;\u0026#39;\u0026#39; Splits a merged representation of (s, V) back into a tuple. Should be used only with `_merge(s, V)` and only if the tuple representation cannot be used. :param x: the `torch.Tensor` returned from `_merge` :param nv: the number of vector channels in the input to `_merge` \u0026#39;\u0026#39;\u0026#39; s = x[..., :-3 * nv] v = x[..., -3 * nv:].contiguous().view(x.shape[0], nv, 3) return s, v def _merge(s, v): \u0026#39;\u0026#39;\u0026#39; Merges a tuple (s, V) into a single `torch.Tensor`, where the vector channels are flattened and appended to the scalar channels. Should be used only if the tuple representation cannot be used. Use `_split(x, nv)` to reverse. \u0026#39;\u0026#39;\u0026#39; v = v.contiguous().view(v.shape[0], v.shape[1] * 3) return torch.cat([s, v], -1) def _split_multi(x, ns, nv, n_conf=5): \u0026#39;\u0026#39;\u0026#39; _split for multiple conformers \u0026#39;\u0026#39;\u0026#39; s = x[..., :-3 * nv * n_conf].contiguous().view(x.shape[0], n_conf, ns) v = x[..., -3 * nv * n_conf:].contiguous().view(x.shape[0], n_conf, nv, 3) return s, v def _merge_multi(s, v): \u0026#39;\u0026#39;\u0026#39; _merge for multiple conformers \u0026#39;\u0026#39;\u0026#39; # s: [n_nodes, n_conf, d] -\u0026gt; [n_nodes, n_conf * d] s = s.contiguous().view(s.shape[0], s.shape[1] * s.shape[2]) # v: [n_nodes, n_conf, d, 3] -\u0026gt; [n_nodes, n_conf * d * 3] v = v.contiguous().view(v.shape[0], v.shape[1] * v.shape[2] * 3) return torch.cat([s, v], -1) 以及models.py:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 ################################################################ # Generalisation of Geometric Vector Perceptron, Jing et al. # for explicit multi-state biomolecule representation learning. # Original repository: https://github.com/drorlab/gvp-pytorch ################################################################ from typing import Optional import torch from torch import nn import torch.nn.functional as F from torch.distributions import Categorical import torch_geometric from src.layers import * class AutoregressiveMultiGNNv1(torch.nn.Module): \u0026#39;\u0026#39;\u0026#39; Autoregressive GVP-GNN for **multiple** structure-conditioned RNA design. Takes in RNA structure graphs of type `torch_geometric.data.Data` or `torch_geometric.data.Batch` and returns a categorical distribution over 4 bases at each position in a `torch.Tensor` of shape [n_nodes, 4]. The standard forward pass requires sequence information as input and should be used for training or evaluating likelihood. For sampling or design, use `self.sample`. Args: node_in_dim (tuple): node dimensions in input graph node_h_dim (tuple): node dimensions to use in GVP-GNN layers node_in_dim (tuple): edge dimensions in input graph edge_h_dim (tuple): edge dimensions to embed in GVP-GNN layers num_layers (int): number of GVP-GNN layers in encoder/decoder drop_rate (float): rate to use in all dropout layers out_dim (int): output dimension (4 bases) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_in_dim = (64, 4), node_h_dim = (128, 16), edge_in_dim = (32, 1), edge_h_dim = (32, 1), num_layers = 3, drop_rate = 0.1, out_dim = 4, num_attn_head = 4, ls_window_size = 32,#初始是50 ls_proj_rank = 32, ): super().__init__() self.node_in_dim = node_in_dim self.node_h_dim = node_h_dim self.edge_in_dim = edge_in_dim self.edge_h_dim = edge_h_dim self.num_layers = num_layers self.out_dim = out_dim activations = (F.silu, None) # Node input embedding self.W_v = torch.nn.Sequential( LayerNorm(self.node_in_dim), GVP(self.node_in_dim, self.node_h_dim, activations=(None, None), vector_gate=True) ) # Edge input embedding self.W_e = torch.nn.Sequential( LayerNorm(self.edge_in_dim), GVP(self.edge_in_dim, self.edge_h_dim, activations=(None, None), vector_gate=True) ) # Encoder layers (supports multiple conformations) self.encoder_layers = nn.ModuleList( HybridGVPLongShortLayer( node_dims=self.node_h_dim, edge_dims=self.edge_h_dim, num_attn_head=num_attn_head, ls_window_size=ls_window_size, ls_proj_rank=ls_proj_rank, drop_rate=drop_rate, ) for _ in range(num_layers)) # Decoder layers self.W_s = nn.Embedding(self.out_dim, self.out_dim) self.edge_h_dim = (self.edge_h_dim[0] + self.out_dim, self.edge_h_dim[1]) self.decoder_layers = nn.ModuleList( GVPConvLayer(self.node_h_dim, self.edge_h_dim, activations=activations, vector_gate=True, drop_rate=drop_rate, autoregressive=True, norm_first=True) for _ in range(num_layers)) # Output self.W_out = GVP(self.node_h_dim, (self.out_dim, 0), activations=(None, None)) def forward(self, batch): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index seq = batch.seq h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E, batch=batch.batch) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features: # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) encoder_embeddings = h_V h_S = self.W_s(seq) h_S = h_S[edge_index[0]] h_S[edge_index[0] \u0026gt;= edge_index[1]] = 0 h_E = (torch.cat([h_E[0], h_S], dim=-1), h_E[1]) for layer in self.decoder_layers: h_V = layer(h_V, edge_index, h_E, autoregressive_x = encoder_embeddings) logits = self.W_out(h_V) return logits @torch.no_grad() def sample( self, batch, n_samples, temperature: Optional[float] = 0.1, logit_bias: Optional[torch.Tensor] = None, return_logits: Optional[bool] = False ): \u0026#39;\u0026#39;\u0026#39; Samples sequences autoregressively from the distribution learned by the model. Args: batch (torch_geometric.data.Data): mini-batch containing one RNA backbone to design sequences for n_samples (int): number of samples temperature (float): temperature to use in softmax over the categorical distribution logit_bias (torch.Tensor): bias to add to logits during sampling to manually fix or control nucleotides in designed sequences, of shape [n_nodes, 4] return_logits (bool): whether to return logits or not Returns: seq (torch.Tensor): int tensor of shape [n_samples, n_nodes] based on the residue-to-int mapping of the original training data logits (torch.Tensor): logits of shape [n_samples, n_nodes, 4] (only if return_logits is True) \u0026#39;\u0026#39;\u0026#39; h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index device = edge_index.device num_nodes = h_V[0].shape[0] h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) # Repeat features for sampling n_samples times h_V = (h_V[0].repeat(n_samples, 1), h_V[1].repeat(n_samples, 1, 1)) h_E = (h_E[0].repeat(n_samples, 1), h_E[1].repeat(n_samples, 1, 1)) # Expand edge index for autoregressive decoding edge_index = edge_index.expand(n_samples, -1, -1) offset = num_nodes * torch.arange(n_samples, device=device).view(-1, 1, 1) edge_index = torch.cat(tuple(edge_index + offset), dim=-1) # This is akin to \u0026#39;batching\u0026#39; (in PyG style) n_samples copies of the graph seq = torch.zeros(n_samples * num_nodes, device=device, dtype=torch.int) h_S = torch.zeros(n_samples * num_nodes, self.out_dim, device=device) logits = torch.zeros(n_samples * num_nodes, self.out_dim, device=device) h_V_cache = [(h_V[0].clone(), h_V[1].clone()) for _ in self.decoder_layers] # Decode one token at a time for i in range(num_nodes): h_S_ = h_S[edge_index[0]] h_S_[edge_index[0] \u0026gt;= edge_index[1]] = 0 h_E_ = (torch.cat([h_E[0], h_S_], dim=-1), h_E[1]) edge_mask = edge_index[1] % num_nodes == i # True for all edges where dst is node i edge_index_ = edge_index[:, edge_mask] # subset all incoming edges to node i h_E_ = tuple_index(h_E_, edge_mask) node_mask = torch.zeros(n_samples * num_nodes, device=device, dtype=torch.bool) node_mask[i::num_nodes] = True # True for all nodes i and its repeats for j, layer in enumerate(self.decoder_layers): out = layer(h_V_cache[j], edge_index_, h_E_, autoregressive_x=h_V_cache[0], node_mask=node_mask) out = tuple_index(out, node_mask) # subset out to only node i and its repeats if j \u0026lt; len(self.decoder_layers)-1: h_V_cache[j+1][0][i::num_nodes] = out[0] h_V_cache[j+1][1][i::num_nodes] = out[1] lgts = self.W_out(out) # Add logit bias if provided to fix or bias positions if logit_bias is not None: lgts += logit_bias[i] # Sample from logits seq[i::num_nodes] = Categorical(logits=lgts / temperature).sample() h_S[i::num_nodes] = self.W_s(seq[i::num_nodes]) logits[i::num_nodes] = lgts if return_logits: return seq.view(n_samples, num_nodes), logits.view(n_samples, num_nodes, self.out_dim) else: return seq.view(n_samples, num_nodes) def pool_multi_conf(self, h_V, h_E, mask_confs, edge_index): if mask_confs.size(1) == 1: # Number of conformations is 1, no need to pool return (h_V[0][:, 0], h_V[1][:, 0]), (h_E[0][:, 0], h_E[1][:, 0]) # True num_conf for masked mean pooling n_conf_true = mask_confs.sum(1, keepdim=True) # (n_nodes, 1) # Mask scalar features mask = mask_confs.unsqueeze(2) # (n_nodes, n_conf, 1) h_V0 = h_V[0] * mask h_E0 = h_E[0] * mask[edge_index[0]] # Mask vector features mask = mask.unsqueeze(3) # (n_nodes, n_conf, 1, 1) h_V1 = h_V[1] * mask h_E1 = h_E[1] * mask[edge_index[0]] # Average pooling multi-conformation features h_V = (h_V0.sum(dim=1) / n_conf_true, # (n_nodes, d_s) h_V1.sum(dim=1) / n_conf_true.unsqueeze(2)) # (n_nodes, d_v, 3) h_E = (h_E0.sum(dim=1) / n_conf_true[edge_index[0]], # (n_edges, d_se) h_E1.sum(dim=1) / n_conf_true[edge_index[0]].unsqueeze(2)) # (n_edges, d_ve, 3) return h_V, h_E class NonAutoregressiveMultiGNNv1(torch.nn.Module): \u0026#39;\u0026#39;\u0026#39; Non-Autoregressive GVP-GNN for **multiple** structure-conditioned RNA design. Takes in RNA structure graphs of type `torch_geometric.data.Data` or `torch_geometric.data.Batch` and returns a categorical distribution over 4 bases at each position in a `torch.Tensor` of shape [n_nodes, 4]. The standard forward pass requires sequence information as input and should be used for training or evaluating likelihood. For sampling or design, use `self.sample`. Args: node_in_dim (tuple): node dimensions in input graph node_h_dim (tuple): node dimensions to use in GVP-GNN layers node_in_dim (tuple): edge dimensions in input graph edge_h_dim (tuple): edge dimensions to embed in GVP-GNN layers num_layers (int): number of GVP-GNN layers in encoder/decoder drop_rate (float): rate to use in all dropout layers out_dim (int): output dimension (4 bases) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_in_dim = (64, 4), node_h_dim = (128, 16), edge_in_dim = (32, 1), edge_h_dim = (32, 1), num_layers = 3, drop_rate = 0.1, out_dim = 4, ): super().__init__() self.node_in_dim = node_in_dim self.node_h_dim = node_h_dim self.edge_in_dim = edge_in_dim self.edge_h_dim = edge_h_dim self.num_layers = num_layers self.out_dim = out_dim activations = (F.silu, None) # Node input embedding self.W_v = torch.nn.Sequential( LayerNorm(self.node_in_dim), GVP(self.node_in_dim, self.node_h_dim, activations=(None, None), vector_gate=True) ) # Edge input embedding self.W_e = torch.nn.Sequential( LayerNorm(self.edge_in_dim), GVP(self.edge_in_dim, self.edge_h_dim, activations=(None, None), vector_gate=True) ) # Encoder layers (supports multiple conformations) self.encoder_layers = nn.ModuleList( MultiGVPConvLayer(self.node_h_dim, self.edge_h_dim, activations=activations, vector_gate=True, drop_rate=drop_rate, norm_first=True) for _ in range(num_layers)) # Output self.W_out = torch.nn.Sequential( LayerNorm(self.node_h_dim), GVP(self.node_h_dim, self.node_h_dim, activations=(None, None), vector_gate=True), GVP(self.node_h_dim, (self.out_dim, 0), activations=(None, None)) ) def forward(self, batch): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features: # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) # h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) h_V = (h_V[0].mean(dim=1), h_V[1].mean(dim=1)) logits = self.W_out(h_V) # (n_nodes, out_dim) return logits def sample(self, batch, n_samples, temperature=0.1, return_logits=False): with torch.no_grad(): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features # h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) h_V = (h_V[0].mean(dim=1), h_V[1].mean(dim=1)) logits = self.W_out(h_V) # (n_nodes, out_dim) probs = F.softmax(logits / temperature, dim=-1) seq = torch.multinomial(probs, n_samples, replacement=True) # (n_nodes, n_samples) if return_logits: return seq.permute(1, 0).contiguous(), logits.unsqueeze(0).repeat(n_samples, 1, 1) else: return seq.permute(1, 0).contiguous() def pool_multi_conf(self, h_V, h_E, mask_confs, edge_index): if mask_confs.size(1) == 1: # Number of conformations is 1, no need to pool return (h_V[0][:, 0], h_V[1][:, 0]), (h_E[0][:, 0], h_E[1][:, 0]) # True num_conf for masked mean pooling n_conf_true = mask_confs.sum(1, keepdim=True) # (n_nodes, 1) # Mask scalar features mask = mask_confs.unsqueeze(2) # (n_nodes, n_conf, 1) h_V0 = h_V[0] * mask h_E0 = h_E[0] * mask[edge_index[0]] # Mask vector features mask = mask.unsqueeze(3) # (n_nodes, n_conf, 1, 1) h_V1 = h_V[1] * mask h_E1 = h_E[1] * mask[edge_index[0]] # Average pooling multi-conformation features h_V = (h_V0.sum(dim=1) / n_conf_true, # (n_nodes, d_s) h_V1.sum(dim=1) / n_conf_true.unsqueeze(2)) # (n_nodes, d_v, 3) h_E = (h_E0.sum(dim=1) / n_conf_true[edge_index[0]], # (n_edges, d_se) h_E1.sum(dim=1) / n_conf_true[edge_index[0]].unsqueeze(2)) # (n_edges, d_ve, 3) return h_V, h_E 添加edge量： 只修改layers.py:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 ################################################################ # Generalisation of Geometric Vector Perceptron, Jing et al. # for explicit multi-state biomolecule representation learning. # Original repository: https://github.com/drorlab/gvp-pytorch # MODIFIED: Added HybridGVPLongShortLayer for deep fusion of # local geometric message passing and an efficient long-short attention mechanism. # VERSION 3: Final robust version incorporating all valid feedback. ################################################################ import functools import torch from torch import nn import torch.nn.functional as F import torch_geometric from torch_geometric.nn import MessagePassing from torch_scatter import scatter_add ######################################################################### # FINAL VERSION: 辅助函数 def _create_batch_mask(batch, dtype, device): \u0026#34;\u0026#34;\u0026#34;根据 torch_geometric 的 batch 向量创建块对角注意力掩码。\u0026#34;\u0026#34;\u0026#34; if batch is None: return None # 返回None，在主函数中处理 num_nodes = batch.size(0) same_graph = batch.unsqueeze(1) == batch.unsqueeze(0) mask = torch.zeros((num_nodes, num_nodes), device=device, dtype=dtype) mask.masked_fill_(~same_graph, torch.finfo(dtype).min) return mask def _create_window_mask(seq_len: int, window_size: int, device: torch.device, dtype: torch.dtype) -\u0026gt; torch.Tensor: \u0026#34;\u0026#34;\u0026#34; 高效的向量化窗口掩码生成 \u0026#34;\u0026#34;\u0026#34; half = window_size // 2 idx = torch.arange(seq_len, device=device) dist = (idx.unsqueeze(1) - idx.unsqueeze(0)).abs() mask = torch.zeros((seq_len, seq_len), device=device, dtype=dtype) mask.masked_fill_(dist \u0026gt; half, torch.finfo(dtype).min) return mask # 位置: 放在 _create_window_mask 函数之后 def _create_graph_mask(edge_index, num_nodes, device, dtype): \u0026#34;\u0026#34;\u0026#34; 根据 edge_index 创建一个稠密的注意力掩码. 这个掩码允许节点关注其在图中的直接邻居。 \u0026#34;\u0026#34;\u0026#34; # 初始化一个完全屏蔽的掩码，所有值为-inf mask = torch.full((num_nodes, num_nodes), torch.finfo(dtype).min, device=device, dtype=dtype) # 允许节点关注自身 (self-attention) mask.fill_diagonal_(0.0) # 允许节点关注其邻居 src, dst = edge_index mask[src, dst] = 0.0 return mask # FINAL VERSION: Long-Short Attention 模块 class LongShortAttention(nn.Module): \u0026#34;\u0026#34;\u0026#34; 实现了Long-Short Transformer思想的注意力模块. - 短程: 滑动窗口自注意力 - 长程: 动态投影 - 融合: DualLN + 拼接注意力得分 \u0026#34;\u0026#34;\u0026#34; def __init__(self, embed_dim, num_heads, window_size, proj_rank, dropout=0.1): super().__init__() assert embed_dim % num_heads == 0, \u0026#34;embed_dim 必须能被 num_heads 整除\u0026#34; self.embed_dim = embed_dim self.num_heads = num_heads self.head_dim = embed_dim // num_heads self.window_size = window_size self.proj_rank = proj_rank self.q_proj = nn.Linear(embed_dim, embed_dim) self.k_proj = nn.Linear(embed_dim, embed_dim) self.v_proj = nn.Linear(embed_dim, embed_dim) self.out_proj = nn.Linear(embed_dim, embed_dim) self.d_proj_matrix_proj = nn.Linear(embed_dim, proj_rank) self.ln_q = nn.LayerNorm(embed_dim) # 采纳建议：为K和V使用独立的LN self.ln_k_short = nn.LayerNorm(embed_dim) self.ln_v_short = nn.LayerNorm(embed_dim) self.ln_k_long = nn.LayerNorm(embed_dim) self.ln_v_long = nn.LayerNorm(embed_dim) self.dropout = nn.Dropout(dropout) def forward(self, x, edge_index, batch=None): bsz, seq_len, _ = x.shape x_norm = self.ln_q(x) q = self.q_proj(x_norm) k = self.k_proj(x) v = self.v_proj(x) k_short, v_short = self.ln_k_short(k), self.ln_v_short(v) k_long, v_long = self.ln_k_long(k), self.ln_v_long(v) q_s = q.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2) k_s = k_short.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2) v_s = v_short.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2) # --- 开始修改 --- window_mask = _create_window_mask(seq_len, self.window_size, x.device, x.dtype) batch_mask = _create_batch_mask(batch, x.dtype, x.device) # [新] 生成图邻居掩码 graph_mask = _create_graph_mask(edge_index, seq_len, x.device, x.dtype) # [核心修改] 融合掩码: # 节点i可以关注节点j，如果j在i的序列窗口内(值为0) 或 j是i的图邻居(值为0) # torch.max(mask1, mask2) 可以完美实现这种 \u0026#34;OR\u0026#34; 逻辑 short_range_mask = torch.max(window_mask, graph_mask) # 将批处理掩码加上去，确保不同图的节点间不产生注意力 if batch_mask is not None: attn_mask = short_range_mask + batch_mask else: attn_mask = short_range_mask attn_scores_short = torch.matmul(q_s, k_s.transpose(-2, -1)) / (self.head_dim ** 0.5) attn_scores_short = attn_scores_short + attn_mask.unsqueeze(0) # --- 结束修改 --- proj_matrix = F.softmax(self.d_proj_matrix_proj(k_long), dim=1).transpose(1, 2) k_compressed = torch.matmul(proj_matrix, k_long) v_compressed = torch.matmul(proj_matrix, v_long) q_l = q.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2) k_c = k_compressed.view(bsz, self.proj_rank, self.num_heads, self.head_dim).transpose(1, 2) v_c = v_compressed.view(bsz, self.proj_rank, self.num_heads, self.head_dim).transpose(1, 2) attn_scores_long = torch.matmul(q_l, k_c.transpose(-2, -1)) / (self.head_dim ** 0.5) attn_scores_fused = torch.cat([attn_scores_short, attn_scores_long], dim=-1) attn_probs = F.softmax(attn_scores_fused, dim=-1) attn_probs = self.dropout(attn_probs) attn_probs_short = attn_probs[..., :seq_len] attn_probs_long = attn_probs[..., seq_len:] output_short = torch.matmul(attn_probs_short, v_s) output_long = torch.matmul(attn_probs_long, v_c) output = output_short + output_long output = output.transpose(1, 2).contiguous().view(bsz, seq_len, self.embed_dim) return self.out_proj(output) # (PositionwiseFeedForward 类保持不变) class PositionwiseFeedForward(nn.Module): \u0026#39;\u0026#39;\u0026#39; A two-layer Feed-Forward-Network. \u0026#39;\u0026#39;\u0026#39; def __init__(self, d_in, d_hid, dropout=0.1): super().__init__() self.w_1 = nn.Linear(d_in, d_hid) self.w_2 = nn.Linear(d_hid, d_in) self.dropout = nn.Dropout(dropout) self.activation = F.silu def forward(self, x): return self.w_2(self.dropout(self.activation(self.w_1(x)))) # FINAL VERSION: HybridGVPLongShortLayer class HybridGVPLongShortLayer(nn.Module): \u0026#39;\u0026#39;\u0026#39; 将GVP-GNN与Long-Short Attention思想深度融合的混合层。 \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_dims, edge_dims, num_attn_head=4, ls_window_size=50, ls_proj_rank=32, n_message=3, drop_rate=.1, activations=(F.silu, torch.sigmoid), vector_gate=True, ): super(HybridGVPLongShortLayer, self).__init__() self.norm_gvp = LayerNorm(node_dims) self.gvp_conv = MultiGVPConv(node_dims, node_dims, edge_dims, n_message, aggr=\u0026#34;mean\u0026#34;, activations=activations, vector_gate=vector_gate) self.dropout_gvp = Dropout(drop_rate) self.norm_attn = nn.LayerNorm(node_dims[0]) self.ls_attention = LongShortAttention(embed_dim=node_dims[0], num_heads=num_attn_head, window_size=ls_window_size, proj_rank=ls_proj_rank, dropout=drop_rate) self.dropout_attn = nn.Dropout(drop_rate) self.norm_ffn = nn.LayerNorm(node_dims[0]) self.ffn = PositionwiseFeedForward(d_in=node_dims[0], d_hid=node_dims[0] * 4, dropout=drop_rate) self.dropout_ffn = nn.Dropout(drop_rate) def forward(self, x, edge_index, edge_attr, batch=None): x_res_gvp = x x_norm_gvp = self.norm_gvp(x) dh_local = self.gvp_conv(x_norm_gvp, edge_index, edge_attr) x_local = tuple_sum(x_res_gvp, self.dropout_gvp(dh_local)) s_local, v_local = x_local s_res_attn = s_local s_norm_attn = self.norm_attn(s_local) n_nodes, n_conf, d_s = s_norm_attn.shape s_reshaped = s_norm_attn.permute(1, 0, 2) #s_attn_out = self.ls_attention(s_reshaped, batch=batch) # 修改为 (将 edge_index 传递下去): s_attn_out = self.ls_attention(s_reshaped, edge_index=edge_index, batch=batch) # --- 结束修改 --- s_attn_out = s_attn_out.permute(1, 0, 2) s_after_attn = s_res_attn + self.dropout_attn(s_attn_out) s_res_ffn = s_after_attn s_norm_ffn = self.norm_ffn(s_after_attn) s_ffn_out = self.ffn(s_norm_ffn) s_final = s_res_ffn + self.dropout_ffn(s_ffn_out) v_final = v_local return (s_final, v_final) class GVPConvLayer(nn.Module): \u0026#39;\u0026#39;\u0026#39; Full graph convolution / message passing layer with Geometric Vector Perceptrons. Residually updates node embeddings with aggregated incoming messages, applies a pointwise feedforward network to node embeddings, and returns updated node embeddings. To only compute the aggregated messages, see `GVPConv`. :param node_dims: node embedding dimensions (n_scalar, n_vector) :param edge_dims: input edge embedding dimensions (n_scalar, n_vector) :param n_message: number of GVPs to use in message function :param n_feedforward: number of GVPs to use in feedforward function :param drop_rate: drop probability in all dropout layers :param autoregressive: if `True`, this `GVPConvLayer` will be used with a different set of input node embeddings for messages where src \u0026gt;= dst :param activations: tuple of functions (scalar_act, vector_act) to use in GVPs :param vector_gate: whether to use vector gating. (vector_act will be used as sigma^+ in vector gating if `True`) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_dims, edge_dims, n_message=3, n_feedforward=2, drop_rate=.1, autoregressive=False, activations=(F.silu, torch.sigmoid), vector_gate=True, residual=True, norm_first=False, ): super(GVPConvLayer, self).__init__() self.conv = GVPConv(node_dims, node_dims, edge_dims, n_message, aggr=\u0026#34;add\u0026#34; if autoregressive else \u0026#34;mean\u0026#34;, activations=activations, vector_gate=vector_gate) GVP_ = functools.partial(GVP, activations=activations, vector_gate=vector_gate) self.norm = nn.ModuleList([LayerNorm(node_dims) for _ in range(2)]) self.dropout = nn.ModuleList([Dropout(drop_rate) for _ in range(2)]) ff_func = [] if n_feedforward == 1: ff_func.append(GVP_(node_dims, node_dims)) else: hid_dims = 4*node_dims[0], 2*node_dims[1] ff_func.append(GVP_(node_dims, hid_dims)) for i in range(n_feedforward-2): ff_func.append(GVP_(hid_dims, hid_dims)) ff_func.append(GVP_(hid_dims, node_dims, activations=(None, None))) self.ff_func = nn.Sequential(*ff_func) self.residual = residual self.norm_first = norm_first def forward(self, x, edge_index, edge_attr, autoregressive_x=None, node_mask=None): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor` :param edge_index: array of shape [2, n_edges] :param edge_attr: tuple (s, V) of `torch.Tensor` :param autoregressive_x: tuple (s, V) of `torch.Tensor`. If not `None`, will be used as src node embeddings for forming messages where src \u0026gt;= dst. The current node embeddings `x` will still be the base of the update and the pointwise feedforward. :param node_mask: array of type `bool` to index into the first dim of node embeddings (s, V). If not `None`, only these nodes will be updated. \u0026#39;\u0026#39;\u0026#39; if autoregressive_x is not None: src, dst = edge_index mask = src \u0026lt; dst edge_index_forward = edge_index[:, mask] edge_index_backward = edge_index[:, ~mask] edge_attr_forward = tuple_index(edge_attr, mask) edge_attr_backward = tuple_index(edge_attr, ~mask) dh = tuple_sum( self.conv(x, edge_index_forward, edge_attr_forward), self.conv(autoregressive_x, edge_index_backward, edge_attr_backward) ) count = scatter_add(torch.ones_like(dst), dst, dim_size=dh[0].size(0)).clamp(min=1).unsqueeze(-1) dh = dh[0] / count, dh[1] / count.unsqueeze(-1) else: if self.norm_first: dh = self.conv(self.norm[0](x), edge_index, edge_attr) else: dh = self.conv(x, edge_index, edge_attr) if node_mask is not None: x_ = x x, dh = tuple_index(x, node_mask), tuple_index(dh, node_mask) if self.norm_first: x = tuple_sum(x, self.dropout[0](dh)) dh = self.ff_func(self.norm[1](x)) x = tuple_sum(x, self.dropout[1](dh)) else: x = self.norm[0](tuple_sum(x, self.dropout[0](dh))) if self.residual else dh dh = self.ff_func(x) x = self.norm[1](tuple_sum(x, self.dropout[1](dh))) if self.residual else dh if node_mask is not None: x_[0][node_mask], x_[1][node_mask] = x[0], x[1] x = x_ return x class GVPConv(MessagePassing): \u0026#39;\u0026#39;\u0026#39; Graph convolution / message passing with Geometric Vector Perceptrons. Takes in a graph with node and edge embeddings, and returns new node embeddings. This does NOT do residual updates and pointwise feedforward layers ---see `GVPConvLayer`. :param in_dims: input node embedding dimensions (n_scalar, n_vector) :param out_dims: output node embedding dimensions (n_scalar, n_vector) :param edge_dims: input edge embedding dimensions (n_scalar, n_vector) :param n_layers: number of GVPs in the message function :param module_list: preconstructed message function, overrides n_layers :param aggr: should be \u0026#34;add\u0026#34; if some incoming edges are masked, as in a masked autoregressive decoder architecture, otherwise \u0026#34;mean\u0026#34; :param activations: tuple of functions (scalar_act, vector_act) to use in GVPs :param vector_gate: whether to use vector gating. (vector_act will be used as sigma^+ in vector gating if `True`) \u0026#39;\u0026#39;\u0026#39; def __init__(self, in_dims, out_dims, edge_dims, n_layers=3, module_list=None, aggr=\u0026#34;mean\u0026#34;, activations=(F.silu, torch.sigmoid), vector_gate=True): super(GVPConv, self).__init__(aggr=aggr) self.si, self.vi = in_dims self.so, self.vo = out_dims self.se, self.ve = edge_dims GVP_ = functools.partial(GVP, activations=activations, vector_gate=vector_gate) module_list = module_list or [] if not module_list: if n_layers == 1: module_list.append( GVP_((2*self.si + self.se, 2*self.vi + self.ve), (self.so, self.vo))) else: module_list.append( GVP_((2*self.si + self.se, 2*self.vi + self.ve), out_dims) ) for i in range(n_layers - 2): module_list.append(GVP_(out_dims, out_dims)) module_list.append(GVP_(out_dims, out_dims, activations=(None, None))) self.message_func = nn.Sequential(*module_list) def forward(self, x, edge_index, edge_attr): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor` :param edge_index: array of shape [2, n_edges] :param edge_attr: tuple (s, V) of `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; x_s, x_v = x message = self.propagate(edge_index, s=x_s, v=x_v.contiguous().view(x_v.shape[0], x_v.shape[1] * 3), edge_attr=edge_attr) return _split(message, self.vo) def message(self, s_i, v_i, s_j, v_j, edge_attr): v_j = v_j.view(v_j.shape[0], v_j.shape[1]//3, 3) v_i = v_i.view(v_i.shape[0], v_i.shape[1]//3, 3) message = tuple_cat((s_j, v_j), edge_attr, (s_i, v_i)) message = self.message_func(message) return _merge(*message) ######################################################################### class MultiGVPConvLayer(nn.Module): \u0026#39;\u0026#39;\u0026#39; GVPConvLayer for handling multiple conformations (encoder-only) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_dims, edge_dims, n_message=3, n_feedforward=2, drop_rate=.1, activations=(F.silu, torch.sigmoid), vector_gate=True, residual=True, norm_first=False, ): super(MultiGVPConvLayer, self).__init__() self.conv = MultiGVPConv(node_dims, node_dims, edge_dims, n_message, aggr=\u0026#34;mean\u0026#34;, activations=activations, vector_gate=vector_gate) GVP_ = functools.partial(GVP, activations=activations, vector_gate=vector_gate) self.norm = nn.ModuleList([LayerNorm(node_dims) for _ in range(2)]) self.dropout = nn.ModuleList([Dropout(drop_rate) for _ in range(2)]) ff_func = [] if n_feedforward == 1: ff_func.append(GVP_(node_dims, node_dims)) else: hid_dims = 4*node_dims[0], 2*node_dims[1] ff_func.append(GVP_(node_dims, hid_dims)) for i in range(n_feedforward-2): ff_func.append(GVP_(hid_dims, hid_dims)) ff_func.append(GVP_(hid_dims, node_dims, activations=(None, None))) self.ff_func = nn.Sequential(*ff_func) self.residual = residual self.norm_first = norm_first def forward(self, x, edge_index, edge_attr): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor` :param edge_index: array of shape [2, n_edges] :param edge_attr: tuple (s, V) of `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; if self.norm_first: dh = self.conv(self.norm[0](x), edge_index, edge_attr) x = tuple_sum(x, self.dropout[0](dh)) dh = self.ff_func(self.norm[1](x)) x = tuple_sum(x, self.dropout[1](dh)) else: dh = self.conv(x, edge_index, edge_attr) x = self.norm[0](tuple_sum(x, self.dropout[0](dh))) if self.residual else dh dh = self.ff_func(x) x = self.norm[1](tuple_sum(x, self.dropout[1](dh))) if self.residual else dh return x class MultiGVPConv(MessagePassing): \u0026#39;\u0026#39;\u0026#39; GVPConv for handling multiple conformations \u0026#39;\u0026#39;\u0026#39; def __init__(self, in_dims, out_dims, edge_dims, n_layers=3, module_list=None, aggr=\u0026#34;mean\u0026#34;, activations=(F.silu, torch.sigmoid), vector_gate=True): super(MultiGVPConv, self).__init__(aggr=aggr) self.si, self.vi = in_dims self.so, self.vo = out_dims self.se, self.ve = edge_dims GVP_ = functools.partial(GVP, activations=activations, vector_gate=vector_gate) module_list = module_list or [] if not module_list: if n_layers == 1: module_list.append( GVP_((2*self.si + self.se, 2*self.vi + self.ve), (self.so, self.vo))) else: module_list.append( GVP_((2*self.si + self.se, 2*self.vi + self.ve), out_dims) ) for i in range(n_layers - 2): module_list.append(GVP_(out_dims, out_dims)) module_list.append(GVP_(out_dims, out_dims, activations=(None, None))) self.message_func = nn.Sequential(*module_list) def forward(self, x, edge_index, edge_attr): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor` :param edge_index: array of shape [2, n_edges] :param edge_attr: tuple (s, V) of `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; x_s, x_v = x n_conf = x_s.shape[1] # x_s: [n_nodes, n_conf, d] -\u0026gt; [n_nodes, n_conf * d] x_s = x_s.contiguous().view(x_s.shape[0], x_s.shape[1] * x_s.shape[2]) # x_v: [n_nodes, n_conf, d, 3] -\u0026gt; [n_nodes, n_conf * d * 3] x_v = x_v.contiguous().view(x_v.shape[0], x_v.shape[1] * x_v.shape[2] * 3) message = self.propagate(edge_index, s=x_s, v=x_v, edge_attr=edge_attr) return _split_multi(message, self.so, self.vo, n_conf) def message(self, s_i, v_i, s_j, v_j, edge_attr): # [n_nodes, n_conf * d] -\u0026gt; [n_nodes, n_conf, d] s_i = s_i.view(s_i.shape[0], s_i.shape[1]//self.si, self.si) s_j = s_j.view(s_j.shape[0], s_j.shape[1]//self.si, self.si) # [n_nodes, n_conf * d * 3] -\u0026gt; [n_nodes, n_conf, d, 3] v_i = v_i.view(v_i.shape[0], v_i.shape[1]//(self.vi * 3), self.vi, 3) v_j = v_j.view(v_j.shape[0], v_j.shape[1]//(self.vi * 3), self.vi, 3) message = tuple_cat((s_j, v_j), edge_attr, (s_i, v_i)) message = self.message_func(message) return _merge_multi(*message) ######################################################################### class GVP(nn.Module): \u0026#39;\u0026#39;\u0026#39; Geometric Vector Perceptron. See manuscript and README.md for more details. :param in_dims: tuple (n_scalar, n_vector) :param out_dims: tuple (n_scalar, n_vector) :param h_dim: intermediate number of vector channels, optional :param activations: tuple of functions (scalar_act, vector_act) :param vector_gate: whether to use vector gating. (vector_act will be used as sigma^+ in vector gating if `True`) \u0026#39;\u0026#39;\u0026#39; def __init__(self, in_dims, out_dims, h_dim=None, activations=(F.silu, torch.sigmoid), vector_gate=True): super(GVP, self).__init__() self.si, self.vi = in_dims self.so, self.vo = out_dims self.vector_gate = vector_gate if self.vi: self.h_dim = h_dim or max(self.vi, self.vo) self.wh = nn.Linear(self.vi, self.h_dim, bias=False) self.ws = nn.Linear(self.h_dim + self.si, self.so) if self.vo: self.wv = nn.Linear(self.h_dim, self.vo, bias=False) if self.vector_gate: self.wsv = nn.Linear(self.so, self.vo) else: self.ws = nn.Linear(self.si, self.so) self.scalar_act, self.vector_act = activations self.dummy_param = nn.Parameter(torch.empty(0)) def forward(self, x): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor`, or (if vectors_in is 0), a single `torch.Tensor` :return: tuple (s, V) of `torch.Tensor`, or (if vectors_out is 0), a single `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; if self.vi: s, v = x v = torch.transpose(v, -1, -2) vh = self.wh(v) vn = _norm_no_nan(vh, axis=-2) s = self.ws(torch.cat([s, vn], -1)) if self.vo: v = self.wv(vh) v = torch.transpose(v, -1, -2) if self.vector_gate: if self.vector_act: gate = self.wsv(self.vector_act(s)) else: gate = self.wsv(s) v = v * torch.sigmoid(gate).unsqueeze(-1) elif self.vector_act: v = v * self.vector_act( _norm_no_nan(v, axis=-1, keepdims=True)) else: s = self.ws(x) if self.vo: v = torch.zeros(s.shape[0], self.vo, 3, device=self.dummy_param.device) if self.scalar_act: s = self.scalar_act(s) return (s, v) if self.vo else s ######################################################################### class _VDropout(nn.Module): \u0026#39;\u0026#39;\u0026#39; Vector channel dropout where the elements of each vector channel are dropped together. \u0026#39;\u0026#39;\u0026#39; def __init__(self, drop_rate): super(_VDropout, self).__init__() self.drop_rate = drop_rate self.dummy_param = nn.Parameter(torch.empty(0)) def forward(self, x): \u0026#39;\u0026#39;\u0026#39; :param x: `torch.Tensor` corresponding to vector channels \u0026#39;\u0026#39;\u0026#39; device = self.dummy_param.device if not self.training: return x mask = torch.bernoulli( (1 - self.drop_rate) * torch.ones(x.shape[:-1], device=device) ).unsqueeze(-1) x = mask * x / (1 - self.drop_rate) return x class Dropout(nn.Module): \u0026#39;\u0026#39;\u0026#39; Combined dropout for tuples (s, V). Takes tuples (s, V) as input and as output. \u0026#39;\u0026#39;\u0026#39; def __init__(self, drop_rate): super(Dropout, self).__init__() self.sdropout = nn.Dropout(drop_rate) self.vdropout = _VDropout(drop_rate) def forward(self, x): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor`, or single `torch.Tensor` (will be assumed to be scalar channels) \u0026#39;\u0026#39;\u0026#39; if type(x) is torch.Tensor: return self.sdropout(x) s, v = x return self.sdropout(s), self.vdropout(v) class LayerNorm(nn.Module): \u0026#39;\u0026#39;\u0026#39; Combined LayerNorm for tuples (s, V). Takes tuples (s, V) as input and as output. \u0026#39;\u0026#39;\u0026#39; def __init__(self, dims): super(LayerNorm, self).__init__() self.s, self.v = dims self.scalar_norm = nn.LayerNorm(self.s) def forward(self, x): \u0026#39;\u0026#39;\u0026#39; :param x: tuple (s, V) of `torch.Tensor`, or single `torch.Tensor` (will be assumed to be scalar channels) \u0026#39;\u0026#39;\u0026#39; if not self.v: return self.scalar_norm(x) s, v = x vn = _norm_no_nan(v, axis=-1, keepdims=True, sqrt=False) vn = torch.sqrt(torch.mean(vn, dim=-2, keepdim=True)) return self.scalar_norm(s), v / vn def tuple_sum(*args): \u0026#39;\u0026#39;\u0026#39; Sums any number of tuples (s, V) elementwise. \u0026#39;\u0026#39;\u0026#39; return tuple(map(sum, zip(*args))) def tuple_cat(*args, dim=-1): \u0026#39;\u0026#39;\u0026#39; Concatenates any number of tuples (s, V) elementwise. :param dim: dimension along which to concatenate when viewed as the `dim` index for the scalar-channel tensors. This means that `dim=-1` will be applied as `dim=-2` for the vector-channel tensors. \u0026#39;\u0026#39;\u0026#39; dim %= len(args[0][0].shape) s_args, v_args = list(zip(*args)) return torch.cat(s_args, dim=dim), torch.cat(v_args, dim=dim) def tuple_index(x, idx): \u0026#39;\u0026#39;\u0026#39; Indexes into a tuple (s, V) along the first dimension. :param idx: any object which can be used to index into a `torch.Tensor` \u0026#39;\u0026#39;\u0026#39; return x[0][idx], x[1][idx] def randn(n, dims, device=\u0026#34;cpu\u0026#34;): \u0026#39;\u0026#39;\u0026#39; Returns random tuples (s, V) drawn elementwise from a normal distribution. :param n: number of data points :param dims: tuple of dimensions (n_scalar, n_vector) :return: (s, V) with s.shape = (n, n_scalar) and V.shape = (n, n_vector, 3) \u0026#39;\u0026#39;\u0026#39; return torch.randn(n, dims[0], device=device), \\ torch.randn(n, dims[1], 3, device=device) def _norm_no_nan(x, axis=-1, keepdims=False, eps=1e-8, sqrt=True): \u0026#39;\u0026#39;\u0026#39; L2 norm of tensor clamped above a minimum value `eps`. :param sqrt: if `False`, returns the square of the L2 norm \u0026#39;\u0026#39;\u0026#39; out = torch.clamp(torch.sum(torch.square(x), axis, keepdims), min=eps) return torch.sqrt(out) if sqrt else out def _split(x, nv): \u0026#39;\u0026#39;\u0026#39; Splits a merged representation of (s, V) back into a tuple. Should be used only with `_merge(s, V)` and only if the tuple representation cannot be used. :param x: the `torch.Tensor` returned from `_merge` :param nv: the number of vector channels in the input to `_merge` \u0026#39;\u0026#39;\u0026#39; s = x[..., :-3 * nv] v = x[..., -3 * nv:].contiguous().view(x.shape[0], nv, 3) return s, v def _merge(s, v): \u0026#39;\u0026#39;\u0026#39; Merges a tuple (s, V) into a single `torch.Tensor`, where the vector channels are flattened and appended to the scalar channels. Should be used only if the tuple representation cannot be used. Use `_split(x, nv)` to reverse. \u0026#39;\u0026#39;\u0026#39; v = v.contiguous().view(v.shape[0], v.shape[1] * 3) return torch.cat([s, v], -1) def _split_multi(x, ns, nv, n_conf=5): \u0026#39;\u0026#39;\u0026#39; _split for multiple conformers \u0026#39;\u0026#39;\u0026#39; s = x[..., :-3 * nv * n_conf].contiguous().view(x.shape[0], n_conf, ns) v = x[..., -3 * nv * n_conf:].contiguous().view(x.shape[0], n_conf, nv, 3) return s, v def _merge_multi(s, v): \u0026#39;\u0026#39;\u0026#39; _merge for multiple conformers \u0026#39;\u0026#39;\u0026#39; # s: [n_nodes, n_conf, d] -\u0026gt; [n_nodes, n_conf * d] s = s.contiguous().view(s.shape[0], s.shape[1] * s.shape[2]) # v: [n_nodes, n_conf, d, 3] -\u0026gt; [n_nodes, n_conf * d * 3] v = v.contiguous().view(v.shape[0], v.shape[1] * v.shape[2] * 3) return torch.cat([s, v], -1) ","date":"2025-09-30T19:45:11+08:00","permalink":"https://mosfish.github.io/p/deep-learning-attempt-for-rna-inverse-design/","title":"Deep Learning attempt for RNA inverse design?"},{"content":"关于Deep Learning与RNA inverse folding的文献 上周正在摸鱼，突然看见导的zoom发了个邮件：“xxx invites you \u0026hellip;\u0026hellip; at 11:30\u0026quot;还以为改时间了，但是看见原本9点半的链接还没取消，于是开会那天ppt的理论部分还没做，9点半进去看看情况（万一选择这个时候开始呢），结果听到，”好的我们开始吧“。\n于是，卒。\n预料内的被批评了，毕竟ppt只有实验没有原理，被训也是正常。这周啥也不干了，好好读文献吧，要不然怎么在文章里tell(吹) a(牛) story(呢)，下周一个个汇报。此处我就简单写一些我认为相对有启发的内容。\nA Hyperbolic Discrete Diffusion 3D RNA Inverse Folding Model for functional RNA design 开幕雷击，这是一篇刊，快50页，读死我了。简称这个为RIdiffusion吧。\nAbstract\u0026amp;Introduction Background: revolutionary opportunities for diverse RNA-based biotechnologies and biomedical applications. primary goal of RNA inverse folding is to design nucleotide sequences that can fold into a given RNA secondary or tertiary structure.\nChallenge: limited availability of experimentally derived 3D structural data and unique characteristics of RNA 3D structures; existing tools either focus on 2D inverse folding tasks or learn limited 3D structural features from experimentally determined and predicted 3D structure datasets for the 3D inverse folding problem. High-resolution RNA structures are significantly less common compared to those of proteins. RIdiffusion, a hyperbolic denoising diffusion generative RNA inverse folding model.\nRIdiffusion efficiently recovers the distribution of nucleotides for targeted RNA 3D structures based on limited training samples using a discrete diffusion model.\n事实上背景一般都是车轱辘话，但是不同的文章聚焦的challenge不一样。本文章最令我印象深刻的地方在于其利用geometric deep learning和discrete diffusion model结合起来，而且评估的很细致，工作量很够。\nstructure based. the promise of creating novel functional RNAs. The “low-sample” challenge underscores the importance of learning efficiency in generative models in 3D RNA inverse folding tasks.说白了，数据少，那就学的高效，就这意思。\n关于Diffusion: 把inverse folding 想象成diffusion的denoising过程。\n之后通过生物学知识: RNA structures exhibit inherent hierarchical organization (e.g., from base-paring, secondary structure elements and remote pseudoknots to complex 3D shapes)引出hyperbolic space.\n为什么要提及这个呢？因为\ncompared to Euclidean space, a hyperbolic distance better captures molecular differences and improve performance in small molecule generation tasks\n也就是说这个hb比euc更能展现结构特征，或者说，更能体现subtle structural的区别。作者通过以下这张图来介绍：\n我们其实重点关注A,D就行，A是变换的一个图示结构，D是rna结构铺在hb空间里的形态，简而言之，不同chain（或者backbone）分开了，也就更好捕捉特征。\n模型概况 hyperbolic equivariant graph neural networks (HEGNNs) to parameterize the discrete diffusion model, and effectively capture the 3D structural characteristics by incorporating RNA’s geometric features and topological properties into the generation process.\n整个的framework如图：\nMATERIALS AND METHODS 这部分写的好细好牛，我大部分看不懂，简单说一个Hyperbolic Equivariant Graph Denoising Network，\n一般的模型处理这种3D数据的时候会丢失数据，\n因而作者utilize SE(3) equivariant neural layers from Equivariant Graph Neural Networks (EGNN).49 This approach allows the model to preserve SO(3) rotational equivariance and E(3) translational invariance when updating the representations of nodes and edges, thereby retaining geometric information and ensuring the robustness and effectiveness of the hidden representations, to enable the EGNN network to update edge.其实就是加了个层。\nDatasets and Setup 实际上我更在意作者如何split的？\nWe followed the same splitting methods outlined in RDesign to ensure a high-quality dataset with only experimentally derived structures, which consists of 1773 structures for training, 221 structures for validation, and 223 structures for testing in an 8:1:1 ratio.\n这也是按照8:1:1分的，所以我现在遇到的事情思考的确实没啥毛病。\n除此之外，为了评价泛化能力，作者用PSI-CD-HIT，基于nucleotide similarity来cluster数据 , 并setting similarity thresholds of 0.8, 0.9, and 1.0。\nEvaluation Metrics 本文的评估标准我很感兴趣，除了我们通常用的RR，还提出了Macro-F1 score，我贴个引用：\nThe Macro-F1 score is used to assess the accuracy and comprehensiveness of the model in predicting protein or RNA sequences, particularly in cases where the distribution of different letter residues is imbalanced, by evaluating the Macro-F1 score for each residue in the sequence.\n叽里咕噜唧唧歪歪说什么呢，没看懂，太生物学了。和我的3.98rmb/h的炼丹炉说去吧。 $$ NoveltyScore(x_i) = 1.0 - RecoveryRate(x_i,x_{mostsimilar}) $$ 还有一个GSN, Global-scale Novelty，就是100个样本按照RR分层来抽。\n以及和SCC很像的，基于RhoFold折叠后再用US-align计算结构相似性也就是RMSD.\nBaselines 作者拿几个老熟人来对比，包括1个RNA tertiary structure inverse folding model, 仨protein tertiary structure inverse folding baselines, 1个Transformer-based graph GNN network for graph structure: gRNAde, PiFold, StructGNN, GVP-GNN, and GraphTrans. 虽然没搞懂为什么用蛋白质模型来预测rna，不过看来好像是在rna数据集上面重新训练了一下作对比试验。至于RiboDiffusion与RhoDesign，确实没有提供训练脚本也没办法控制超参数。\nResults 其实不用看就知道，肯定这好那好嘛，要不然发出来干啥。不过我注意到作者：\nwe divided the dataset of seq-0.8 into short (\u0026lt;50nt), medium (50~100nt), and long (\u0026gt;100nt)\n嗯？这样划分吗？其实也行，和RiboDiffusion的划分一致。\n至于以下的我贴个原文，其实云里雾里的：\nThe novelty of generative designs can be viewed from two perspectives: sequence novelty and physicochemical properties novelty. In our case, sequence and physicochemical properties (derived from sequence) novelty are important in RNA 3D inverse folding. Indeed, sequence features such as physicochemical properties play a crucial role in functional RNA design. For instance, it was reported that natural RNAs show privileged physicochemical property space which is related to their biological functions. Other sequence features like GC content are important properties related to developability of RNA molecules. Given the nature of one-to-many relationship between the targeted RNA structure and its possible sequences, the novelty and diversity of generated sequences are important considerations for improving physicochemical properties of the designed sequences.\n涉及生物学知识比较多，还有类似于理化特性的。\n之后抽样进行physicochemical properties space的评估。就是说三个部分应该有区别。\nBeyond RNA Structure Alone: Complex-Aware Feature Fusion for Tertiary Structure-based RNA Design Abstract important in synthetic biology and therapeutics limitation: overlook the role of complex-level information 事实上作者的观点是，光分析rna不行，还得去看有关系的complexes。\nour method incorporates protein features extracted by protein language model (e.g., ESM-2)\n没看懂，为什么要用蛋白质的feature来拟合rna？宛宛类卿是吗？\nTo address bio-logical complexity of protein-RNA interactions, propose a distance-aware filtering for local features from protein representation.\na high-affinity design framework that combines our CARD with an affinity evaluation model.\n多了个evaluation吗？有点意思。\nFinal goal: produce high-affinity RNA sequences\nIntroduction more sophisticated computational approaches that can model the complex relationship between RNA sequences and their structures. 作者提到了基于RL的LEARNA和Meta-LEARNA，基于3D图的RDesign和RhoDesign。\ndifferent from protein folding which roughly follows Anfinsen’s rule, RNAs are highly flexible and rely on interactions with proteins, DNA, and other biomolecules to achieve folding，又是一个表述rna结构灵活多变的。 RNAs may adopt various conformations by interacting with distinct macromolecules at different stages of functioning.不同阶段还会与大分子结合。 考虑到OVERLOOK那些information的局限性，那就加上不就得了。\n本文就是考虑rna结构特征与protein-RNA的情况，综合生成序列。\nOutline也如图一，有一个pre-trained protein language model (PLM)来处理蛋白质，以及Complex-Aware Transformer (CAFormer)来结合rna与蛋白质的特征，利用distance-aware filtering来选择作用区域忽略无关区域影响，以上使模型能够捕捉蛋白质-RNA复合物上下文信息并聚焦于复合体内部的相互作用区域。\n整体而言，作者迭代筛选生成的RNA序列，候选序列先根据预测的亲和力分数进行过滤，再通过多重折叠模型进行结构兼容性验证。\nAffinity Evaluation\n关于“亲和力”，作者提到了预测模型PNAB，DeePNAP，PredPRBA, PRdeltaGPred and PRA-Pred。\n然而RNA-protein complex结构数据太稀缺，CoPRA 整合了PRA310并提出multi-modal model，模型将RNA和蛋白质大型语言模型与全面的结构信息相结合。\n蚊香小课堂 作者提到inverse folding的发展与背景：\nRNA design aims to generate sequences that fold into predefined structures. Early methods focused on secondary structure optimization, using thermodynamic parameters and energy minimization. Tools like RNAfold predict RNA secondary structures based on the minimum free energy principle. As understanding of RNA structure has advanced, focus has shifted to complex tertiary structure-based design due to RNA’s high conformational flexibility, which challenges traditional thermodynamic methods. Recent deep learning approaches for RNA tertiary structure design include gRNAde, which utilizes geometric deep learning and graph neural networks to generate RNA sequences; RiboDiffusion, a diffusion model for inverse folding leveraging RNA backbone structures; RDesign, which employs a data-efficient learning framework with contrastive learning for tertiary structures; and Rhodesign, focusing on RNA aptamer design by guiding sequence generation through structural predictions.\n从热力学参数和能量最小化原理，到基于深度学习来预测rna。其实可以结合吧？\nMethods 作者的pipeline：\n倒是比较完整。对于那个滤波器，由于一个蛋白质可能通过多个结合位点（不同构象）与RNA结合，同时单个RNA也能与不同蛋白质相互作用，作者给出以下图来说明：\nCOMPLEX-AWARE ATTENTION BLOCK\n关于这个部分，作者先把rna和过滤的蛋白质信息拼接，并用了N个multi-head self-attention来增强上下文捕捉能力。\n之后采用了类似于RhoDesign的基于Transformer的解码器来生成RNA序列。解码过程被构建为一个下一个标记预测任务，其中解码器基于先前的标记预测下一个核苷酸。在训练过程中，模型通过使用交叉熵损失进行训练。\nHigh-Affinity RNA Design Framework\nstructure-to-sequence design model and evaluation tools. 先通过作者的模型进行设计，生成符合复合约束条件（如结合位点和相互作用）的定制化RNA序列；对序列利用PRA201数据集上训练的集成回归模型来评估，对结构利用AlphaFold3、RhoFold和RoseTTAFold2NA等来折叠后算RMSD，每次筛选前10%∼20%的序列，迭代直到最优。\nExperiments Dataset and Implementation Details\nDatasets: PRI30K and PRA201. 后者用于blind test，前者剔除结构相似之类的用于训练与测试，处理后是21,050个蛋白质-RNA配对和2,309条RNA序列的数据集。Cluster也是用的CD-HIT，相似性80%。 200 epochs, batch size of 48 (24 per GPU), attention blocks N = 6, local filtered size K = 64, ESM-2 650M提取蛋白质表征。 评比模型：SeqRNN and SeqLSTM, StructGNN, GraphTrans, RDesign, and RhoDesign. Ablation Studies\nkey components of method, including the number of attention blocks in CAFormer, the fashion of filtering the protein representation, and the choices of protein representation model.\n随着CAFormer模块数量增加，性能呈现持续提升趋势；其他指标就一一测试就行。\n根据作者之前的流程，\u0026ldquo;亲和力设计\u0026quot;能展现出比天然RNA序列更高的结合亲和力其他的conclusion我就不多嘴了。\nRiboDiffusion: tertiary structure-based RNA inverse folding with generative diffusion models 我就只写重点吧：\nAbstract:\nscarcity of data, nonunique structure-sequence mapping, flexibility of RNA conformation.\ngrowing applications in synthetic biology and therapeutics;\ninverse folding problem;\nIntroduction:\nRNA-based biotechnology;\nearly methods for focus on folding into RNA secondary structures; Some use efficient local search strategies guided by the energy function; Or globally by modeling the sequence distribution or directly manipulating diverse candidates;\nDAS physically based approach, but still constrained by local design strategy and computational efficiency.\n\u0026ndash; only 2D, without considering 3D structures of RNA\nMethods:\nDiffusion;\nThree-atom coarse-grained representation including the atom coordinates of C4’, C1’, N1 (pyrimidine) or N9 (purine) for every nucleotide;\nConsider the RNA inverse folding problem as modeling the conditional distribution p(S|X);\nBased on the GVP-GNN architecture;\nResults\nDataset: predicting structures with RhoFold. The structures predicted from RNAcentral sequences are filtered by pLDDT to keep only high-quality predictions, resulting in 17 000 structures.\nCluster: sequence\u0026ndash;PSI-CD-HIT to cluster sequences based on nucleotide similarity. We set the threshold at 0:8=0:6=0:4 and obtain 1252=1157=1114 clusters; structure similarity clustering, calculate the TM-score matrix using US-align and apply scipy, achieve 2036=1659=1302 clusters with TM-score thresholds of 0:6=0:5=0:4. 15% for testing, 10% for validation.\nEvaluation Metrics:\nRR, F1 Score(RNAfold and RMSD)\nLearning to Design RNA Abstract:\nBased on deep reinforcement learning;\nJointly optimize over a rich space of architectures for the policy network, the hyperparameters of the training procedure and the formulation of the decision process.\nIntroduction:\nLEARNA: deep RL algorithm for RNA Design. Given a target secondary structure, can predict the entire RNA sequence. After generating an RNA sequence, then folds this and locally adapts it, and uses the distance of the resulting structure to the target structure as an error signal for the RL agent;\nMeta-LEARNA: learns a single policy across many RNA Design tasks directly applicable to new RNA Design tasks;\nThe first application of architecture search (AS) to RL;\nNew benchmark dataset with an explicit training, validation and test split;\nFaster.\nTHE RNA DESIGN PROBLEM:\nFolding algorithm: zuker;\nLoss Function: Hamming diastance.\nLEARNING TO DESIGN RNA:\nAction Space, State Space, Transition Function, Reward Function;\nOne problem of current deep reinforcement learning methods is that their performance can be very sensitive to choices regarding the architecture of the policy network, the training hyperparameters, and the formulation of the problem as a decision process.\nRL often yield noisy or unreliable outcomes in single optimization runs, (a) The number of unsolved sequences, (b) the sum of mean distances, (c) the sum of minimum distances to the target structure.\nRNA-DCGen: Dual Constrained RNA Sequence Generation with LLM-Attack Challenge: recent diffusion and flowmatching-based models face two key limitations: specialization for fixed constraint types, such as tertiary structures, and lack of flexibility in imposing additional conditions beyond the primary property of interest.\nGenerative \u0026ndash;\u0026gt; Search;\nDual Constrained: on the sequence itself and on specified constraints.\n不是哥们，现在在训练好的模型上面调参都能发顶会吗？\n就读到这里吧，现在真是八仙过海各显神通了说是。赶紧赶mitx课程的ddl了，吐了。\n关于Long-Range的识别与预测的文献 找到motivation了不？其实找到了，就是识别long rna sequence嘛，问题是我们的multiscale光这个不够，需要多看论文多找多想。\n其实本周算是找了一堆没啥用的SOTA文章汇报（最起码对现在的研究没啥用），一周读了二十来篇论文但是白白浪费时间（当然也有好处，最起码熟悉了背景）。刚才我和老师大眼瞪小眼，咋汇报的文献没啥idea启发嘞？因此导师建议去找：\nmamba gnn, long protein seq, long molecule, long-range gnn, long-range attention\n那么加上attention is all you need这篇transformer的文章，和讲multiscale的文章，本周再来一轮汇报。其实找到了这些，但是有作用的不多。\n等等，多少篇？ Game over. 已老实。\n","date":"2025-09-20T16:55:14+08:00","image":"https://mosfish.github.io/p/%E5%BE%9C%E5%BE%89%E5%9C%A8arxiv%E5%92%8Cbioarxiv%E7%9A%84%E6%B5%B7%E6%B4%8B%E9%87%8C/1_hu_5b26fac71d3a39b8.jpg","permalink":"https://mosfish.github.io/p/%E5%BE%9C%E5%BE%89%E5%9C%A8arxiv%E5%92%8Cbioarxiv%E7%9A%84%E6%B5%B7%E6%B4%8B%E9%87%8C/","title":"徜徉在arxiv和bioarxiv的海洋里"},{"content":"如何优化rna逆合成模型 这是一个很challenging的问题，别问，问就是啥都不会。\n考虑到gRNAde: Geometric Deep Learning for 3D RNA Inverse Design论文的细节、思路非常清晰，且作者release了非常具象的source code，因而以gRNAde等state-of-the-art模型入手分析问题，作者代码开源地址：https://github.com/chaitjo/geometric-rna-design\n服务器需要的一些设置 在这个过程中，注意一些tricks。由于租用的国内服务器与英国的环境不太一样，因此需要多使用数据盘而非系统盘。本项目最大的问题是作者的环境变量设置。\nPython 3.10.12 and CUDA 11.8, numpy \u0026lt;2.0\n镜像网站加速 1 git clone https://ghfast.top/github.com/chaitjo/geometric-rna-design 1 cd /root/autodl-tmp/geometric-rna-design 此外，在数据盘配环境 1 mamba create -p /root/autodl-tmp/rna python=3.10 如果需要激活环境，请注意相对路径：\n1 mamba activate /root/autodl-tmp/rna 以及，防止系统盘数据太大，需要及时清理缓存：\n1 2 3 4 5 # 清理 pip 缓存 pip cache purge # 清理 conda 缓存 (可以释放 G 级别的空间) conda clean --all 配置租用服务器版本环境变量，下方命令只对当前shell有效。建议写入bashrc或者利用作者给出的.env文件，记得source ~/.bashrc 1 2 3 4 5 6 export PROJECT_PATH=\u0026#39;/root/autodl-tmp/geometric-rna-design/\u0026#39; export ETERNAFOLD=\u0026#39;/root/autodl-tmp/geometric-rna-design/tools/EternaFold\u0026#39; export X3DNA=\u0026#39;/root/autodl-tmp/geometric-rna-design/tools/x3dna-v2.4\u0026#39; export PATH=\u0026#34;/root/autodl-tmp/geometric-rna-design/tools/x3dna-v2.4/bin:$PATH\u0026#34; export PATH=\u0026#34;/root/autodl-tmp/cdhit:$PATH\u0026#34; PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128 而相应的，英国项目版本则按照如下，放到.env文件里。\n1 2 3 4 5 6 7 8 9 export PROJECT_PATH=\u0026#39;/home/remote1/geometric-rna-design/\u0026#39; export DATA_PATH=\u0026#39;/home/remote1/geometric-rna-design/data/\u0026#39; export WANDB_PROJECT=\u0026#39;rna\u0026#39; export WANDB_ENTITY=\u0026#39;wenxy59-sun-yat-sen-university\u0026#39; export WANDB_DIR=\u0026#39;/home/remote1/geometric-rna-design/\u0026#39; export ETERNAFOLD=\u0026#39;/home/remote1/geometric-rna-design/tools/EternaFold\u0026#39; export X3DNA=\u0026#39;/home/remote1/geometric-rna-design/tools/x3dna-v2.4\u0026#39; export PATH=\u0026#34;/home/remote1/geometric-rna-design/tools/x3dna-v2.4/bin:$PATH\u0026#34; PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128 训练模型的注意事项 数据预处理 注意运行main脚本前，需要处理数据生成process.pt文件，并生成相应的das_split.pt文件。在这个过程中，需要安装USalign与qTMclust工具。一般而言，安装后者的同时会自动安装前者。\n1 2 3 git clone https://github.com/pylelab/USalign.git cd USalign g++ -O3 -o qTMclust qTMclust.cpp -lm 之后就可以使用USalign -h与qTMclust -h命令来验证安装，记得查一下路径。在训练脚本里的相应位置路径用的相对路径可能报错，例如src/data/clustering_units.py记得修改。\n处理数据成功 数据处理大概是把14000+条raw数据处理为3910条可用数据，因为raw数据有残缺的处理后筛查出去了，因而数据不多，正常。\n有问题的数据 然后用notebook里的代码生成split文件。\n模型使用与实验 作者给出.py脚本进行启动，或者用命令行如下：\n1 python gRNAde.py --pdb_filepath data/raw/6J6G_1_L-E.pdb --output_filepath tutorial/lnc/po/114.fasta --split das --max_num_conformers 1 --n_samples 16 --temperature 0.5 使用效果如图：\n利用gRNAde预测结构与序列 模型在长rna序列（100+nts）的时候性能会下降，虽然recovery保持良好但是二级结构自洽性得分SC Score呈现明显线性下降。\n四个参数直观对比 SC Score(左)与Recovery(右)随Sequence的变化 另一个生成范式：RiboDiffusion 至于RiboDiffusion，其他部署方式一致但是环境设置如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 conda create -n rna2 python=3.10 -y conda activate rna2 pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116 pip install absl-py==0.15.0 pip install biopython==1.80 pip install dm_tree==0.1.7 pip install fair-esm==2.0.0 pip install ml_collections==0.1.1 pip install numpy==1.24.3 pip install scipy\u0026gt;=1.10.0 pip install tqdm==4.64.1 pip install torch-cluster==1.6.1+pt113cu116 -f https://data.pyg.org/whl/torch-1.13.0+cu116.html pip install torch-scatter==2.1.1+pt113cu116 -f https://data.pyg.org/whl/torch-1.13.0+cu116.html pip install torch-geometric==2.3.1 根据脚本运行，输出会出现一些问题，例如：\nRiboDiffusion输出 RiboDiffusion模型的Recovery在对数坐标(上)与常数坐标(下)表示下随Sequence的变化 原始的启动脚本为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 import torch from tqdm import tqdm import numpy as np import random from models import * from utils import * from diffusion import NoiseScheduleVP from sampling import get_sampling_fn from datasets import utils as du import functools import tree from configs.inference_ribodiffusion import get_config config = get_config() # Choose heckpoint name checkpoint_path = \u0026#39;./ckpts/exp_inf.pth\u0026#39; # checkpoint_path = \u0026#39;./ckpts/exp_inf_large.pth\u0026#39; config.eval.sampling_steps = 100 # config.eval.sampling_steps = 100 NUM_TO_LETTER = np.array([\u0026#39;A\u0026#39;, \u0026#39;G\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;U\u0026#39;]) def get_optimizer(config, params): \u0026#34;\u0026#34;\u0026#34;Return a flax optimizer object based on `config`.\u0026#34;\u0026#34;\u0026#34; if config.optim.optimizer == \u0026#39;Adam\u0026#39;: optimizer = optim.Adam(params, lr=config.optim.lr, betas=(config.optim.beta1, 0.999), eps=config.optim.eps, weight_decay=config.optim.weight_decay) elif config.optim.optimizer == \u0026#39;AdamW\u0026#39;: optimizer = torch.optim.AdamW(params, lr=config.optim.lr, amsgrad=True, weight_decay=1e-12) else: raise NotImplementedError(f\u0026#39;Optimizer {config.optim.optimizer} not supported yet!\u0026#39;) return optimizer # Initialize model model = create_model(config) ema = ExponentialMovingAverage(model.parameters(), decay=config.model.ema_decay) params = model.parameters() optimizer = get_optimizer(config, model.parameters()) state = dict(optimizer=optimizer, model=model, ema=ema, step=0) model_size = sum(p.numel() for p in model.parameters()) * 4 / 2 ** 20 print(\u0026#39;model size: {:.1f}MB\u0026#39;.format(model_size)) # Load checkpoint state = restore_checkpoint(checkpoint_path, state, device=config.device) ema.copy_to(model.parameters()) # Initialize noise scheduler noise_scheduler = NoiseScheduleVP(config.sde.schedule, continuous_beta_0=config.sde.continuous_beta_0, continuous_beta_1=config.sde.continuous_beta_1) # Obtain data scalar and inverse scalar inverse_scaler = get_data_inverse_scaler(config) # Setup sampling function test_sampling_fn = get_sampling_fn(config, noise_scheduler, config.eval.sampling_steps, inverse_scaler) pdb2data = functools.partial(du.PDBtoData, num_posenc=config.data.num_posenc, num_rbf=config.data.num_rbf, knn_num=config.data.knn_num) # Run inference on a single p pdb_file= \u0026#39;/home/remote1/geometric-rna-design/data/raw/1FIR_1_A.pdb\u0026#39; pdb_id = pdb_file.replace(\u0026#39;.pdb\u0026#39;, \u0026#39;\u0026#39;) if \u0026#39;/\u0026#39; in pdb_id: pdb_id = pdb_id.split(\u0026#39;/\u0026#39;)[-1] config.eval.dynamic_threshold=True config.eval.cond_scale=0.4 config.eval.n_samples=16 test_sampling_fn = get_sampling_fn(config, noise_scheduler, config.eval.sampling_steps, inverse_scaler) struct_data = pdb2data(pdb_file) struct_data = tree.map_structure(lambda x:x.unsqueeze(0).repeat_interleave(config.eval.n_samples, dim=0).to(config.device), struct_data) samples = test_sampling_fn(model, struct_data) print(f\u0026#39;PDB ID: {pdb_id}\u0026#39;) native_seq = \u0026#39;\u0026#39;.join(list(NUM_TO_LETTER[struct_data[\u0026#39;seq\u0026#39;][0].cpu().numpy()])) print(f\u0026#39;Native sequence: {native_seq}\u0026#39;) for i in range(len(samples)): # native_seq = \u0026#39;\u0026#39;.join(list(NUM_TO_LETTER[struct_data[\u0026#39;seq\u0026#39;].squeeze(0).cpu().numpy()])) # print(f\u0026#39;Native sequence: {native_seq}\u0026#39;) designed_seq = \u0026#39;\u0026#39;.join(list(NUM_TO_LETTER[samples[i].cpu().numpy()])) print(f\u0026#39;Generated sequence {i+1}: {designed_seq}\u0026#39;) recovery_ = samples[i].eq(struct_data[\u0026#39;seq\u0026#39;][0]).float().mean().item() print(f\u0026#39;Recovery rate {i+1}: {recovery_:.4f}\u0026#39;) 自动化设计为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 import torch from tqdm import tqdm import numpy as np import random import os import sys from datetime import datetime # Add the gRNAde path to import evaluation tools sys.path.append(\u0026#39;/home/remote1/geometric-rna-design/src\u0026#39;) sys.path.append(\u0026#39;/home/remote1/geometric-rna-design/\u0026#39;) from models import * from utils import * from diffusion import NoiseScheduleVP from sampling import get_sampling_fn from datasets import utils as du import functools import tree from configs.inference_ribodiffusion import get_config # Import gRNAde evaluation functions from src.evaluator import ( self_consistency_score_eternafold, edit_distance ) from src.data.data_utils import pdb_to_tensor, get_c4p_coords from src.constants import NUM_TO_LETTER, PROJECT_PATH # Import BioPython for sequence handling from Bio import SeqIO from Bio.Seq import Seq from Bio.SeqRecord import SeqRecord config = get_config() # Choose checkpoint name checkpoint_path = \u0026#39;./ckpts/exp_inf.pth\u0026#39; config.eval.sampling_steps = 100 def get_optimizer(config, params): \u0026#34;\u0026#34;\u0026#34;Return a flax optimizer object based on `config`.\u0026#34;\u0026#34;\u0026#34; if config.optim.optimizer == \u0026#39;Adam\u0026#39;: optimizer = optim.Adam(params, lr=config.optim.lr, betas=(config.optim.beta1, 0.999), eps=config.optim.eps, weight_decay=config.optim.weight_decay) elif config.optim.optimizer == \u0026#39;AdamW\u0026#39;: optimizer = torch.optim.AdamW(params, lr=config.optim.lr, amsgrad=True, weight_decay=1e-12) else: raise NotImplementedError(f\u0026#39;Optimizer {config.optim.optimizer} not supported yet!\u0026#39;) return optimizer def extract_sec_struct_from_pdb(pdb_file): \u0026#34;\u0026#34;\u0026#34; Extract secondary structure from PDB file using gRNAde\u0026#39;s data utilities. \u0026#34;\u0026#34;\u0026#34; try: sequence, coords, sec_struct, sasa = pdb_to_tensor( pdb_file, return_sec_struct=True, return_sasa=True, keep_insertions=False ) return [sec_struct] if sec_struct else None except Exception as e: print(f\u0026#34;Warning: Could not extract secondary structure from {pdb_file}: {e}\u0026#34;) return None def prepare_raw_data_for_grnade_eval(pdb_file, native_seq): \u0026#34;\u0026#34;\u0026#34; Prepare raw data structure compatible with gRNAde evaluator. \u0026#34;\u0026#34;\u0026#34; try: sequence, coords, sec_struct, sasa = pdb_to_tensor( pdb_file, return_sec_struct=True, return_sasa=True, keep_insertions=False ) raw_data = { \u0026#39;sequence\u0026#39;: native_seq, \u0026#39;coords_list\u0026#39;: [coords] if coords is not None else [], \u0026#39;sec_struct_list\u0026#39;: [sec_struct] if sec_struct else [\u0026#34;.\u0026#34;] * len(native_seq), \u0026#39;sasa_list\u0026#39;: [sasa] if sasa is not None else [np.ones(len(native_seq))] } return raw_data except Exception as e: print(f\u0026#34;Warning: Could not prepare raw data from {pdb_file}: {e}\u0026#34;) # Return minimal raw data structure return { \u0026#39;sequence\u0026#39;: native_seq, \u0026#39;coords_list\u0026#39;: [], \u0026#39;sec_struct_list\u0026#39;: [\u0026#34;.\u0026#34;] * len(native_seq), \u0026#39;sasa_list\u0026#39;: [np.ones(len(native_seq))] } def evaluate_ribodiffusion_with_grnade_sc(samples, native_seq, pdb_file, pdb_id, output_dir=None, save_results=True): \u0026#34;\u0026#34;\u0026#34; Evaluate RiboDiffusion samples using gRNAde\u0026#39;s self-consistency evaluation. \u0026#34;\u0026#34;\u0026#34; # Prepare raw data for gRNAde evaluator raw_data = prepare_raw_data_for_grnade_eval(pdb_file, native_seq) # Convert RiboDiffusion samples to numpy arrays sample_arrays = [] for sample in samples: if isinstance(sample, torch.Tensor): sample_arrays.append(sample.cpu().numpy()) else: sample_arrays.append(np.array(sample)) # Create mask for coordinates (assume all positions are valid for now) mask_coords = np.ones(len(native_seq), dtype=bool) # Calculate basic metrics results = { \u0026#39;pdb_id\u0026#39;: pdb_id, \u0026#39;native_seq\u0026#39;: native_seq, \u0026#39;samples\u0026#39;: [], \u0026#39;recovery_rates\u0026#39;: [], \u0026#39;edit_distances\u0026#39;: [], \u0026#39;sc_scores_eternafold\u0026#39;: [] } # Convert native sequence to numerical for recovery calculation letter_to_num = {letter: idx for idx, letter in enumerate(NUM_TO_LETTER)} native_array = np.array([letter_to_num[char] for char in native_seq]) print(f\u0026#34;\\nEvaluating {len(samples)} samples for {pdb_id}:\u0026#34;) for i, sample_array in enumerate(sample_arrays): designed_seq = \u0026#39;\u0026#39;.join([NUM_TO_LETTER[num] for num in sample_array]) results[\u0026#39;samples\u0026#39;].append(designed_seq) # Calculate recovery rate recovery = (sample_array == native_array).mean() results[\u0026#39;recovery_rates\u0026#39;].append(recovery) # Calculate edit distance using gRNAde\u0026#39;s function edit_dist = edit_distance(designed_seq, native_seq) results[\u0026#39;edit_distances\u0026#39;].append(edit_dist) print(f\u0026#39;Sample {i+1}: Recovery={recovery:.4f}, Edit_dist={edit_dist}\u0026#39;) # Calculate self-consistency scores using gRNAde\u0026#39;s EternaFold evaluator print(\u0026#34;\\nCalculating self-consistency scores with EternaFold...\u0026#34;) try: sc_scores = self_consistency_score_eternafold( sample_arrays, raw_data[\u0026#39;sec_struct_list\u0026#39;], mask_coords ) results[\u0026#39;sc_scores_eternafold\u0026#39;] = sc_scores.tolist() for i, sc_score in enumerate(sc_scores): print(f\u0026#39;Sample {i+1}: SC_score={sc_score:.4f}\u0026#39;) except Exception as e: print(f\u0026#34;Warning: Could not calculate SC scores: {e}\u0026#34;) print(\u0026#34;This might be due to EternaFold not being properly installed or configured.\u0026#34;) results[\u0026#39;sc_scores_eternafold\u0026#39;] = [0.0] * len(samples) # Save results if save_results and output_dir: os.makedirs(output_dir, exist_ok=True) # Save as FASTA file compatible with gRNAde format sequences = [] # First record: input sequence with metadata sequences.append(SeqRecord( Seq(native_seq), id=\u0026#34;input_sequence,\u0026#34;, description=f\u0026#34;pdb_id={pdb_id}, ribodiffusion_evaluation\u0026#34; )) # Remaining records: designed sequences with metrics for i, (seq, recovery, edit_dist, sc_score) in enumerate(zip( results[\u0026#39;samples\u0026#39;], results[\u0026#39;recovery_rates\u0026#39;], results[\u0026#39;edit_distances\u0026#39;], results[\u0026#39;sc_scores_eternafold\u0026#39;] )): sequences.append(SeqRecord( Seq(seq), id=f\u0026#34;sample={i},\u0026#34;, description=f\u0026#34;recovery={recovery:.4f}, edit_dist={edit_dist}, sc_score={sc_score:.4f}\u0026#34; )) # Save FASTA fasta_path = os.path.join(output_dir, f\u0026#34;{pdb_id}_ribodiffusion_designs.fasta\u0026#34;) SeqIO.write(sequences, fasta_path, \u0026#34;fasta\u0026#34;) print(f\u0026#34;\\nResults saved to: {fasta_path}\u0026#34;) # Print summary statistics print(f\u0026#34;\\n{\u0026#39;=\u0026#39;*50}\u0026#34;) print(f\u0026#34;Summary for {pdb_id}:\u0026#34;) print(f\u0026#34;Native sequence length: {len(native_seq)}\u0026#34;) print(f\u0026#34;Number of samples: {len(samples)}\u0026#34;) print(f\u0026#34;Mean Recovery: {np.mean(results[\u0026#39;recovery_rates\u0026#39;]):.4f} ± {np.std(results[\u0026#39;recovery_rates\u0026#39;]):.4f}\u0026#34;) print(f\u0026#34;Mean Edit Distance: {np.mean(results[\u0026#39;edit_distances\u0026#39;]):.2f} ± {np.std(results[\u0026#39;edit_distances\u0026#39;]):.2f}\u0026#34;) if results[\u0026#39;sc_scores_eternafold\u0026#39;][0] != 0.0: print(f\u0026#34;Mean SC Score (EternaFold): {np.mean(results[\u0026#39;sc_scores_eternafold\u0026#39;]):.4f} ± {np.std(results[\u0026#39;sc_scores_eternafold\u0026#39;]):.4f}\u0026#34;) else: print(\u0026#34;SC Scores not calculated (EternaFold unavailable)\u0026#34;) print(f\u0026#34;{\u0026#39;=\u0026#39;*50}\u0026#34;) return results # Initialize model model = create_model(config) ema = ExponentialMovingAverage(model.parameters(), decay=config.model.ema_decay) params = model.parameters() optimizer = get_optimizer(config, model.parameters()) state = dict(optimizer=optimizer, model=model, ema=ema, step=0) model_size = sum(p.numel() for p in model.parameters()) * 4 / 2 ** 20 print(\u0026#39;Model size: {:.1f}MB\u0026#39;.format(model_size)) # Load checkpoint state = restore_checkpoint(checkpoint_path, state, device=config.device) ema.copy_to(model.parameters()) # Initialize noise scheduler noise_scheduler = NoiseScheduleVP(config.sde.schedule, continuous_beta_0=config.sde.continuous_beta_0, continuous_beta_1=config.sde.continuous_beta_1) # Obtain data scalar and inverse scalar inverse_scaler = get_data_inverse_scaler(config) # Setup sampling function test_sampling_fn = get_sampling_fn(config, noise_scheduler, config.eval.sampling_steps, inverse_scaler) pdb2data = functools.partial(du.PDBtoData, num_posenc=config.data.num_posenc, num_rbf=config.data.num_rbf, knn_num=config.data.knn_num) # Run inference pdb_file = \u0026#39;/home/remote1/geometric-rna-design/data/raw/7PIC_1_5.pdb\u0026#39; pdb_id = os.path.basename(pdb_file).replace(\u0026#39;.pdb\u0026#39;, \u0026#39;\u0026#39;) # Configure sampling config.eval.dynamic_threshold = True config.eval.cond_scale = 0.4 config.eval.n_samples = 16 # Generate samples print(f\u0026#39;Processing PDB: {pdb_file}\u0026#39;) test_sampling_fn = get_sampling_fn(config, noise_scheduler, config.eval.sampling_steps, inverse_scaler) struct_data = pdb2data(pdb_file) struct_data = tree.map_structure( lambda x: x.unsqueeze(0).repeat_interleave(config.eval.n_samples, dim=0).to(config.device), struct_data ) samples = test_sampling_fn(model, struct_data) # Get native sequence native_seq = \u0026#39;\u0026#39;.join(list(NUM_TO_LETTER[struct_data[\u0026#39;seq\u0026#39;][0].cpu().numpy()])) print(f\u0026#39;Native sequence: {native_seq}\u0026#39;) # Create output directory current_time = datetime.now().strftime(\u0026#34;%Y%m%d_%H%M%S\u0026#34;) output_dir = f\u0026#34;ribodiffusion_grnade_eval_{current_time}\u0026#34; # Evaluate with gRNAde\u0026#39;s self-consistency framework results = evaluate_ribodiffusion_with_grnade_sc( samples=samples, native_seq=native_seq, pdb_file=pdb_file, pdb_id=pdb_id, output_dir=output_dir, save_results=True ) 在13000条数据进行测试，\n自动化测试 测试结果与测试结果（log后） 初步改进——attention 考虑到多层注意力机制会有利于长序列的捕捉，我先使用MultiheadAttention，加了一层简单的代码，进行训练。其中原本release的代码有bug，尤其是这个函数里的mask_coords掩码逻辑有问题，经常与sample的维度不匹配报错。我把修改过的evaluator.py贴在这里，同时防止显存爆炸，需要设置一些batch。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 import os import copy import shutil from datetime import datetime import numpy as np import pandas as pd from tqdm import tqdm import wandb import torch import torch.nn.functional as F from torchmetrics.functional.classification import binary_matthews_corrcoef from Bio import SeqIO from Bio.Seq import Seq from Bio.SeqRecord import SeqRecord from MDAnalysis.analysis.align import rotation_matrix from MDAnalysis.analysis.rms import rmsd as get_rmsd from src.data.data_utils import pdb_to_tensor, get_c4p_coords from src.data.sec_struct_utils import ( predict_sec_struct, dotbracket_to_paired, dotbracket_to_adjacency ) from src.constants import ( NUM_TO_LETTER, PROJECT_PATH, RMSD_THRESHOLD, TM_THRESHOLD, GDT_THRESHOLD ) def evaluate( model, dataset, n_samples, temperature, device, model_name=\u0026#34;eval\u0026#34;, metrics=[ \u0026#39;recovery\u0026#39;, \u0026#39;perplexity\u0026#39;, \u0026#39;sc_score_eternafold\u0026#39;, \u0026#39;sc_score_ribonanzanet\u0026#39;, \u0026#39;sc_score_rhofold\u0026#39; ], save_designs=False ): \u0026#34;\u0026#34;\u0026#34; Run evaluation suite for trained RNA inverse folding model on a dataset. The following metrics can be computed along with metadata per sample per residue: 1. (recovery) Sequence recovery per residue (taking mean gives per sample recovery) 2. (perplexity) Perplexity per sample 3. (sc_score_eternafold) Secondary structure self-consistency score per sample, using EternaFold for secondary structure prediction and computing MCC between the predicted and groundtruth 2D structures as adjacency matrices. 4. (sc_score_ribonanzanet) Chemical modification self-consistency score per sample, using RibonanzaNet for chemical modification prediction of the groundtruth and designed sequences, and measuring MAE between them. 5. (sc_score_rhofold) Tertiary structure self-consistency scores per sample, using RhoFold for tertiary structure prediction and measuring RMSD, TM-score, and GDT_TS between the predicted and groundtruth C4\u0026#39; 3D coordinates. 6. (rmsd_within_thresh) Percentage of samples with RMSD within threshold (\u0026lt;=2.0A) 7. (tm_within_thresh) Percentage of samples with TM-score within threshold (\u0026gt;=0.45) 8. (gddt_within_thresh) Percentage of samples with GDT_TS within threshold (\u0026gt;=0.50) Args: model: trained RNA inverse folding model dataset: dataset to evaluate on n_samples: number of predicted samples/sequences per data point temperature: sampling temperature device: device to run evaluation on model_name: name of model/dataset for plotting (default: \u0026#39;eval\u0026#39;) metrics: list of metrics to compute save_designs: whether to save designs as fasta with metrics Returns: Dictionary with the following keys: df: DataFrame with metrics and metadata per residue per sample for analysis and plotting samples_list: list of tensors of shape (n_samples, seq_len) per data point recovery_list: list of mean recovery per data point perplexity_list: list of mean perplexity per data point sc_score_eternafold_list: list of 2D self-consistency scores per data point sc_score_ribonanzanet_list: list of 1D self-consistency scores per data point sc_score_rmsd_list: list of 3D self-consistency RMSDs per data point sc_score_tm_list: list of 3D self-consistency TM-scores per data point sc_score_gddt_list: list of 3D self-consistency GDTs per data point rmsd_within_thresh_list: list of % scRMSDs within threshold per data point tm_within_thresh_list: list of % scTMs within threshold per data point gddt_within_thresh_list: list of % scGDDTs within threshold per data point \u0026#34;\u0026#34;\u0026#34; assert \u0026#39;recovery\u0026#39; in metrics, \u0026#39;Sequence recovery must be computed for evaluation\u0026#39; ####################################################################### # Optionally initialise other models used for self-consistency scoring ####################################################################### if \u0026#39;sc_score_ribonanzanet\u0026#39; in metrics: from tools.ribonanzanet.network import RibonanzaNet # Initialise RibonanzaNet for self-consistency score ribonanza_net = RibonanzaNet( os.path.join(PROJECT_PATH, \u0026#39;tools/ribonanzanet/config.yaml\u0026#39;), os.path.join(PROJECT_PATH, \u0026#39;tools/ribonanzanet/ribonanzanet.pt\u0026#39;), device ) # Transfer model to device in eval mode ribonanza_net = ribonanza_net.to(device) ribonanza_net.eval() if \u0026#39;sc_score_rhofold\u0026#39; in metrics: from tools.rhofold.rf import RhoFold from tools.rhofold.config import rhofold_config # Initialise RhoFold for 3D self-consistency score rhofold = RhoFold(rhofold_config, device) rhofold_path = os.path.join(PROJECT_PATH, \u0026#34;tools/rhofold/model_20221010_params.pt\u0026#34;) print(f\u0026#34;Loading RhoFold checkpoint: {rhofold_path}\u0026#34;) rhofold.load_state_dict(torch.load(rhofold_path, map_location=torch.device(\u0026#39;cpu\u0026#39;))[\u0026#39;model\u0026#39;]) # Transfer model to device in eval mode rhofold = rhofold.to(device) rhofold.eval() current_datetime = datetime.now().strftime(\u0026#34;%Y%m%d_%H%M%S\u0026#34;) #################################################### # Evaluation loop over each data point sequentially #################################################### # per sample metric lists for storing evaluation results samples_list = [] # list of tensors of shape (n_samples, seq_len) per data point recovery_list = [] # list of mean recovery per data point perplexity_list = [] # list of mean perplexity per data point sc_score_ribonanzanet_list = [] # list of 1D self-consistency scores per data point sc_score_eternafold_list = [] # list of 2D self-consistency scores per data point sc_score_rmsd_list = [] # list of 3D self-consistency RMSDs per data point rmsd_within_thresh_list = [] # list of % scRMSDs within threshold per data point sc_score_tm_list = [] # list of 3D self-consistency TM-scores per data point tm_within_thresh_list = [] # list of % scTMs within threshold per data point sc_score_gddt_list = [] # list of 3D self-consistency GDTs per data point gddt_within_thresh_list = [] # list of % scGDDTs within threshold per data point # DataFrame to store metrics and metadata per residue per sample for analysis and plotting df = pd.DataFrame(columns=[\u0026#39;idx\u0026#39;, \u0026#39;recovery\u0026#39;, \u0026#39;sasa\u0026#39;, \u0026#39;paired\u0026#39;, \u0026#39;rmsds\u0026#39;, \u0026#39;model_name\u0026#39;]) model.eval() if device.type == \u0026#39;xpu\u0026#39;: import intel_extension_for_pytorch as ipex model = ipex.optimize(model) if \u0026#39;sc_score_ribonanzanet\u0026#39; in metrics: ribonanza_net = ipex.optimize(ribonanza_net) if \u0026#39;sc_score_rhofold\u0026#39; in metrics: rhofold = ipex.optimize(rhofold) with torch.no_grad(): for idx, raw_data in tqdm( enumerate(dataset.data_list), total=len(dataset.data_list) ): # featurise raw data data = dataset.featurizer(raw_data).to(device) # sample n_samples from model for single data point: n_samples x seq_len samples, logits = model.sample(data, n_samples, temperature, return_logits=True) samples_list.append(samples.cpu().numpy()) # perplexity per sample: n_samples x 1 n_nodes = logits.shape[1] perplexity = torch.exp(F.cross_entropy( logits.view(n_samples * n_nodes, model.out_dim), samples.view(n_samples * n_nodes).long(), reduction=\u0026#34;none\u0026#34; ).view(n_samples, n_nodes).mean(dim=1)).cpu().numpy() perplexity_list.append(perplexity.mean()) ########### # Metadata ########### # per residue average SASA: seq_len x 1 mask_coords = data.mask_coords.cpu().numpy() sasa = np.mean(raw_data[\u0026#39;sasa_list\u0026#39;], axis=0)[mask_coords] # per residue indicator for paired/unpaired: seq_len x 1 paired = np.mean( [dotbracket_to_paired(sec_struct) for sec_struct in raw_data[\u0026#39;sec_struct_list\u0026#39;]], axis=0 )[mask_coords] # per residue average RMSD: seq_len x 1 if len(raw_data[\u0026#34;coords_list\u0026#34;]) == 1: rmsds = np.zeros_like(sasa) else: rmsds = [] for i in range(len(raw_data[\u0026#34;coords_list\u0026#34;])): for j in range(i+1, len(raw_data[\u0026#34;coords_list\u0026#34;])): coords_i = get_c4p_coords(raw_data[\u0026#34;coords_list\u0026#34;][i]) coords_j = get_c4p_coords(raw_data[\u0026#34;coords_list\u0026#34;][j]) rmsds.append(torch.sqrt(torch.sum((coords_i - coords_j)**2, dim=1)).cpu().numpy()) rmsds = np.stack(rmsds).mean(axis=0)[mask_coords] ########## # Metrics ########## # sequence recovery per residue across all samples: n_samples x seq_len recovery = samples.eq(data.seq).float().cpu().numpy() recovery_list.append(recovery.mean()) # update per residue per sample dataframe df = pd.concat([ df, pd.DataFrame({ \u0026#39;idx\u0026#39;: [idx] * len(recovery.mean(axis=0)), \u0026#39;recovery\u0026#39;: recovery.mean(axis=0), \u0026#39;sasa\u0026#39;: sasa, \u0026#39;paired\u0026#39;: paired, \u0026#39;rmsds\u0026#39;: rmsds, \u0026#39;model_name\u0026#39;: [model_name] * len(recovery.mean(axis=0)) }) ], ignore_index=True) # global 2D self consistency score per sample: n_samples x 1 if \u0026#39;sc_score_eternafold\u0026#39; in metrics: sc_score_eternafold, pred_sec_structs = self_consistency_score_eternafold( samples.cpu().numpy(), raw_data[\u0026#39;sec_struct_list\u0026#39;], mask_coords, return_sec_structs = True ) sc_score_eternafold_list.append(sc_score_eternafold.mean()) # global 1D self consistency score per sample: n_samples x 1 if \u0026#39;sc_score_ribonanzanet\u0026#39; in metrics: sc_score_ribonanzanet, pred_chem_mods = self_consistency_score_ribonanzanet( samples.cpu().numpy(), raw_data[\u0026#39;sequence\u0026#39;], mask_coords, ribonanza_net, return_chem_mods = True ) sc_score_ribonanzanet_list.append(sc_score_ribonanzanet.mean()) # global 3D self consistency scores per sample: n_samples x 1, each if \u0026#39;sc_score_rhofold\u0026#39; in metrics: try: output_dir = os.path.join( wandb.run.dir, f\u0026#34;designs_{model_name}/{current_datetime}/sample{idx}/\u0026#34;) except AttributeError: output_dir = os.path.join( PROJECT_PATH, f\u0026#34;designs_{model_name}/{current_datetime}/sample{idx}/\u0026#34;) sc_score_rmsd, sc_score_tm, sc_score_gdt = self_consistency_score_rhofold( samples.cpu().numpy(), raw_data, mask_coords, rhofold, output_dir, save_designs = save_designs ) sc_score_rmsd_list.append(sc_score_rmsd.mean()) sc_score_tm_list.append(sc_score_tm.mean()) sc_score_gddt_list.append(sc_score_gdt.mean()) rmsd_within_thresh_list.append((sc_score_rmsd \u0026lt;= RMSD_THRESHOLD).sum() / n_samples) tm_within_thresh_list.append((sc_score_tm \u0026gt;= TM_THRESHOLD).sum() / n_samples) gddt_within_thresh_list.append((sc_score_gdt \u0026gt;= GDT_THRESHOLD).sum() / n_samples) if save_designs: # collate designed sequences in fasta format sequences = [SeqRecord( Seq(raw_data[\u0026#34;sequence\u0026#34;]), id=f\u0026#34;input_sequence,\u0026#34;, description=f\u0026#34;pdb_id={raw_data[\u0026#39;id_list\u0026#39;][0]} rfam={raw_data[\u0026#39;rfam_list\u0026#39;][0]} eq_class={raw_data[\u0026#39;eq_class_list\u0026#39;][0]} cluster={raw_data[\u0026#39;cluster_structsim0.45\u0026#39;]}\u0026#34; )] for idx, zipped in enumerate(zip( samples.cpu().numpy(), perplexity, recovery.mean(axis=1), sc_score_eternafold, pred_sec_structs, sc_score_ribonanzanet, pred_chem_mods, sc_score_rmsd, sc_score_tm, sc_score_gdt )): seq, perp, rec, sc, pred_ss, sc_ribo, pred_cm, sc_rmsd, sc_tm, sc_gdt = zipped seq = \u0026#34;\u0026#34;.join([NUM_TO_LETTER[num] for num in seq]) edit_dist = edit_distance(seq, raw_data[\u0026#39;sequence\u0026#39;]) sequences.append(SeqRecord( Seq(seq), id=f\u0026#34;sample={idx},\u0026#34;, description=f\u0026#34;temperature={temperature} perplexity={perp:.4f} recovery={rec:.4f} edit_dist={edit_dist} sc_score={sc:.4f} sc_score_ribonanzanet={sc_ribo:.4f} sc_score_rmsd={sc_rmsd:.4f} sc_score_tm={sc_tm:.4f} sc_score_gdt={sc_gdt:.4f}\u0026#34; )) # write all designed sequences to output filepath SeqIO.write(sequences, os.path.join(output_dir, \u0026#34;all_designs.fasta\u0026#34;), \u0026#34;fasta\u0026#34;) out = { \u0026#39;df\u0026#39;: df, \u0026#39;samples_list\u0026#39;: samples_list, \u0026#39;recovery_list\u0026#39;: recovery_list, \u0026#39;perplexity_list\u0026#39;: perplexity_list } if \u0026#39;sc_score_eternafold\u0026#39; in metrics: out[\u0026#39;sc_score_eternafold\u0026#39;] = sc_score_eternafold_list if \u0026#39;sc_score_ribonanzanet\u0026#39; in metrics: out[\u0026#39;sc_score_ribonanzanet\u0026#39;] = sc_score_ribonanzanet_list if \u0026#39;sc_score_rhofold\u0026#39; in metrics: out[\u0026#39;sc_score_rmsd\u0026#39;] = sc_score_rmsd_list out[\u0026#39;sc_score_tm\u0026#39;] = sc_score_tm_list out[\u0026#39;sc_score_gddt\u0026#39;] = sc_score_gddt_list out[\u0026#39;rmsd_within_thresh\u0026#39;] = rmsd_within_thresh_list out[\u0026#39;tm_within_thresh\u0026#39;] = tm_within_thresh_list out[\u0026#39;gddt_within_thresh\u0026#39;] = gddt_within_thresh_list # ========================================================= import gc if \u0026#39;ribonanza_net\u0026#39; in locals(): del ribonanza_net if \u0026#39;rhofold\u0026#39; in locals(): del rhofold gc.collect() if torch.cuda.is_available(): torch.cuda.empty_cache() # ========================================================= return out def self_consistency_score_eternafold( samples, true_sec_struct_list, mask_coords, n_samples_ss = 1, num_to_letter = NUM_TO_LETTER, return_sec_structs = False ): \u0026#34;\u0026#34;\u0026#34; Compute self consistency score for an RNA, given its true secondary structure(s) and a list of designed sequences. EternaFold is used to \u0026#39;forward fold\u0026#39; the designs. Args: samples: designed sequences of shape (n_samples, seq_len) true_sec_struct_list: list of true secondary structures (n_true_ss, seq_len) mask_coords: mask for missing sequence coordinates to be ignored during evaluation n_samples_ss: number of predicted secondary structures per designed sample num_to_letter: lookup table mapping integers to nucleotides return_sec_structs: whether to return the predicted secondary structures Workflow: Input: For a given RNA molecule, we are given: - Designed sequences of shape (n_samples, seq_len) - True secondary structure(s) of shape (n_true_ss, seq_len) For each designed sequence: - Predict n_sample_ss secondary structures using EternaFold - For each pair of true and predicted secondary structures: - Compute MCC score between their adjacency matrix representations - Take the average MCC score across all n_sample_ss predicted structures Take the average MCC score across all n_samples designed sequences \u0026#34;\u0026#34;\u0026#34; n_true_ss = len(true_sec_struct_list) sequence_length = mask_coords.sum() # map all entries from dotbracket to numerical representation true_sec_struct_list = np.array([dotbracket_to_adjacency(ss) for ss in true_sec_struct_list]) # mask out missing sequence coordinates true_sec_struct_list = true_sec_struct_list[:, mask_coords][:, :, mask_coords] # reshape to (n_true_ss * n_samples_ss, seq_len, seq_len) true_sec_struct_list = torch.tensor( true_sec_struct_list ).unsqueeze(1).repeat(1, n_samples_ss, 1, 1).reshape(-1, sequence_length, sequence_length) mcc_scores = [] pred_sec_structs = [] for _sample in samples: # convert sample to string pred_seq = \u0026#39;\u0026#39;.join([num_to_letter[num] for num in _sample]) # predict secondary structure(s) for each sample pred_sec_struct_list = predict_sec_struct(pred_seq, n_samples=n_samples_ss) if return_sec_structs: pred_sec_structs.append(copy.copy(pred_sec_struct_list)) # map all entries from dotbracket to numerical representation pred_sec_struct_list = np.array([dotbracket_to_adjacency(ss) for ss in pred_sec_struct_list]) # reshape to (n_samples_ss * n_true_ss, seq_len, seq_len) pred_sec_struct_list = torch.tensor( pred_sec_struct_list ).unsqueeze(0).repeat(n_true_ss, 1, 1, 1).reshape(-1, sequence_length, sequence_length) # compute mean MCC score between pairs of true and predicted secondary structures mcc_scores.append( binary_matthews_corrcoef( pred_sec_struct_list, true_sec_struct_list, ).float().mean() ) if return_sec_structs: return np.array(mcc_scores), pred_sec_structs else: return np.array(mcc_scores) def self_consistency_score_ribonanzanet( samples, true_sequence, mask_seq, ribonanza_net, num_to_letter=NUM_TO_LETTER, return_chem_mods=False, ): \u0026#34;\u0026#34;\u0026#34;Compute self consistency score for an RNA, given the (predicted) chemical modifications for the original RNA and a list of designed sequences. RibonanzaNet is used to \u0026#39;forward fold\u0026#39; the designs. Args: samples: designed sequences of shape (n_samples, seq_len) true_sequence: true RNA sequence used to predict chemical modifications mask_seq: mask for missing sequence coordinates to be ignored during evaluation ribonanza_net: RibonanzaNet model num_to_letter: lookup table mapping integers to nucleotides return_chem_mods: whether to return the predicted chemical modifications Workflow: Input: For a given RNA molecule, we are given: - Designed sequences of shape (n_samples, seq_len) - Predicted chemical modifications for original sequence, of shape (n_samples, seq_len, 2), predicted via RibonanzaNet, of which we take the index 0 from the last channal --\u0026gt; 2A3/SHAPE. For each designed sequence: - Predict chemical modifications using RibonanzaNet - Compute mean absolute error between prediction and chemical modifications for the original sequence Take the average mean absolute error across all n_samples designed sequences \u0026#34;\u0026#34;\u0026#34; # Compute original sequence\u0026#39;s chemical modifications using RibonanzaNet true_sequence = np.array([char for char in true_sequence]) true_sequence = \u0026#34;\u0026#34;.join(true_sequence[mask_seq]) true_chem_mod = ribonanza_net.predict(true_sequence).unsqueeze(0).cpu().numpy()[:,:,0] # 2. 【核心修改】分批处理模型生成的样本 _samples_char = np.array([[num_to_letter[num] for num in seq] for seq in samples]) batch_size = 1 # 定义一个小的批次大小，可以根据显存调整（比如4, 8, 16） all_preds = [] # 用于收集所有批次的预测结果 for i in range(0, len(_samples_char), batch_size): # 取出一个小批次 batch_samples = _samples_char[i:i+batch_size] # 对这个小批次进行预测 batch_pred = ribonanza_net.predict(batch_samples).cpu().numpy()[:,:,0] all_preds.append(batch_pred) # 将所有批次的结果拼接起来 pred_chem_mod = np.concatenate(all_preds, axis=0) # _samples_char = np.array([[num_to_letter[num] for num in seq] for seq in samples]) # _samples = np.array([[num_to_letter[num] for num in seq] for seq in samples]) #pred_chem_mod = ribonanza_net.predict(_samples_char).cpu().numpy()[:,:,0] ##pred_chem_mod = ribonanza_net.predict(_samples[:, mask_seq]).cpu().numpy()[:,:,0] if return_chem_mods: return (np.abs(pred_chem_mod - true_chem_mod).mean(1)), pred_chem_mod else: return np.abs(pred_chem_mod - true_chem_mod).mean(1) def self_consistency_score_ribonanzanet_sec_struct( samples, true_sec_struct, mask_coords, ribonanza_net_ss, num_to_letter = NUM_TO_LETTER, return_sec_structs = False ): # map from dotbracket to numerical representation true_sec_struct = np.array(dotbracket_to_adjacency(true_sec_struct, keep_pseudoknots=True)) # mask out missing sequence coordinates true_sec_struct = true_sec_struct[mask_coords][:, mask_coords] # (n_samples, seq_len, seq_len) true_sec_struct = torch.tensor(true_sec_struct) _samples = np.array([[num_to_letter[num] for num in seq] for seq in samples]) _, pred_sec_structs = ribonanza_net_ss.predict(_samples) # (n_samples, seq_len, seq_len) mcc_scores = [] for pred_sec_struct in pred_sec_structs: # map from dotbracket to numerical representation pred_sec_struct = torch.tensor(dotbracket_to_adjacency(pred_sec_struct, keep_pseudoknots=True)) # compute mean MCC score between pairs of true and predicted secondary structures mcc_scores.append( binary_matthews_corrcoef( pred_sec_struct, true_sec_struct, ).float().mean() ) if return_sec_structs: return np.array(mcc_scores), pred_sec_structs else: return np.array(mcc_scores) def self_consistency_score_rhofold( samples, true_raw_data, mask_coords, rhofold, output_dir, num_to_letter = NUM_TO_LETTER, save_designs = False, save_pdbs = False, use_relax = False, ): \u0026#34;\u0026#34;\u0026#34; Compute self consistency score for an RNA, given its true 3D structure(s) for the original RNA and a list of designed sequences. RhoFold is used to \u0026#39;forward fold\u0026#39; the designs. Credit: adapted from Rishabh Anand Args: samples: designed sequences of shape (n_samples, seq_len) true_raw_data: Original RNA raw data with 3D structure(s) in `coords_list` mask_coords: mask for missing sequence coordinates to be ignored during evaluation rhofold: RhoFold model output_dir: directory to save designed sequences and structures num_to_letter: lookup table mapping integers to nucleotides save_designs: whether to save designs as fasta to output directory save_pdbs: whether to save PDBs of forward-folded designs to output directory use_relax: whether to perform Amber relaxation on designed structures Workflow: Input: For a given RNA molecule, we are given: - Designed sequences of shape (n_samples, seq_len) - True 3D structure(s) of shape (n_true_structs, seq_len, 3) For each designed sequence: - Predict the tertiary structure using RhoFold - For each pair of true and predicted 3D structures: - Compute RMSD, TM-score \u0026amp; GDT between their C4\u0026#39; coordinates Take the average self-consistency scores across all n_samples designed sequences Returns: sc_rmsds: array of RMSD scores per sample sc_tms: array of TM-score scores per sample sc_gddts: array of GDT scores per sample \u0026#34;\u0026#34;\u0026#34; os.makedirs(output_dir, exist_ok=True) # Collate designed sequences in fasta format # first record: input sequence and model metadata input_seq = SeqRecord( Seq(true_raw_data[\u0026#34;sequence\u0026#34;]), id=f\u0026#34;input_sequence,\u0026#34;, description=f\u0026#34;input_sequence\u0026#34; ) # SeqIO.write(input_seq, os.path.join(output_dir, \u0026#34;input_seq.fasta\u0026#34;), \u0026#34;fasta\u0026#34;) sequences = [input_seq] # remaining records: designed sequences and metrics sc_rmsds = [] sc_tms = [] sc_gddts = [] for idx, seq in enumerate(samples): # Save designed sequence to fasta file (temporary) seq = SeqRecord( Seq(\u0026#34;\u0026#34;.join([num_to_letter[num] for num in seq])), id=f\u0026#34;sample={idx},\u0026#34;, description=f\u0026#34;sample={idx}\u0026#34; ) sequences.append(seq) design_fasta_path = os.path.join(output_dir, f\u0026#34;design{idx}.fasta\u0026#34;) SeqIO.write(seq, design_fasta_path, \u0026#34;fasta\u0026#34;) # Forward fold designed sequence using RhoFold design_pdb_path = os.path.join(output_dir, f\u0026#34;design{idx}.pdb\u0026#34;) rhofold.predict(design_fasta_path, design_pdb_path, use_relax) # Load C4\u0026#39; coordinates of designed structure _, coords, _, _ = pdb_to_tensor( design_pdb_path, return_sec_struct=False, return_sasa=False, keep_insertions=False, ) coords = get_c4p_coords(coords) # zero-center coordinates coords = coords - coords.mean(dim=0) # Compute self-consistency between designed and groundtruth structures _sc_rmsds = [] _sc_tms = [] _sc_gddts = [] for other_coords in true_raw_data[\u0026#34;coords_list\u0026#34;]: _other = get_c4p_coords(other_coords)[mask_coords, :] # zero-center other coordinates _other = _other - _other.mean(dim=0) # globally align coordinates R_hat = rotation_matrix( _other, # mobile set coords # reference set )[0] _other = _other @ R_hat.T # compute metrics _sc_rmsds.append(get_rmsd( coords, _other, superposition=True, center=True)) _sc_tms.append(get_tmscore(coords, _other)) _sc_gddts.append(get_gddt(coords, _other)) sc_rmsds.append(np.mean(_sc_rmsds)) sc_tms.append(np.mean(_sc_tms)) sc_gddts.append(np.mean(_sc_gddts)) # remove temporary files os.unlink(design_fasta_path) if save_pdbs is False: os.unlink(design_pdb_path) if save_designs is False: # remove output directory shutil.rmtree(output_dir) else: # write all designed sequences to output filepath SeqIO.write(sequences, os.path.join(output_dir, \u0026#34;all_designs.fasta\u0026#34;), \u0026#34;fasta\u0026#34;) return np.array(sc_rmsds), np.array(sc_tms), np.array(sc_gddts) def get_tmscore(y_hat: torch.Tensor, y: torch.Tensor) -\u0026gt; torch.Tensor: \u0026#34;\u0026#34;\u0026#34;Template Modelling score (TM-score). Credit: Arian Jamasb, graphein (https://github.com/a-r-j/graphein) https://en.wikipedia.org/wiki/Template_modeling_score TM-score is a measure of similarity between two protein structures. The TM-score is intended as a more accurate measure of the global similarity of full-length protein structures than the often used RMSD measure. The TM-score indicates the similarity between two structures by a score between ``[0, 1]``, where 1 indicates a perfect match between two structures (thus the higher the better). Generally scores below 0.20 corresponds to randomly chosen unrelated proteins whereas structures with a score higher than 0.5 assume roughly the same fold. A quantitative study shows that proteins of TM-score = 0.5 have a posterior probability of 37% in the same CATH topology family and of 13% in the same SCOP fold family. The probabilities increase rapidly when TM-score \u0026gt; 0.5. The TM-score is designed to be independent of protein lengths. We have adapted the implementation to RNA (TM-score threshold = 0.45). Requires aligned C4\u0026#39; coordinates as input. \u0026#34;\u0026#34;\u0026#34; l_target = y.shape[0] d0_l_target = 1.24 * np.power(l_target - 15, 1 / 3) - 1.8 di = torch.pairwise_distance(y_hat, y) out = torch.sum(1 / (1 + (di / d0_l_target) ** 2)) / l_target if torch.isnan(out): return torch.tensor(0.0) return out def get_gddt(y_hat: torch.Tensor, y: torch.Tensor) -\u0026gt; torch.Tensor: \u0026#34;\u0026#34;\u0026#34;Global Distance Deviation Test metric (GDDT). Credit: Arian Jamasb, graphein (https://github.com/a-r-j/graphein) https://en.wikipedia.org/wiki/Global_distance_test The GDT score is calculated as the largest set of amino acid residues\u0026#39; alpha carbon atoms in the model structure falling within a defined distance cutoff of their position in the experimental structure, after iteratively superimposing the two structures. By the original design the GDT algorithm calculates 20 GDT scores, i.e. for each of 20 consecutive distance cutoffs (``0.5 Å, 1.0 Å, 1.5 Å, ... 10.0 Å``). For structure similarity assessment it is intended to use the GDT scores from several cutoff distances, and scores generally increase with increasing cutoff. A plateau in this increase may indicate an extreme divergence between the experimental and predicted structures, such that no additional atoms are included in any cutoff of a reasonable distance. The conventional GDT_TS total score in CASP is the average result of cutoffs at ``1``, ``2``, ``4``, and ``8`` Å. Random predictions give around 20; getting the gross topology right gets one to ~50; accurate topology is usually around 70; and when all the little bits and pieces, including side-chain conformations, are correct, GDT_TS begins to climb above 90. We have adapted the implementation to RNA. Requires aligned C4\u0026#39; coordinates as input. \u0026#34;\u0026#34;\u0026#34; # Get distance between points dist = torch.norm(y - y_hat, dim=1) # Return mean fraction of distances below cutoff for each cutoff (1, 2, 4, 8) count_1 = (dist \u0026lt; 1).sum() / dist.numel() count_2 = (dist \u0026lt; 2).sum() / dist.numel() count_4 = (dist \u0026lt; 4).sum() / dist.numel() count_8 = (dist \u0026lt; 8).sum() / dist.numel() out = torch.mean(torch.tensor([count_1, count_2, count_4, count_8])) if torch.isnan(out): return torch.tensor(0.0) return out def edit_distance(s: str, t: str) -\u0026gt; int: \u0026#34;\u0026#34;\u0026#34; A Space efficient Dynamic Programming based Python3 program to find minimum number operations to convert str1 to str2 Source: https://www.geeksforgeeks.org/edit-distance-dp-5/ \u0026#34;\u0026#34;\u0026#34; n = len(s) m = len(t) prev = [j for j in range(m+1)] curr = [0] * (m+1) for i in range(1, n+1): curr[0] = i for j in range(1, m+1): if s[i-1] == t[j-1]: curr[j] = prev[j-1] else: mn = min(1 + prev[j], 1 + curr[j-1]) curr[j] = min(mn, 1 + prev[j-1]) prev = curr.copy() return prev[m] 除此之外，需要加一层简单的attention，models.py代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 ################################################################ # Generalisation of Geometric Vector Perceptron, Jing et al. # for explicit multi-state biomolecule representation learning. # Original repository: https://github.com/drorlab/gvp-pytorch ################################################################ from typing import Optional import torch from torch import nn import torch.nn.functional as F from torch.distributions import Categorical import torch_geometric from src.layers import * class AutoregressiveMultiGNNv1(torch.nn.Module): \u0026#39;\u0026#39;\u0026#39; Autoregressive GVP-GNN for **multiple** structure-conditioned RNA design. Takes in RNA structure graphs of type `torch_geometric.data.Data` or `torch_geometric.data.Batch` and returns a categorical distribution over 4 bases at each position in a `torch.Tensor` of shape [n_nodes, 4]. The standard forward pass requires sequence information as input and should be used for training or evaluating likelihood. For sampling or design, use `self.sample`. Args: node_in_dim (tuple): node dimensions in input graph node_h_dim (tuple): node dimensions to use in GVP-GNN layers node_in_dim (tuple): edge dimensions in input graph edge_h_dim (tuple): edge dimensions to embed in GVP-GNN layers num_layers (int): number of GVP-GNN layers in encoder/decoder drop_rate (float): rate to use in all dropout layers out_dim (int): output dimension (4 bases) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_in_dim = (64, 4), node_h_dim = (128, 16), edge_in_dim = (32, 1), edge_h_dim = (32, 1), num_layers = 3, drop_rate = 0.1, out_dim = 4, ): super().__init__() self.node_in_dim = node_in_dim self.node_h_dim = node_h_dim self.edge_in_dim = edge_in_dim self.edge_h_dim = edge_h_dim self.num_layers = num_layers self.out_dim = out_dim activations = (F.silu, None) # Node input embedding self.W_v = torch.nn.Sequential( LayerNorm(self.node_in_dim), GVP(self.node_in_dim, self.node_h_dim, activations=(None, None), vector_gate=True) ) # Edge input embedding self.W_e = torch.nn.Sequential( LayerNorm(self.edge_in_dim), GVP(self.edge_in_dim, self.edge_h_dim, activations=(None, None), vector_gate=True) ) # Encoder layers (supports multiple conformations) self.encoder_layers = nn.ModuleList( MultiGVPConvLayer(self.node_h_dim, self.edge_h_dim, activations=activations, vector_gate=True, drop_rate=drop_rate, norm_first=True) for _ in range(num_layers)) # Simple self-attention on pooled scalar node features self.attn = nn.MultiheadAttention( embed_dim=self.node_h_dim[0], num_heads=4, dropout=drop_rate, batch_first=True ) self.attn_ln = nn.LayerNorm(self.node_h_dim[0]) # Decoder layers self.W_s = nn.Embedding(self.out_dim, self.out_dim) self.edge_h_dim = (self.edge_h_dim[0] + self.out_dim, self.edge_h_dim[1]) self.decoder_layers = nn.ModuleList( GVPConvLayer(self.node_h_dim, self.edge_h_dim, activations=activations, vector_gate=True, drop_rate=drop_rate, autoregressive=True, norm_first=True) for _ in range(num_layers)) # Output self.W_out = GVP(self.node_h_dim, (self.out_dim, 0), activations=(None, None)) def forward(self, batch): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index seq = batch.seq h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features: # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) # Apply simple self-attention over nodes (sequence length = n_nodes) x = h_V[0].unsqueeze(0) # (1, n_nodes, d_s) attn_out, _ = self.attn(x, x, x, need_weights=False) x = self.attn_ln(x + attn_out) h_V = (x.squeeze(0), h_V[1]) encoder_embeddings = h_V h_S = self.W_s(seq) h_S = h_S[edge_index[0]] h_S[edge_index[0] \u0026gt;= edge_index[1]] = 0 h_E = (torch.cat([h_E[0], h_S], dim=-1), h_E[1]) for layer in self.decoder_layers: h_V = layer(h_V, edge_index, h_E, autoregressive_x = encoder_embeddings) logits = self.W_out(h_V) return logits @torch.no_grad() def sample( self, batch, n_samples, temperature: Optional[float] = 0.1, logit_bias: Optional[torch.Tensor] = None, return_logits: Optional[bool] = False ): \u0026#39;\u0026#39;\u0026#39; Samples sequences autoregressively from the distribution learned by the model. Args: batch (torch_geometric.data.Data): mini-batch containing one RNA backbone to design sequences for n_samples (int): number of samples temperature (float): temperature to use in softmax over the categorical distribution logit_bias (torch.Tensor): bias to add to logits during sampling to manually fix or control nucleotides in designed sequences, of shape [n_nodes, 4] return_logits (bool): whether to return logits or not Returns: seq (torch.Tensor): int tensor of shape [n_samples, n_nodes] based on the residue-to-int mapping of the original training data logits (torch.Tensor): logits of shape [n_samples, n_nodes, 4] (only if return_logits is True) \u0026#39;\u0026#39;\u0026#39; h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index device = edge_index.device num_nodes = h_V[0].shape[0] h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) # Apply simple self-attention over nodes (sequence length = n_nodes) x = h_V[0].unsqueeze(0) # (1, n_nodes, d_s) attn_out, _ = self.attn(x, x, x, need_weights=False) x = self.attn_ln(x + attn_out) h_V = (x.squeeze(0), h_V[1]) # Repeat features for sampling n_samples times h_V = (h_V[0].repeat(n_samples, 1), h_V[1].repeat(n_samples, 1, 1)) h_E = (h_E[0].repeat(n_samples, 1), h_E[1].repeat(n_samples, 1, 1)) # Expand edge index for autoregressive decoding edge_index = edge_index.expand(n_samples, -1, -1) offset = num_nodes * torch.arange(n_samples, device=device).view(-1, 1, 1) edge_index = torch.cat(tuple(edge_index + offset), dim=-1) # This is akin to \u0026#39;batching\u0026#39; (in PyG style) n_samples copies of the graph seq = torch.zeros(n_samples * num_nodes, device=device, dtype=torch.int) h_S = torch.zeros(n_samples * num_nodes, self.out_dim, device=device) logits = torch.zeros(n_samples * num_nodes, self.out_dim, device=device) h_V_cache = [(h_V[0].clone(), h_V[1].clone()) for _ in self.decoder_layers] # Decode one token at a time for i in range(num_nodes): h_S_ = h_S[edge_index[0]] h_S_[edge_index[0] \u0026gt;= edge_index[1]] = 0 h_E_ = (torch.cat([h_E[0], h_S_], dim=-1), h_E[1]) edge_mask = edge_index[1] % num_nodes == i # True for all edges where dst is node i edge_index_ = edge_index[:, edge_mask] # subset all incoming edges to node i h_E_ = tuple_index(h_E_, edge_mask) node_mask = torch.zeros(n_samples * num_nodes, device=device, dtype=torch.bool) node_mask[i::num_nodes] = True # True for all nodes i and its repeats for j, layer in enumerate(self.decoder_layers): out = layer(h_V_cache[j], edge_index_, h_E_, autoregressive_x=h_V_cache[0], node_mask=node_mask) out = tuple_index(out, node_mask) # subset out to only node i and its repeats if j \u0026lt; len(self.decoder_layers)-1: h_V_cache[j+1][0][i::num_nodes] = out[0] h_V_cache[j+1][1][i::num_nodes] = out[1] lgts = self.W_out(out) # Add logit bias if provided to fix or bias positions if logit_bias is not None: lgts += logit_bias[i] # Sample from logits seq[i::num_nodes] = Categorical(logits=lgts / temperature).sample() h_S[i::num_nodes] = self.W_s(seq[i::num_nodes]) logits[i::num_nodes] = lgts if return_logits: return seq.view(n_samples, num_nodes), logits.view(n_samples, num_nodes, self.out_dim) else: return seq.view(n_samples, num_nodes) def pool_multi_conf(self, h_V, h_E, mask_confs, edge_index): if mask_confs.size(1) == 1: # Number of conformations is 1, no need to pool return (h_V[0][:, 0], h_V[1][:, 0]), (h_E[0][:, 0], h_E[1][:, 0]) # True num_conf for masked mean pooling n_conf_true = mask_confs.sum(1, keepdim=True) # (n_nodes, 1) # Mask scalar features mask = mask_confs.unsqueeze(2) # (n_nodes, n_conf, 1) h_V0 = h_V[0] * mask h_E0 = h_E[0] * mask[edge_index[0]] # Mask vector features mask = mask.unsqueeze(3) # (n_nodes, n_conf, 1, 1) h_V1 = h_V[1] * mask h_E1 = h_E[1] * mask[edge_index[0]] # Average pooling multi-conformation features h_V = (h_V0.sum(dim=1) / n_conf_true, # (n_nodes, d_s) h_V1.sum(dim=1) / n_conf_true.unsqueeze(2)) # (n_nodes, d_v, 3) h_E = (h_E0.sum(dim=1) / n_conf_true[edge_index[0]], # (n_edges, d_se) h_E1.sum(dim=1) / n_conf_true[edge_index[0]].unsqueeze(2)) # (n_edges, d_ve, 3) return h_V, h_E class NonAutoregressiveMultiGNNv1(torch.nn.Module): \u0026#39;\u0026#39;\u0026#39; Non-Autoregressive GVP-GNN for **multiple** structure-conditioned RNA design. Takes in RNA structure graphs of type `torch_geometric.data.Data` or `torch_geometric.data.Batch` and returns a categorical distribution over 4 bases at each position in a `torch.Tensor` of shape [n_nodes, 4]. The standard forward pass requires sequence information as input and should be used for training or evaluating likelihood. For sampling or design, use `self.sample`. Args: node_in_dim (tuple): node dimensions in input graph node_h_dim (tuple): node dimensions to use in GVP-GNN layers node_in_dim (tuple): edge dimensions in input graph edge_h_dim (tuple): edge dimensions to embed in GVP-GNN layers num_layers (int): number of GVP-GNN layers in encoder/decoder drop_rate (float): rate to use in all dropout layers out_dim (int): output dimension (4 bases) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_in_dim = (64, 4), node_h_dim = (128, 16), edge_in_dim = (32, 1), edge_h_dim = (32, 1), num_layers = 3, drop_rate = 0.1, out_dim = 4, ): super().__init__() self.node_in_dim = node_in_dim self.node_h_dim = node_h_dim self.edge_in_dim = edge_in_dim self.edge_h_dim = edge_h_dim self.num_layers = num_layers self.out_dim = out_dim activations = (F.silu, None) # Node input embedding self.W_v = torch.nn.Sequential( LayerNorm(self.node_in_dim), GVP(self.node_in_dim, self.node_h_dim, activations=(None, None), vector_gate=True) ) # Edge input embedding self.W_e = torch.nn.Sequential( LayerNorm(self.edge_in_dim), GVP(self.edge_in_dim, self.edge_h_dim, activations=(None, None), vector_gate=True) ) # Encoder layers (supports multiple conformations) self.encoder_layers = nn.ModuleList( MultiGVPConvLayer(self.node_h_dim, self.edge_h_dim, activations=activations, vector_gate=True, drop_rate=drop_rate, norm_first=True) for _ in range(num_layers)) # Simple self-attention on pooled scalar node features self.attn = nn.MultiheadAttention( embed_dim=self.node_h_dim[0], num_heads=4, dropout=drop_rate, batch_first=True ) self.attn_ln = nn.LayerNorm(self.node_h_dim[0]) # Output self.W_out = torch.nn.Sequential( LayerNorm(self.node_h_dim), GVP(self.node_h_dim, self.node_h_dim, activations=(None, None), vector_gate=True), GVP(self.node_h_dim, (self.out_dim, 0), activations=(None, None)) ) def forward(self, batch): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features: # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) # h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) h_V = (h_V[0].mean(dim=1), h_V[1].mean(dim=1)) # Apply simple self-attention over nodes (sequence length = n_nodes) x = h_V[0].unsqueeze(0) # (1, n_nodes, d_s) attn_out, _ = self.attn(x, x, x, need_weights=False) x = self.attn_ln(x + attn_out) h_V = (x.squeeze(0), h_V[1]) logits = self.W_out(h_V) # (n_nodes, out_dim) return logits def sample(self, batch, n_samples, temperature=0.1, return_logits=False): with torch.no_grad(): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features # h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) h_V = (h_V[0].mean(dim=1), h_V[1].mean(dim=1)) logits = self.W_out(h_V) # (n_nodes, out_dim) probs = F.softmax(logits / temperature, dim=-1) seq = torch.multinomial(probs, n_samples, replacement=True) # (n_nodes, n_samples) if return_logits: return seq.permute(1, 0).contiguous(), logits.unsqueeze(0).repeat(n_samples, 1, 1) else: return seq.permute(1, 0).contiguous() def pool_multi_conf(self, h_V, h_E, mask_confs, edge_index): if mask_confs.size(1) == 1: # Number of conformations is 1, no need to pool return (h_V[0][:, 0], h_V[1][:, 0]), (h_E[0][:, 0], h_E[1][:, 0]) # True num_conf for masked mean pooling n_conf_true = mask_confs.sum(1, keepdim=True) # (n_nodes, 1) # Mask scalar features mask = mask_confs.unsqueeze(2) # (n_nodes, n_conf, 1) h_V0 = h_V[0] * mask h_E0 = h_E[0] * mask[edge_index[0]] # Mask vector features mask = mask.unsqueeze(3) # (n_nodes, n_conf, 1, 1) h_V1 = h_V[1] * mask h_E1 = h_E[1] * mask[edge_index[0]] # Average pooling multi-conformation features h_V = (h_V0.sum(dim=1) / n_conf_true, # (n_nodes, d_s) h_V1.sum(dim=1) / n_conf_true.unsqueeze(2)) # (n_nodes, d_v, 3) h_E = (h_E0.sum(dim=1) / n_conf_true[edge_index[0]], # (n_edges, d_se) h_E1.sum(dim=1) / n_conf_true[edge_index[0]].unsqueeze(2)) # (n_edges, d_ve, 3) return h_V, h_E 而由于本地服务器一般很难登上wandb，而作者原版代码在路径上用了很多相关的，因而在trainer.py更改路径，\n1 2 3 4 5 6 7 8 if device.type == \u0026#39;xpu\u0026#39;: import intel_extension_for_pytorch as ipex model, optimizer = ipex.optimize(model, optimizer=optimizer) #=======上面的和作者的一样======= # Initialise save directory save_dir = os.path.join(os.path.dirname(__file__), \u0026#34;..\u0026#34;, \u0026#34;mymodel\u0026#34;) #save_dir = os.path.abspath(save_dir) 这是换成绝对路径，可以不需要；模型保存在主项目目录的mymodel文件夹。 os.makedirs(save_dir, exist_ok=True) 之后把wandb.run.dir路径改为save_dir路径，防止训练模型后没有文件；模型默认选择autoaggresive。\n注意，训练模型最好挂在后台运行，具体命令如下：\n1 nohup python main.py --no_wandb \u0026gt; main.log 2\u0026gt;\u0026amp;1 \u0026amp; 然后可以查看log日志，\n1 tail -f main.log 以及及时选择查看gpu的运行情况，例如，\n1 nvidia-smi 第一次测试训练的模型 模型以best_checkpoint.h5形式得出，然后根据作者的gRNAde.py脚本，只需修改以下的加载路径和其他没啥用的print字符串就可以，由于多态生成我没有用，因此我没替换那个；其余俩都得替换。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 CHECKPOINT_PATH = { \u0026#39;all\u0026#39;: { 1: os.path.join(PROJECT_PATH, \u0026#34;mymodel/best_checkpoint.h5\u0026#34;),#修改为mymodel里的checkpoint 2: os.path.join(PROJECT_PATH, \u0026#34;checkpoints/gRNAde_ARv1_2state_all.h5\u0026#34;), 3: os.path.join(PROJECT_PATH, \u0026#34;checkpoints/gRNAde_ARv1_3state_all.h5\u0026#34;), 5: os.path.join(PROJECT_PATH, \u0026#34;checkpoints/gRNAde_ARv1_5state_all.h5\u0026#34;), }, \u0026#39;das\u0026#39;: { 1: os.path.join(PROJECT_PATH, \u0026#34;mymodel/best_checkpoint.h5\u0026#34;),#修改为mymodel里的checkpoint 2: os.path.join(PROJECT_PATH, \u0026#34;checkpoints/gRNAde_ARv1_2state_das.h5\u0026#34;), 3: os.path.join(PROJECT_PATH, \u0026#34;checkpoints/gRNAde_ARv1_3state_das.h5\u0026#34;), 5: os.path.join(PROJECT_PATH, \u0026#34;checkpoints/gRNAde_ARv1_5state_das.h5\u0026#34;), }, \u0026#39;multi\u0026#39;: { 1: os.path.join(PROJECT_PATH, \u0026#34;checkpoints/gRNAde_ARv1_1state_multi.h5\u0026#34;), 2: os.path.join(PROJECT_PATH, \u0026#34;checkpoints/gRNAde_ARv1_2state_multi.h5\u0026#34;), 3: os.path.join(PROJECT_PATH, \u0026#34;checkpoints/gRNAde_ARv1_3state_multi.h5\u0026#34;), 5: os.path.join(PROJECT_PATH, \u0026#34;checkpoints/gRNAde_ARv1_5state_multi.h5\u0026#34;), } } 除此之外，通过命令行人工测试太费劲了，需要写一个自动化脚本。具体逻辑就是，我在data/raw里面取一些名称作为索引，保存在.txt文件中；然后用脚本把原先命令行的命令包含进去，input文件路径下改为按索引名称.pdb递增，输出.fasta文件同理，注意models.py文件要保持同步！！！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 #这是自动化测试脚本 import os import subprocess import sys from pathlib import Path def read_test_index(index_file=\u0026#34;test.txt\u0026#34;): \u0026#34;\u0026#34;\u0026#34; Read test_index.txt file to get the list of PDB files \u0026#34;\u0026#34;\u0026#34; try: with open(index_file, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: lines = f.readlines() # Filter out empty lines and comment lines, remove newline characters pdb_files = [] for line in lines: line = line.strip() if line and not line.startswith(\u0026#39;#\u0026#39;): pdb_files.append(line) return pdb_files except FileNotFoundError: print(f\u0026#34;Error: File {index_file} not found\u0026#34;) return [] except Exception as e: print(f\u0026#34;Error reading file: {e}\u0026#34;) return [] def extract_filename_without_extension(pdb_filename): \u0026#34;\u0026#34;\u0026#34; Extract the filename without extension from a PDB filename Example: 100D_1_A-B.pdb -\u0026gt; 100D_1_A-B \u0026#34;\u0026#34;\u0026#34; return Path(pdb_filename).stem def run_command(pdb_file): \u0026#34;\u0026#34;\u0026#34; Execute the run.py command for the specified PDB file \u0026#34;\u0026#34;\u0026#34; # Extract filename (without extension) for output filename output_name = extract_filename_without_extension(pdb_file) # Build command cmd = [ \u0026#34;python\u0026#34;, \u0026#34;run.py\u0026#34;, \u0026#34;--pdb_filepath\u0026#34;, f\u0026#34;data/raw/{pdb_file}\u0026#34;, \u0026#34;--output_filepath\u0026#34;, f\u0026#34;testmyrna/{output_name}.fasta\u0026#34;, \u0026#34;--split\u0026#34;, \u0026#34;das\u0026#34;, \u0026#34;--max_num_conformers\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;--n_samples\u0026#34;, \u0026#34;16\u0026#34;, \u0026#34;--temperature\u0026#34;, \u0026#34;0.5\u0026#34; ] print(f\u0026#34;Processing: {pdb_file}\u0026#34;) print(f\u0026#34;Executing command: {\u0026#39; \u0026#39;.join(cmd)}\u0026#34;) try: # Execute command result = subprocess.run(cmd, capture_output=True, text=True, check=True) print(f\u0026#34;✓ Successfully processed {pdb_file}\u0026#34;) print(f\u0026#34;Output file: testmyrna/{output_name}.fasta\u0026#34;) # Display part of the output if available if result.stdout: print(\u0026#34;Standard output:\u0026#34;) print(result.stdout[:200] + (\u0026#34;...\u0026#34; if len(result.stdout) \u0026gt; 200 else \u0026#34;\u0026#34;)) return True except subprocess.CalledProcessError as e: print(f\u0026#34;✗ Failed to process {pdb_file}\u0026#34;) print(f\u0026#34;Error code: {e.returncode}\u0026#34;) if e.stderr: print(f\u0026#34;Error message: {e.stderr}\u0026#34;) return False except Exception as e: print(f\u0026#34;✗ Unexpected error occurred while processing {pdb_file}: {e}\u0026#34;) return False def main(): \u0026#34;\u0026#34;\u0026#34; Main function \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;=== RNA Test Script Started ===\u0026#34;) # Check for required files and directories if not os.path.exists(\u0026#34;run.py\u0026#34;): print(\u0026#34;Error: run.py file not found in the current directory\u0026#34;) sys.exit(1) if not os.path.exists(\u0026#34;test.txt\u0026#34;): print(\u0026#34;Error: test.txt file not found in the current directory\u0026#34;) sys.exit(1) # Ensure output directory exists output_dir = \u0026#34;testmyrna\u0026#34; os.makedirs(output_dir, exist_ok=True) print(f\u0026#34;Output directory: {output_dir}\u0026#34;) # Read test index file pdb_files = read_test_index() if not pdb_files: print(\u0026#34;Warning: test.txt file is empty or failed to read\u0026#34;) sys.exit(1) print(f\u0026#34;Found {len(pdb_files)} PDB files to process:\u0026#34;) for i, pdb_file in enumerate(pdb_files, 1): print(f\u0026#34; {i}. {pdb_file}\u0026#34;) print(\u0026#34;\\nStarting processing...\u0026#34;) # Statistics success_count = 0 failed_files = [] # Process each PDB file for i, pdb_file in enumerate(pdb_files, 1): print(f\u0026#34;\\n[{i}/{len(pdb_files)}] \u0026#34; + \u0026#34;=\u0026#34;*50) # Check if input file exists input_path = f\u0026#34;data/raw/{pdb_file}\u0026#34; if not os.path.exists(input_path): print(f\u0026#34;Warning: Input file {input_path} does not exist, skipping...\u0026#34;) failed_files.append(pdb_file) continue # Execute command if run_command(pdb_file): success_count += 1 else: failed_files.append(pdb_file) # Print summary print(\u0026#34;\\n\u0026#34; + \u0026#34;=\u0026#34;*60) print(\u0026#34;=== Processing Completed ===\u0026#34;) print(f\u0026#34;Total: {len(pdb_files)} files\u0026#34;) print(f\u0026#34;Success: {success_count} files\u0026#34;) print(f\u0026#34;Failed: {len(failed_files)} files\u0026#34;) if failed_files: print(\u0026#34;\\nFailed files:\u0026#34;) for failed_file in failed_files: print(f\u0026#34; - {failed_file}\u0026#34;) print(f\u0026#34;\\nOutput files saved in: {output_dir}/\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() 注意，有时sec_struct_utils.py文件清除缓存速度太快了，所以我进行修改，首先把这部分清除的注释了：\n1 2 3 4 5 6 7 8 9 10 output = subprocess.run(cmd, check=True, capture_output=True).stdout.decode(\u0026#34;utf-8\u0026#34;) # Delete temporary files这三行注释掉 # if sequence is not None: # os.remove(fasta_file_path) if n_samples \u0026gt; 1: return output.split(\u0026#34;\\n\u0026#34;)[:-1] else: return [output.split(\u0026#34;\\n\u0026#34;)[-2]] 之后把路径改了，\n1 2 3 4 5 current_datetime = datetime.now().strftime(\u0026#34;%Y%m%d_%H%M%S\u0026#34;) try: fasta_file_path = os.path.join(wandb.run.dir, f\u0026#34;temp_{current_datetime}.fasta\u0026#34;) except AttributeError: fasta_file_path = os.path.join(PROJECT_PATH, \u0026#34;temp\u0026#34;, f\u0026#34;temp_{current_datetime}.fasta\u0026#34;)#改这里路径后是这样，我一般不用wandb 生成在某文件夹后，需要用新的脚本处理数据，由于我的sample为16，因而需要分别计算length, perplexity, recovery, edit distance, SC Score的平均值，并按照列的顺序保存为.txt文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 import os import re import glob from pathlib import Path def parse_fasta_file(fasta_path): \u0026#34;\u0026#34;\u0026#34; Parse a single FASTA file to extract the input sequence length and metrics for 16 samples Returns: - input_length: Length of the input sequence - avg_metrics: Average metrics for 16 samples {perplexity, recovery, edit_dist, sc_score} \u0026#34;\u0026#34;\u0026#34; try: with open(fasta_path, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: content = f.read() # Split different sequence blocks sequences = content.strip().split(\u0026#39;\u0026gt;\u0026#39;) sequences = [seq.strip() for seq in sequences if seq.strip()] input_length = 0 sample_metrics = [] for seq_block in sequences: lines = seq_block.strip().split(\u0026#39;\\n\u0026#39;) if not lines: continue header = lines[0] sequence_lines = lines[1:] # Process input sequence if \u0026#39;input_sequence\u0026#39; in header: # Combine all sequence lines and calculate length sequence = \u0026#39;\u0026#39;.join(sequence_lines).replace(\u0026#39; \u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39;\\n\u0026#39;, \u0026#39;\u0026#39;) input_length = len(sequence) print(f\u0026#34; Input sequence length: {input_length}\u0026#34;) # Process sample sequence elif \u0026#39;sample=\u0026#39; in header: # Extract metrics using regular expressions perplexity_match = re.search(r\u0026#39;perplexity=([0-9.]+)\u0026#39;, header) recovery_match = re.search(r\u0026#39;recovery=([0-9.]+)\u0026#39;, header) edit_dist_match = re.search(r\u0026#39;edit_dist=([0-9.]+)\u0026#39;, header) sc_score_match = re.search(r\u0026#39;sc_score=([0-9.]+)\u0026#39;, header) if all([perplexity_match, recovery_match, edit_dist_match, sc_score_match]): metrics = { \u0026#39;perplexity\u0026#39;: float(perplexity_match.group(1)), \u0026#39;recovery\u0026#39;: float(recovery_match.group(1)), \u0026#39;edit_dist\u0026#39;: float(edit_dist_match.group(1)), \u0026#39;sc_score\u0026#39;: float(sc_score_match.group(1)) } sample_metrics.append(metrics) # Calculate averages if sample_metrics: avg_metrics = { \u0026#39;perplexity\u0026#39;: sum(m[\u0026#39;perplexity\u0026#39;] for m in sample_metrics) / len(sample_metrics), \u0026#39;recovery\u0026#39;: sum(m[\u0026#39;recovery\u0026#39;] for m in sample_metrics) / len(sample_metrics), \u0026#39;edit_dist\u0026#39;: sum(m[\u0026#39;edit_dist\u0026#39;] for m in sample_metrics) / len(sample_metrics), \u0026#39;sc_score\u0026#39;: sum(m[\u0026#39;sc_score\u0026#39;] for m in sample_metrics) / len(sample_metrics) } print(f\u0026#34; Found {len(sample_metrics)} samples\u0026#34;) print(f\u0026#34; Average metrics: perplexity={avg_metrics[\u0026#39;perplexity\u0026#39;]:.4f}, recovery={avg_metrics[\u0026#39;recovery\u0026#39;]:.4f}, edit_dist={avg_metrics[\u0026#39;edit_dist\u0026#39;]:.4f}, sc_score={avg_metrics[\u0026#39;sc_score\u0026#39;]:.4f}\u0026#34;) else: print(\u0026#34; Warning: No valid sample metrics found\u0026#34;) avg_metrics = None return input_length, avg_metrics except Exception as e: print(f\u0026#34; Error: Exception occurred while processing file: {e}\u0026#34;) return 0, None def process_all_fasta_files(input_dir=\u0026#34;tout\u0026#34;, output_file=\u0026#34;data/plotdata/plot.txt\u0026#34;): \u0026#34;\u0026#34;\u0026#34; Process all FASTA files in the specified directory \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;=== FASTA File Processing Script ===\u0026#34;) # Check input directory if not os.path.exists(input_dir): print(f\u0026#34;Error: Input directory does not exist: {input_dir}\u0026#34;) return # Create output directory output_dir = os.path.dirname(output_file) if output_dir: os.makedirs(output_dir, exist_ok=True) print(f\u0026#34;Output directory: {output_dir}\u0026#34;) # Find all FASTA files fasta_pattern = os.path.join(input_dir, \u0026#34;*.fasta\u0026#34;) fasta_files = glob.glob(fasta_pattern) if not fasta_files: print(f\u0026#34;Warning: No .fasta files found in {input_dir}\u0026#34;) return print(f\u0026#34;Found {len(fasta_files)} FASTA files\u0026#34;) # Store processing results results = [] processed_count = 0 failed_count = 0 # Process each FASTA file for i, fasta_file in enumerate(sorted(fasta_files), 1): filename = os.path.basename(fasta_file) print(f\u0026#34;\\n[{i}/{len(fasta_files)}] Processing file: {filename}\u0026#34;) input_length, avg_metrics = parse_fasta_file(fasta_file) if input_length \u0026gt; 0 and avg_metrics is not None: # Format result result_line = f\u0026#34;{input_length} {avg_metrics[\u0026#39;perplexity\u0026#39;]:.4f} {avg_metrics[\u0026#39;recovery\u0026#39;]:.4f} {avg_metrics[\u0026#39;edit_dist\u0026#39;]:.4f} {avg_metrics[\u0026#39;sc_score\u0026#39;]:.4f}\u0026#34; results.append(result_line) processed_count += 1 print(f\u0026#34; ✓ Processed successfully\u0026#34;) else: print(f\u0026#34; ✗ Processing failed\u0026#34;) failed_count += 1 # Save results if results: try: with open(output_file, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: for result in results: f.write(result + \u0026#39;\\n\u0026#39;) print(f\u0026#34;\\n=== Processing Completed ===\u0026#34;) print(f\u0026#34;Total files: {len(fasta_files)}\u0026#34;) print(f\u0026#34;Successfully processed: {processed_count}\u0026#34;) print(f\u0026#34;Failed: {failed_count}\u0026#34;) print(f\u0026#34;Results saved to: {output_file}\u0026#34;) # Show preview of first few lines print(f\u0026#34;\\nResults preview (first 5 lines):\u0026#34;) for i, result in enumerate(results[:5]): print(f\u0026#34; {result}\u0026#34;) if len(results) \u0026gt; 5: print(f\u0026#34; ... (total {len(results)} lines)\u0026#34;) except Exception as e: print(f\u0026#34;Error saving file: {e}\u0026#34;) else: print(\u0026#34;No successfully processed data, unable to generate output file\u0026#34;) def validate_output_format(output_file): \u0026#34;\u0026#34;\u0026#34; Validate the format of the output file \u0026#34;\u0026#34;\u0026#34; if not os.path.exists(output_file): print(\u0026#34;Output file does not exist\u0026#34;) return print(f\u0026#34;\\n=== Validate Output Format ===\u0026#34;) try: with open(output_file, \u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: lines = f.readlines() print(f\u0026#34;Total lines: {len(lines)}\u0026#34;) for i, line in enumerate(lines[:3], 1): # Check first 3 lines parts = line.strip().split() if len(parts) == 5: length = int(parts[0]) perplexity = float(parts[1]) recovery = float(parts[2]) edit_dist = float(parts[3]) sc_score = float(parts[4]) print(f\u0026#34;Line {i}: length={length}, perplexity={perplexity}, recovery={recovery}, edit_dist={edit_dist}, sc_score={sc_score}\u0026#34;) else: print(f\u0026#34;Line {i} format error: {line.strip()}\u0026#34;) except Exception as e: print(f\u0026#34;Error during validation: {e}\u0026#34;) def main(): \u0026#34;\u0026#34;\u0026#34; Main function \u0026#34;\u0026#34;\u0026#34; # Set input and output paths input_directory = \u0026#34;tout\u0026#34; output_filepath = \u0026#34;data/plotdata/plotgrna.txt\u0026#34; # Process all FASTA files process_all_fasta_files(input_directory, output_filepath) # Validate output format validate_output_format(output_filepath) if __name__ == \u0026#34;__main__\u0026#34;: main() 以及matlab的绘图代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 % Script to visualize RNA prediction metrics from else.txt % Load data data = load(\u0026#39;g.txt\u0026#39;); % Format: [length, perplexity, recovery, edit_dist, sc_score] lengths = data(:, 1); perplexity = data(:, 2); recovery = data(:, 3); edit_dist = data(:, 4); sc_score = data(:, 5); % Compute unique lengths and their average metrics [unique_lengths, ~, idx] = unique(lengths); n = length(unique_lengths); avg_perplexity = zeros(n,1); avg_recovery = zeros(n,1); avg_edit_dist = zeros(n,1); avg_sc_score = zeros(n,1); for i = 1:n avg_perplexity(i) = mean(perplexity(idx == i)); avg_recovery(i) = mean(recovery(idx == i)); avg_edit_dist(i) = mean(edit_dist(idx == i)); avg_sc_score(i) = mean(sc_score(idx == i)); end % Prepare 2x2 subplot figure(\u0026#39;Name\u0026#39;,\u0026#39;RNA Prediction Metrics\u0026#39;,\u0026#39;NumberTitle\u0026#39;,\u0026#39;off\u0026#39;); metrics = {avg_perplexity, avg_recovery, avg_edit_dist, avg_sc_score}; titles = { \u0026#39;Variation of Perplexity with RNA Sequence Length\u0026#39;, ... \u0026#39;Variation of Recovery Rate with RNA Sequence Length\u0026#39;, ... \u0026#39;Variation of Edit Distance with RNA Sequence Length\u0026#39;, ... \u0026#39;Variation of Structural Conservation Score with RNA Sequence Length\u0026#39; }; ylabels = {\u0026#39;Average Perplexity\u0026#39;, \u0026#39;Average Recovery Rate\u0026#39;, ... \u0026#39;Average Edit Distance\u0026#39;, \u0026#39;Average SC Score\u0026#39;}; % Set Times New Roman font for all text set(0,\u0026#39;defaultAxesFontName\u0026#39;,\u0026#39;Times New Roman\u0026#39;); set(0,\u0026#39;defaultTextFontName\u0026#39;,\u0026#39;Times New Roman\u0026#39;); markerSize = 10; markerColor = [0.9, 0.2, 0.2]; lineWidth = 1; for i = 1:4 subplot(2,2,i); scatter(unique_lengths, metrics{i}, markerSize, ... \u0026#39;MarkerEdgeColor\u0026#39;, markerColor, ... \u0026#39;MarkerFaceColor\u0026#39;, markerColor, ... \u0026#39;LineWidth\u0026#39;, lineWidth); xlabel(\u0026#39;RNA Sequence Length (nt)\u0026#39;,\u0026#39;FontName\u0026#39;,\u0026#39;Times New Roman\u0026#39;); ylabel(ylabels{i},\u0026#39;FontName\u0026#39;,\u0026#39;Times New Roman\u0026#39;); title(titles{i},\u0026#39;FontName\u0026#39;,\u0026#39;Times New Roman\u0026#39;); grid on; set(gca,\u0026#39;FontName\u0026#39;,\u0026#39;Times New Roman\u0026#39;); end % Adjust layout sgtitle(\u0026#39;Comparative Analysis of GRNADE Prediction Metrics\u0026#39;,\u0026#39;FontName\u0026#39;,\u0026#39;Times New Roman\u0026#39;); 除此之外，模型models.py如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 ################################################################ # Generalisation of Geometric Vector Perceptron, Jing et al. # for explicit multi-state biomolecule representation learning. # Original repository: https://github.com/drorlab/gvp-pytorch ################################################################ from typing import Optional import torch from torch import nn import torch.nn.functional as F from torch.distributions import Categorical import torch_geometric from src.layers import * class AutoregressiveMultiGNNv1(torch.nn.Module): \u0026#39;\u0026#39;\u0026#39; Autoregressive GVP-GNN for **multiple** structure-conditioned RNA design. Takes in RNA structure graphs of type `torch_geometric.data.Data` or `torch_geometric.data.Batch` and returns a categorical distribution over 4 bases at each position in a `torch.Tensor` of shape [n_nodes, 4]. The standard forward pass requires sequence information as input and should be used for training or evaluating likelihood. For sampling or design, use `self.sample`. Args: node_in_dim (tuple): node dimensions in input graph node_h_dim (tuple): node dimensions to use in GVP-GNN layers node_in_dim (tuple): edge dimensions in input graph edge_h_dim (tuple): edge dimensions to embed in GVP-GNN layers num_layers (int): number of GVP-GNN layers in encoder/decoder drop_rate (float): rate to use in all dropout layers out_dim (int): output dimension (4 bases) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_in_dim = (64, 4), node_h_dim = (128, 16), edge_in_dim = (32, 1), edge_h_dim = (32, 1), num_layers = 3, drop_rate = 0.1, out_dim = 4, ): super().__init__() self.node_in_dim = node_in_dim self.node_h_dim = node_h_dim self.edge_in_dim = edge_in_dim self.edge_h_dim = edge_h_dim self.num_layers = num_layers self.out_dim = out_dim activations = (F.silu, None) # Node input embedding self.W_v = torch.nn.Sequential( LayerNorm(self.node_in_dim), GVP(self.node_in_dim, self.node_h_dim, activations=(None, None), vector_gate=True) ) # Edge input embedding self.W_e = torch.nn.Sequential( LayerNorm(self.edge_in_dim), GVP(self.edge_in_dim, self.edge_h_dim, activations=(None, None), vector_gate=True) ) # Encoder layers (supports multiple conformations) self.encoder_layers = nn.ModuleList( MultiGVPConvLayer(self.node_h_dim, self.edge_h_dim, activations=activations, vector_gate=True, drop_rate=drop_rate, norm_first=True) for _ in range(num_layers)) # Simple self-attention on pooled scalar node features self.attn = nn.MultiheadAttention( embed_dim=self.node_h_dim[0], num_heads=4, dropout=drop_rate, batch_first=True ) self.attn_ln = nn.LayerNorm(self.node_h_dim[0]) # Decoder layers self.W_s = nn.Embedding(self.out_dim, self.out_dim) self.edge_h_dim = (self.edge_h_dim[0] + self.out_dim, self.edge_h_dim[1]) self.decoder_layers = nn.ModuleList( GVPConvLayer(self.node_h_dim, self.edge_h_dim, activations=activations, vector_gate=True, drop_rate=drop_rate, autoregressive=True, norm_first=True) for _ in range(num_layers)) # Output self.W_out = GVP(self.node_h_dim, (self.out_dim, 0), activations=(None, None)) def forward(self, batch): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index seq = batch.seq h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features: # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) # Apply simple self-attention over nodes (sequence length = n_nodes) x = h_V[0].unsqueeze(0) # (1, n_nodes, d_s) attn_out, _ = self.attn(x, x, x, need_weights=False) x = self.attn_ln(x + attn_out) h_V = (x.squeeze(0), h_V[1]) encoder_embeddings = h_V h_S = self.W_s(seq) h_S = h_S[edge_index[0]] h_S[edge_index[0] \u0026gt;= edge_index[1]] = 0 h_E = (torch.cat([h_E[0], h_S], dim=-1), h_E[1]) for layer in self.decoder_layers: h_V = layer(h_V, edge_index, h_E, autoregressive_x = encoder_embeddings) logits = self.W_out(h_V) return logits @torch.no_grad() def sample( self, batch, n_samples, temperature: Optional[float] = 0.1, logit_bias: Optional[torch.Tensor] = None, return_logits: Optional[bool] = False ): \u0026#39;\u0026#39;\u0026#39; Samples sequences autoregressively from the distribution learned by the model. Args: batch (torch_geometric.data.Data): mini-batch containing one RNA backbone to design sequences for n_samples (int): number of samples temperature (float): temperature to use in softmax over the categorical distribution logit_bias (torch.Tensor): bias to add to logits during sampling to manually fix or control nucleotides in designed sequences, of shape [n_nodes, 4] return_logits (bool): whether to return logits or not Returns: seq (torch.Tensor): int tensor of shape [n_samples, n_nodes] based on the residue-to-int mapping of the original training data logits (torch.Tensor): logits of shape [n_samples, n_nodes, 4] (only if return_logits is True) \u0026#39;\u0026#39;\u0026#39; h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index device = edge_index.device num_nodes = h_V[0].shape[0] h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) # Apply simple self-attention over nodes (sequence length = n_nodes) x = h_V[0].unsqueeze(0) # (1, n_nodes, d_s) attn_out, _ = self.attn(x, x, x, need_weights=False) x = self.attn_ln(x + attn_out) h_V = (x.squeeze(0), h_V[1]) # Repeat features for sampling n_samples times h_V = (h_V[0].repeat(n_samples, 1), h_V[1].repeat(n_samples, 1, 1)) h_E = (h_E[0].repeat(n_samples, 1), h_E[1].repeat(n_samples, 1, 1)) # Expand edge index for autoregressive decoding edge_index = edge_index.expand(n_samples, -1, -1) offset = num_nodes * torch.arange(n_samples, device=device).view(-1, 1, 1) edge_index = torch.cat(tuple(edge_index + offset), dim=-1) # This is akin to \u0026#39;batching\u0026#39; (in PyG style) n_samples copies of the graph seq = torch.zeros(n_samples * num_nodes, device=device, dtype=torch.int) h_S = torch.zeros(n_samples * num_nodes, self.out_dim, device=device) logits = torch.zeros(n_samples * num_nodes, self.out_dim, device=device) h_V_cache = [(h_V[0].clone(), h_V[1].clone()) for _ in self.decoder_layers] # Decode one token at a time for i in range(num_nodes): h_S_ = h_S[edge_index[0]] h_S_[edge_index[0] \u0026gt;= edge_index[1]] = 0 h_E_ = (torch.cat([h_E[0], h_S_], dim=-1), h_E[1]) edge_mask = edge_index[1] % num_nodes == i # True for all edges where dst is node i edge_index_ = edge_index[:, edge_mask] # subset all incoming edges to node i h_E_ = tuple_index(h_E_, edge_mask) node_mask = torch.zeros(n_samples * num_nodes, device=device, dtype=torch.bool) node_mask[i::num_nodes] = True # True for all nodes i and its repeats for j, layer in enumerate(self.decoder_layers): out = layer(h_V_cache[j], edge_index_, h_E_, autoregressive_x=h_V_cache[0], node_mask=node_mask) out = tuple_index(out, node_mask) # subset out to only node i and its repeats if j \u0026lt; len(self.decoder_layers)-1: h_V_cache[j+1][0][i::num_nodes] = out[0] h_V_cache[j+1][1][i::num_nodes] = out[1] lgts = self.W_out(out) # Add logit bias if provided to fix or bias positions if logit_bias is not None: lgts += logit_bias[i] # Sample from logits seq[i::num_nodes] = Categorical(logits=lgts / temperature).sample() h_S[i::num_nodes] = self.W_s(seq[i::num_nodes]) logits[i::num_nodes] = lgts if return_logits: return seq.view(n_samples, num_nodes), logits.view(n_samples, num_nodes, self.out_dim) else: return seq.view(n_samples, num_nodes) def pool_multi_conf(self, h_V, h_E, mask_confs, edge_index): if mask_confs.size(1) == 1: # Number of conformations is 1, no need to pool return (h_V[0][:, 0], h_V[1][:, 0]), (h_E[0][:, 0], h_E[1][:, 0]) # True num_conf for masked mean pooling n_conf_true = mask_confs.sum(1, keepdim=True) # (n_nodes, 1) # Mask scalar features mask = mask_confs.unsqueeze(2) # (n_nodes, n_conf, 1) h_V0 = h_V[0] * mask h_E0 = h_E[0] * mask[edge_index[0]] # Mask vector features mask = mask.unsqueeze(3) # (n_nodes, n_conf, 1, 1) h_V1 = h_V[1] * mask h_E1 = h_E[1] * mask[edge_index[0]] # Average pooling multi-conformation features h_V = (h_V0.sum(dim=1) / n_conf_true, # (n_nodes, d_s) h_V1.sum(dim=1) / n_conf_true.unsqueeze(2)) # (n_nodes, d_v, 3) h_E = (h_E0.sum(dim=1) / n_conf_true[edge_index[0]], # (n_edges, d_se) h_E1.sum(dim=1) / n_conf_true[edge_index[0]].unsqueeze(2)) # (n_edges, d_ve, 3) return h_V, h_E class NonAutoregressiveMultiGNNv1(torch.nn.Module): \u0026#39;\u0026#39;\u0026#39; Non-Autoregressive GVP-GNN for **multiple** structure-conditioned RNA design. Takes in RNA structure graphs of type `torch_geometric.data.Data` or `torch_geometric.data.Batch` and returns a categorical distribution over 4 bases at each position in a `torch.Tensor` of shape [n_nodes, 4]. The standard forward pass requires sequence information as input and should be used for training or evaluating likelihood. For sampling or design, use `self.sample`. Args: node_in_dim (tuple): node dimensions in input graph node_h_dim (tuple): node dimensions to use in GVP-GNN layers node_in_dim (tuple): edge dimensions in input graph edge_h_dim (tuple): edge dimensions to embed in GVP-GNN layers num_layers (int): number of GVP-GNN layers in encoder/decoder drop_rate (float): rate to use in all dropout layers out_dim (int): output dimension (4 bases) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_in_dim = (64, 4), node_h_dim = (128, 16), edge_in_dim = (32, 1), edge_h_dim = (32, 1), num_layers = 3, drop_rate = 0.1, out_dim = 4, ): super().__init__() self.node_in_dim = node_in_dim self.node_h_dim = node_h_dim self.edge_in_dim = edge_in_dim self.edge_h_dim = edge_h_dim self.num_layers = num_layers self.out_dim = out_dim activations = (F.silu, None) # Node input embedding self.W_v = torch.nn.Sequential( LayerNorm(self.node_in_dim), GVP(self.node_in_dim, self.node_h_dim, activations=(None, None), vector_gate=True) ) # Edge input embedding self.W_e = torch.nn.Sequential( LayerNorm(self.edge_in_dim), GVP(self.edge_in_dim, self.edge_h_dim, activations=(None, None), vector_gate=True) ) # Encoder layers (supports multiple conformations) self.encoder_layers = nn.ModuleList( MultiGVPConvLayer(self.node_h_dim, self.edge_h_dim, activations=activations, vector_gate=True, drop_rate=drop_rate, norm_first=True) for _ in range(num_layers)) # Output self.W_out = torch.nn.Sequential( LayerNorm(self.node_h_dim), GVP(self.node_h_dim, self.node_h_dim, activations=(None, None), vector_gate=True), GVP(self.node_h_dim, (self.out_dim, 0), activations=(None, None)) ) def forward(self, batch): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features: # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) # h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) h_V = (h_V[0].mean(dim=1), h_V[1].mean(dim=1)) logits = self.W_out(h_V) # (n_nodes, out_dim) return logits def sample(self, batch, n_samples, temperature=0.1, return_logits=False): with torch.no_grad(): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features # h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) h_V = (h_V[0].mean(dim=1), h_V[1].mean(dim=1)) logits = self.W_out(h_V) # (n_nodes, out_dim) probs = F.softmax(logits / temperature, dim=-1) seq = torch.multinomial(probs, n_samples, replacement=True) # (n_nodes, n_samples) if return_logits: return seq.permute(1, 0).contiguous(), logits.unsqueeze(0).repeat(n_samples, 1, 1) else: return seq.permute(1, 0).contiguous() def pool_multi_conf(self, h_V, h_E, mask_confs, edge_index): if mask_confs.size(1) == 1: # Number of conformations is 1, no need to pool return (h_V[0][:, 0], h_V[1][:, 0]), (h_E[0][:, 0], h_E[1][:, 0]) # True num_conf for masked mean pooling n_conf_true = mask_confs.sum(1, keepdim=True) # (n_nodes, 1) # Mask scalar features mask = mask_confs.unsqueeze(2) # (n_nodes, n_conf, 1) h_V0 = h_V[0] * mask h_E0 = h_E[0] * mask[edge_index[0]] # Mask vector features mask = mask.unsqueeze(3) # (n_nodes, n_conf, 1, 1) h_V1 = h_V[1] * mask h_E1 = h_E[1] * mask[edge_index[0]] # Average pooling multi-conformation features h_V = (h_V0.sum(dim=1) / n_conf_true, # (n_nodes, d_s) h_V1.sum(dim=1) / n_conf_true.unsqueeze(2)) # (n_nodes, d_v, 3) h_E = (h_E0.sum(dim=1) / n_conf_true[edge_index[0]], # (n_edges, d_se) h_E1.sum(dim=1) / n_conf_true[edge_index[0]].unsqueeze(2)) # (n_edges, d_ve, 3) return h_V, h_E 经过实验与对比，起初的问题是，当epoch = 1的时候，模型简直非常差：\n很差的效果 但是当epoch提升到50，肉眼可见的好多了，和作者训练的模型几乎一致，因此代码是没问题的：\nepoch=50的效果 然而在我训练后发现我加了attention的模型与不加一模一样，后来发现，我在nonaggressive里面加的，而模型默认没选择这个。\n效果几乎一模一样，很奇怪 在之后，我重新修改了multiheadattention代码，训练好模型后如下，进行预测\n我的模型 使用情况正常 我随机抽取了500个datapoint后进行测试，保持全部的一致，控制变量，结果如图：\n实际情况看来，貌似有效果但不大 因此我在考虑multi-scale attention的想法，根据论文Atlas: Multi-Scale Attention Improves Long Context Image Modeling的思路与AI的协助（实际上压力ai了），现在模型是如下这样，训练之后在进行测试。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 ################################################################ # Generalisation of Geometric Vector Perceptron, Jing et al. # for explicit multi-state biomolecule representation learning. # Original repository: https://github.com/drorlab/gvp-pytorch ################################################################ from typing import Optional import torch from torch import nn import torch.nn.functional as F from torch.distributions import Categorical import torch_geometric from src.layers import * class MultiScaleAttention(nn.Module): \u0026#39;\u0026#39;\u0026#39; Multi-scale attention module to capture dependencies at different window sizes. \u0026#39;\u0026#39;\u0026#39; def __init__( self, embed_dim: int, num_heads: int = 8, window_sizes: list = [10, 50, 200, None], # None for global scale dropout: float = 0.1 ): super().__init__() self.window_sizes = window_sizes self.attentions = nn.ModuleList([ nn.MultiheadAttention( embed_dim=embed_dim, num_heads=num_heads, dropout=dropout, batch_first=True ) for _ in window_sizes ]) def forward(self, x, mask=None): # x: (batch_size, seq_len, embed_dim) outputs = [] seq_len = x.size(1) for idx, (attn, window_size) in enumerate(zip(self.attentions, self.window_sizes)): if window_size is None: # Global attention attn_output, _ = attn(x, x, x, attn_mask=mask) else: # Local window attention: create sliding window mask or approximate # For simplicity, we can use full attention but in practice, implement windowing # Here, as a placeholder, apply full attention per scale (can be optimized with sparse masks) attn_output, _ = attn(x, x, x, attn_mask=mask) outputs.append(attn_output) # Fuse outputs: average across scales fused_output = torch.mean(torch.stack(outputs), dim=0) return fused_output class AutoregressiveMultiGNNv1(torch.nn.Module): \u0026#39;\u0026#39;\u0026#39; Autoregressive GVP-GNN for **multiple** structure-conditioned RNA design. Takes in RNA structure graphs of type `torch_geometric.data.Data` or `torch_geometric.data.Batch` and returns a categorical distribution over 4 bases at each position in a `torch.Tensor` of shape [n_nodes, 4]. The standard forward pass requires sequence information as input and should be used for training or evaluating likelihood. For sampling or design, use `self.sample`. Args: node_in_dim (tuple): node dimensions in input graph node_h_dim (tuple): node dimensions to use in GVP-GNN layers node_in_dim (tuple): edge dimensions in input graph edge_h_dim (tuple): edge dimensions to embed in GVP-GNN layers num_layers (int): number of GVP-GNN layers in encoder/decoder drop_rate (float): rate to use in all dropout layers out_dim (int): output dimension (4 bases) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_in_dim = (64, 4), node_h_dim = (128, 16), edge_in_dim = (32, 1), edge_h_dim = (32, 1), num_layers = 3, drop_rate = 0.1, out_dim = 4, num_attention_heads = 8, attention_window_sizes = [10, 50, 200, None], # Multi-scale windows ): super().__init__() self.node_in_dim = node_in_dim self.node_h_dim = node_h_dim self.edge_in_dim = edge_in_dim self.edge_h_dim = edge_h_dim self.num_layers = num_layers self.out_dim = out_dim activations = (F.silu, None) # Node input embedding self.W_v = torch.nn.Sequential( LayerNorm(self.node_in_dim), GVP(self.node_in_dim, self.node_h_dim, activations=(None, None), vector_gate=True) ) # Edge input embedding self.W_e = torch.nn.Sequential( LayerNorm(self.edge_in_dim), GVP(self.edge_in_dim, self.edge_h_dim, activations=(None, None), vector_gate=True) ) # Encoder layers (supports multiple conformations) self.encoder_layers = nn.ModuleList( MultiGVPConvLayer(self.node_h_dim, self.edge_h_dim, activations=activations, vector_gate=True, drop_rate=drop_rate, norm_first=True) for _ in range(num_layers)) # Multi-scale attention for capturing long-distance dependencies at different scales self.multi_scale_attention = MultiScaleAttention( embed_dim=self.node_h_dim[0], # Scalar dimension num_heads=num_attention_heads, window_sizes=attention_window_sizes, dropout=drop_rate ) # Decoder layers self.W_s = nn.Embedding(self.out_dim, self.out_dim) self.edge_h_dim = (self.edge_h_dim[0] + self.out_dim, self.edge_h_dim[1]) self.decoder_layers = nn.ModuleList( GVPConvLayer(self.node_h_dim, self.edge_h_dim, activations=activations, vector_gate=True, drop_rate=drop_rate, autoregressive=True, norm_first=True) for _ in range(num_layers)) # Output self.W_out = GVP(self.node_h_dim, (self.out_dim, 0), activations=(None, None)) def forward(self, batch): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index seq = batch.seq h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features: # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) # Apply multi-scale attention on pooled scalar features h_V_s = h_V[0].unsqueeze(0) # (1, n_nodes, d_s) attn_output = self.multi_scale_attention(h_V_s) h_V = (attn_output.squeeze(0) + h_V[0], h_V[1]) # Residual connection encoder_embeddings = h_V h_S = self.W_s(seq) h_S = h_S[edge_index[0]] h_S[edge_index[0] \u0026gt;= edge_index[1]] = 0 h_E = (torch.cat([h_E[0], h_S], dim=-1), h_E[1]) for layer in self.decoder_layers: h_V = layer(h_V, edge_index, h_E, autoregressive_x = encoder_embeddings) logits = self.W_out(h_V) return logits @torch.no_grad() def sample( self, batch, n_samples, temperature: Optional[float] = 0.1, logit_bias: Optional[torch.Tensor] = None, return_logits: Optional[bool] = False ): \u0026#39;\u0026#39;\u0026#39; Samples sequences autoregressively from the distribution learned by the model. Args: batch (torch_geometric.data.Data): mini-batch containing one RNA backbone to design sequences for n_samples (int): number of samples temperature (float): temperature to use in softmax over the categorical distribution logit_bias (torch.Tensor): bias to add to logits during sampling to manually fix or control nucleotides in designed sequences, of shape [n_nodes, 4] return_logits (bool): whether to return logits or not Returns: seq (torch.Tensor): int tensor of shape [n_samples, n_nodes] based on the residue-to-int mapping of the original training data logits (torch.Tensor): logits of shape [n_samples, n_nodes, 4] (only if return_logits is True) \u0026#39;\u0026#39;\u0026#39; h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index device = edge_index.device num_nodes = h_V[0].shape[0] h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) # Apply multi-scale attention on pooled scalar features h_V_s = h_V[0].unsqueeze(0) # (1, n_nodes, d_s) attn_output = self.multi_scale_attention(h_V_s) h_V = (attn_output.squeeze(0) + h_V[0], h_V[1]) # Residual connection # Repeat features for sampling n_samples times h_V = (h_V[0].repeat(n_samples, 1), h_V[1].repeat(n_samples, 1, 1)) h_E = (h_E[0].repeat(n_samples, 1), h_E[1].repeat(n_samples, 1, 1)) # Expand edge index for autoregressive decoding edge_index = edge_index.expand(n_samples, -1, -1) offset = num_nodes * torch.arange(n_samples, device=device).view(-1, 1, 1) edge_index = torch.cat(tuple(edge_index + offset), dim=-1) # This is akin to \u0026#39;batching\u0026#39; (in PyG style) n_samples copies of the graph seq = torch.zeros(n_samples * num_nodes, device=device, dtype=torch.int) h_S = torch.zeros(n_samples * num_nodes, self.out_dim, device=device) logits = torch.zeros(n_samples * num_nodes, self.out_dim, device=device) h_V_cache = [(h_V[0].clone(), h_V[1].clone()) for _ in self.decoder_layers] # Decode one token at a time for i in range(num_nodes): h_S_ = h_S[edge_index[0]] h_S_[edge_index[0] \u0026gt;= edge_index[1]] = 0 h_E_ = (torch.cat([h_E[0], h_S_], dim=-1), h_E[1]) edge_mask = edge_index[1] % num_nodes == i # True for all edges where dst is node i edge_index_ = edge_index[:, edge_mask] # subset all incoming edges to node i h_E_ = tuple_index(h_E_, edge_mask) node_mask = torch.zeros(n_samples * num_nodes, device=device, dtype=torch.bool) node_mask[i::num_nodes] = True # True for all nodes i and its repeats for j, layer in enumerate(self.decoder_layers): out = layer(h_V_cache[j], edge_index_, h_E_, autoregressive_x=h_V_cache[0], node_mask=node_mask) out = tuple_index(out, node_mask) # subset out to only node i and its repeats if j \u0026lt; len(self.decoder_layers)-1: h_V_cache[j+1][0][i::num_nodes] = out[0] h_V_cache[j+1][1][i::num_nodes] = out[1] lgts = self.W_out(out) # Add logit bias if provided to fix or bias positions if logit_bias is not None: lgts += logit_bias[i] # Sample from logits seq[i::num_nodes] = Categorical(logits=lgts / temperature).sample() h_S[i::num_nodes] = self.W_s(seq[i::num_nodes]) logits[i::num_nodes] = lgts if return_logits: return seq.view(n_samples, num_nodes), logits.view(n_samples, num_nodes, self.out_dim) else: return seq.view(n_samples, num_nodes) def pool_multi_conf(self, h_V, h_E, mask_confs, edge_index): if mask_confs.size(1) == 1: # Number of conformations is 1, no need to pool return (h_V[0][:, 0], h_V[1][:, 0]), (h_E[0][:, 0], h_E[1][:, 0]) # True num_conf for masked mean pooling n_conf_true = mask_confs.sum(1, keepdim=True) # (n_nodes, 1) # Mask scalar features mask = mask_confs.unsqueeze(2) # (n_nodes, n_conf, 1) h_V0 = h_V[0] * mask h_E0 = h_E[0] * mask[edge_index[0]] # Mask vector features mask = mask.unsqueeze(3) # (n_nodes, n_conf, 1, 1) h_V1 = h_V[1] * mask h_E1 = h_E[1] * mask[edge_index[0]] # Average pooling multi-conformation features h_V = (h_V0.sum(dim=1) / n_conf_true, # (n_nodes, d_s) h_V1.sum(dim=1) / n_conf_true.unsqueeze(2)) # (n_nodes, d_v, 3) h_E = (h_E0.sum(dim=1) / n_conf_true[edge_index[0]], # (n_edges, d_se) h_E1.sum(dim=1) / n_conf_true[edge_index[0]].unsqueeze(2)) # (n_edges, d_ve, 3) return h_V, h_E class NonAutoregressiveMultiGNNv1(torch.nn.Module): \u0026#39;\u0026#39;\u0026#39; Non-Autoregressive GVP-GNN for **multiple** structure-conditioned RNA design. Takes in RNA structure graphs of type `torch_geometric.data.Data` or `torch_geometric.data.Batch` and returns a categorical distribution over 4 bases at each position in a `torch.Tensor` of shape [n_nodes, 4]. The standard forward pass requires sequence information as input and should be used for training or evaluating likelihood. For sampling or design, use `self.sample`. Args: node_in_dim (tuple): node dimensions in input graph node_h_dim (tuple): node dimensions to use in GVP-GNN layers node_in_dim (tuple): edge dimensions in input graph edge_h_dim (tuple): edge dimensions to embed in GVP-GNN layers num_layers (int): number of GVP-GNN layers in encoder/decoder drop_rate (float): rate to use in all dropout layers out_dim (int): output dimension (4 bases) \u0026#39;\u0026#39;\u0026#39; def __init__( self, node_in_dim = (64, 4), node_h_dim = (128, 16), edge_in_dim = (32, 1), edge_h_dim = (32, 1), num_layers = 3, drop_rate = 0.1, out_dim = 4, ): super().__init__() self.node_in_dim = node_in_dim self.node_h_dim = node_h_dim self.edge_in_dim = edge_in_dim self.edge_h_dim = edge_h_dim self.num_layers = num_layers self.out_dim = out_dim activations = (F.silu, None) # Node input embedding self.W_v = torch.nn.Sequential( LayerNorm(self.node_in_dim), GVP(self.node_in_dim, self.node_h_dim, activations=(None, None), vector_gate=True) ) # Edge input embedding self.W_e = torch.nn.Sequential( LayerNorm(self.edge_in_dim), GVP(self.edge_in_dim, self.edge_h_dim, activations=(None, None), vector_gate=True) ) # Encoder layers (supports multiple conformations) self.encoder_layers = nn.ModuleList( MultiGVPConvLayer(self.node_h_dim, self.edge_h_dim, activations=activations, vector_gate=True, drop_rate=drop_rate, norm_first=True) for _ in range(num_layers)) # Output self.W_out = torch.nn.Sequential( LayerNorm(self.node_h_dim), GVP(self.node_h_dim, self.node_h_dim, activations=(None, None), vector_gate=True), GVP(self.node_h_dim, (self.out_dim, 0), activations=(None, None)) ) def forward(self, batch): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features: # nodes: (n_nodes, d_s), (n_nodes, d_v, 3) # edges: (n_edges, d_se), (n_edges, d_ve, 3) # h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) h_V = (h_V[0].mean(dim=1), h_V[1].mean(dim=1)) logits = self.W_out(h_V) # (n_nodes, out_dim) return logits def sample(self, batch, n_samples, temperature=0.1, return_logits=False): with torch.no_grad(): h_V = (batch.node_s, batch.node_v) h_E = (batch.edge_s, batch.edge_v) edge_index = batch.edge_index h_V = self.W_v(h_V) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) h_E = self.W_e(h_E) # (n_edges, n_conf, d_se), (n_edges, n_conf, d_ve, 3) for layer in self.encoder_layers: h_V = layer(h_V, edge_index, h_E) # (n_nodes, n_conf, d_s), (n_nodes, n_conf, d_v, 3) # Pool multi-conformation features # h_V, h_E = self.pool_multi_conf(h_V, h_E, batch.mask_confs, edge_index) h_V = (h_V[0].mean(dim=1), h_V[1].mean(dim=1)) logits = self.W_out(h_V) # (n_nodes, out_dim) probs = F.softmax(logits / temperature, dim=-1) seq = torch.multinomial(probs, n_samples, replacement=True) # (n_nodes, n_samples) if return_logits: return seq.permute(1, 0).contiguous(), logits.unsqueeze(0).repeat(n_samples, 1, 1) else: return seq.permute(1, 0).contiguous() def pool_multi_conf(self, h_V, h_E, mask_confs, edge_index): if mask_confs.size(1) == 1: # Number of conformations is 1, no need to pool return (h_V[0][:, 0], h_V[1][:, 0]), (h_E[0][:, 0], h_E[1][:, 0]) # True num_conf for masked mean pooling n_conf_true = mask_confs.sum(1, keepdim=True) # (n_nodes, 1) # Mask scalar features mask = mask_confs.unsqueeze(2) # (n_nodes, n_conf, 1) h_V0 = h_V[0] * mask h_E0 = h_E[0] * mask[edge_index[0]] # Mask vector features mask = mask.unsqueeze(3) # (n_nodes, n_conf, 1, 1) h_V1 = h_V[1] * mask h_E1 = h_E[1] * mask[edge_index[0]] # Average pooling multi-conformation features h_V = (h_V0.sum(dim=1) / n_conf_true, # (n_nodes, d_s) h_V1.sum(dim=1) / n_conf_true.unsqueeze(2)) # (n_nodes, d_v, 3) h_E = (h_E0.sum(dim=1) / n_conf_true[edge_index[0]], # (n_edges, d_se) h_E1.sum(dim=1) / n_conf_true[edge_index[0]].unsqueeze(2)) # (n_edges, d_ve, 3) return h_V, h_E 根据新的模型训练后进行测试比对，\nMulti-Scale Attention 看起来有点作用不是吗？\n测试Multi-scale在数据集的效果 在同样500条数据集测试，grnade模型的数据如下：\nLength Range Statistic Perplexity Recovery Edit Distance SC Score Sample Count 0-100 Median 1.4128 0.56445 17.5972 0.62315 234 100-200 Median 1.26885 0.73585 30.2634 0.61495 72 200+ Median 1.3132 0.64605 226.875 0.42835 138 0-100 Mean 1.47854274 0.569795726 18.55480427 0.634651282 234 100-200 Mean 1.34514583 0.685369444 37.49759306 0.569984722 72 200+ Mean 1.41243696 0.639286232 211.1403986 0.421031884 138 而加了multiheadattention后数据如表格：\nLength Range Statistic Perplexity Recovery Edit Distance SC Score Sample Count 0-100 Median 1.30675 0.5532 17.21875 0.62105 234 100-200 Median 1.17275 0.7444 29.75 0.62205 72 200+ Median 1.30785 0.70485 183.84375 0.41915 140 0-100 Mean 1.36121325 0.572758974 18.34507564 0.638930342 234 100-200 Mean 1.24458056 0.704726389 35.62898472 0.605529167 72 200+ Mean 1.36845071 0.685876429 180.6455357 0.430865714 140 之后用的多层注意力Multiscale attention如下：\nLength Range Statistic Perplexity Recovery Edit Distance SC Score Sample Count 0-100 Median 1.3358 0.5592 17.6667 0.6396 235 100-200 Median 1.2226 0.71205 33.78125 0.6771 72 200+ Median 1.32545 0.68665 193.0625 0.42465 140 0-100 Mean 1.36930766 0.557402979 18.98926 0.660275319 235 100-200 Mean 1.28780417 0.682672222 37.93399306 0.624776389 72 200+ Mean 1.40186786 0.673555 187.8361607 0.434380714 140 在多数据测试之后，我做可视化对比，我们主要比较SCC，Recovery。\n加了注意力的两个模型实际在表现上都比原版好，现在就要取舍了 最终我认为SCC指标更重要，因而在12000条数据对multiscale和grnade进行测试，得到二者lgx为坐标的图像对比：\n是有细微差别的，毕竟grnade已经算sota了，优化起来费劲 经过对比，在中长序列显著提高了SCC，同时平均Recovery差别不大 但是数据泄露的问题来了 作者有13000+数据（2023年RNAsolo），能用的大概12000+，其中train split有12000+，而500+个validation set，200+在test set。\n什么概念？12000：500：200，比8：1：1差远了；这还没完，更离谱的是这200条数据集甚至长度都没超过200的，这让我测试个啥？\n0-160的长度范围 当然，实验不能白做，我在这个test set上面还是测试了一下两个模型，看起来我们的方法在长序列情况下还是占优势：\n其实不小心把图例打错了，不过问题不大 痛定思痛：如何优化split方法？ 作者把小于10nt、大于1000nt的全丢进去训练集了；再加上划分的不合理，我的想法是，要不先按照0-100，100-200，200+的length range把cluster进行划分？然后在各自范围用8：1：1的方式来筛选cluster，最后把cluster含有的pdb索引拿出来，这样会好一些。\n但是这就产生了疑惑：\n**为啥不是8:1:1直接划分不同长度的呢？**其实我也不清楚，我和gemini讨论之后发现，作者划分cluster是按照rna家族的相似性进行划分的，如果直接划分的话容易把同一个cluster的rna划分到一半训练集一半测试集，由于本身结构相似，就又数据泄露了(不是，怎么老是泄露啊哥们，你以为你是至善园的管道吗)。\n先按照这个想法试试，之后我得到：\ntrain split的分布，大概12000条 validation split的分布，大概450条其实也还好 test split的分布，大概660条 这样子看起来就好多了。如今2025年，我之前捣鼓下载了最新的数据集（15000+条诶！），然后导师说用23年的。但是不能白下载对不对嘿嘿，那就用25年比23年多出的这部分加入到测试集！刚好评估一下模型对未知rna的预测水平。\n多了快3000条诶 除此之外，既然是评估长rna的预测水平，原先模型好像把1000+nt的rna全丢训练集了，之后看看咋改动一下。\n敬请期待下一条更新。\n","date":"2025-09-04T15:36:23+08:00","permalink":"https://mosfish.github.io/p/how-about-rna-inverse-folding-first-attempt./","title":"How about RNA inverse folding? First attempt."},{"content":"Free5GC核心网部署与接入测试手册 写在开篇： 建议养成备份（例如git工具）的好习惯。本文包含Linux开发基础内容、free5gc核心网\n考虑到版权问题，本文章如需要转载请进行声明。\n起初使用VMware虚拟机装的Ubuntu桌面版系统，但是实际工程需要板载Linux系统（但是学习初期直接上手，容易因为不熟悉操作而出现诸如网卡连不了网，没声音，拼音输入法等软硬件不适配类似的各种问题）可以先基于虚拟机进行学习，入门后再基于板载Linux系统开发核心网。\n5G核心网介绍 参考 【5G】5G 核心网（5GC）基本架构_5g核心网架构-CSDN博客\n核心网具体结构 5G 核心网是支持 5G 移动通信的核心基础设施，在 5G 通信中负责实现数据处理、控制、管理、路由和连接等功能。5G 核心网的架构采用了基于服务的设计 (Service-based Architecture, SBA)，支持网络切片、NFV、软件定义网络 (Software-Defined Networking, SDN) 等先进技术，提供更高的灵活性和可扩展性。\n5G网络架构与接口 5G核心网网元功能 AMF (Access and Mobility Management Function) 接入与移动性管理功能，主要负责：\n接入控制、用户移动性管理 会话管理和用户身份管理 处理UE与网络的接入请求 管理用户接入状态及移动性支持 SMF (Session Management Function)\n会话管理功能，负责：\n会话的建立、修改和释放 数据流管理（路由、QoS保证、IP分配） UPF (User Plane Function) 用户面功能，负责：\n转发用户数据流 与SMF协作管理数据路径、路由和转发 NSSF (Network Slice Selection Function) 网络切片选择功能，负责：\n根据业务需求动态选择网络切片 管理不同业务场景的切片资源 PCF (Policy Control Function) 策略控制功能，负责：\n制定网络策略（QoS、计费、流量管理、安全性） 为AMF/SMF/UPF提供策略决策服务 UDM (Unified Data Management) 统一数据管理功能，负责：\n存储用户订阅信息（SUPI）、服务配置、认证信息 与AUSF/AMF等网元协作提供数据服务 5G网络组成 架构组成：5GC（核心网） + RAN（无线接入网） + UE（用户设备） 核心网功能：服务管理、数据传输、安全性 RAN功能：无线连接、数据传输与控制信号传递 UE角色：用户交互终端，通过RAN与核心网通信 无线接入网与核心网接口 主要接口及功能：\nN1接口\n连接：UE ↔ AMF 功能：信令传递（UE接入管理、认证） N2接口\n连接：AMF ↔ SMF 功能：会话管理协作（处理用户会话任务） N3接口\n连接：无线接入网 ↔ UPF 功能：用户数据传输（数据面主要路径） N4接口\n连接：SMF ↔ UPF 功能：用户数据路径选择与管理（SMF控制UPF流量） N6接口\n连接：UPF ↔ 数据网络（DN） 功能：用户数据外发至互联网/外部网络 linux开发基本配置与指令 一、常用指令 1.基本指令部分 复制 Ctrl+Shift+C\n粘贴 Ctrl+Shift+V\n更新包列表\n1 sudo apt update 查网卡ip\n1 2 Ifconfig # 记得提前安装ifconfig网络工具 sudo apt install net-tools 或者\n1 ip a 显示当前路径\n1 pwd 进入文件夹\n1 2 3 cd \u0026lt;文件夹名\u0026gt; # 例如 cd free5gc-compose # 或者进入多个内嵌文件夹如 cd ~/free5gc-compose/config 查询网站ip地址\n1 nslookup baidu.com 查各网元运行情况、地址\n1 2 docker-compose ps 或看全部网元： docker ps -a 停止容器网元运行\n1 docker-compose down 启动容器网元并后台挂机\n1 docker-compose up -d 查看运行日志（以amf为例，可换成smf、upf等）\n1 docker logs \u0026lt;id\u0026gt; 例如：docker logs amf\n查找单个网元信息（例如amf）\n1 docker inspect amf 进入容器进行交互\n1 docker exec -it \u0026lt;容器ID或容器名(如amf)\u0026gt; sh 或者docker exec -it \u0026lt;容器ID或容器名(如amf)\u0026gt; bash\n按照格式查找所有网元的ip地址（没有启动或者出错就不显示）\n1 docker inspect -f \u0026#39;{{.Name}} - {{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}\u0026#39; $(docker ps -aq) 查询所有网元mac地址\n1 docker inspect -f \u0026#39;{{.Name}} - {{range .NetworkSettings.Networks}}{{.MacAddress}}{{end}}\u0026#39; $(docker ps -aq) 我的地址（每个人的都不同，根据实际情况可以修改）： /home/wxy/free5gc-compose/config/amfcfg.yaml\n查看端口情况\n1 etstat -tuln | grep 38412 看防火墙设置\n1 sudo iptables -L 看网桥\n1 brctl show 查看网桥连接的ip地址\n1 brctl showmacs \u0026lt;网桥名\u0026gt; 看路由\n1 ip route show 添加网桥\n1 sudo brctl addif \u0026lt;bridge\u0026gt; \u0026lt;网卡名\u0026gt; Linux启动wireshark抓包——需要安装linux的wireshark然后启动：\tsudo wireshark\n2.网络空间测试 一般是用docker inspect amf或者docker logs amf来对amf、smf、upf之类的进行测试，\n也可以进入网络空间进行进一步测试例如：\n1 docker exec -it upf bash 不过最好是利用pid方法进入网络空间进行ifconfig或者ping操作\n1 2 3 ps aux | grep upf #获取进程（可以得到各种进程id） pgrep -f upf #获取pid： sudo nsenter -t \u0026lt;pid\u0026gt; -n #进入网络空间 其余指令还有kill之类的可以终止进程。\n除此之外有的时候ping网站可能会遇到name resolution的报错，可以换成ip地址，指令如下，以百度为例：\n1 nslookup baidu.com 不过ping命令有的时候会被网页阻拦，用curl命令比较合适，例如：\n1 curl www.baidu.com 3.启动环境部分 启动核心网和ueransim环境分以下三步，根据实际情况可以更改代码：\n启动核心网环境\n1 2 cd ~/free5gc-compose sudo docker-compose up -d 启动UERANSIM的gnb\n1 2 cd ~/UERANSIM/build ./nr-gnb -c ../config/free5gc-gnb.yaml 启动ue\n1 2 cd ~/UERANSIM/build sudo ./nr-ue -c ../config/free5gc-ue.yaml 虚拟网卡测试方法\n1 2 ping www.baidu.com -I uesimtun0 # 或者 curl www.baidu.com -I uesimtun0 二、虚拟机Linux设置vpn方法 途径1.主机共享vpn 参考：VMware Ubuntu虚拟机 使用主机VPN 配置（简单、可行）-CSDN博客\n（图片资源没保存，所以只有文字了）\n一定要记得开篇说的资源备份啊呜呜呜 打开虚拟网络编辑器，可以看到虚拟机开启的NAT模式是VMnet8。\n主机windows+R输入cmd打开命令行输入ipconfig ，得到VMnet8的ip：192.168.154.1。之后查询vpn端口，以clash为例，右上角记下vpn的端口，之后允许局域网记得打开。\n在虚拟机的设置中打开proxy代理，选择manual，\n虚拟机网络地址与VPN Port需要根据本机确定，左边四个填VMnet4的ip，右边四个填vpn的端口即可。\n问题1：如果我的vpn没有用clash，不知道vpn端口怎么办？ 参考：在windows中如何查看代理的地址和端口_怎么查看自己电脑的代理地址-CSDN博客\nWindows+R输入control打开主机的控制面板，点击「网络和Internet」，\n在「internet选项」中点击「连接」的「局域网设置」\n启用代理服务器，不用打勾，保持默认就行，右下角端口即为vpn端口。\n问题2：为什么我的vpn它通不了外网？ 一般而言，如果浏览器可以打开谷歌就证明梯子没问题。那么问题就出在——实际命令行终端走代理需要进一步配置端口\n已知代理端口（例如7890），之后就set一下http、https两个协议走这个端口，类似于\n1 set http_proxy=http://127.0.0.1:7890 \u0026amp; set https_proxy=http://127.0.0.1:7890 但是具体还是得看具体的设备，这种事情可以问一下ai。\n途径2.linux里下载Clash csdn里有相关内容，请自行搜索，配置起来较麻烦，\nLinux下Clash翻墙完整使用指南 | Clash中文教程网。\n这个教程写的不是很清楚，可以拓展一下。\n三、主机与虚拟机共享剪贴板 参考：主机和VMware虚拟机间共享剪贴板方法_vmware workstation 中启用了剪贴板共享功能-CSDN博客\n为啥主机复制过去虚拟机粘贴不了？有的时候可以复制粘贴有的时候不能？一般来说，先设置虚拟机，需要保证客户机隔离里面是启用复制粘贴的（默认启用）\n如果这个时候还不行，可以需要安装虚拟机增强工具包open-vm-tools和open-vm-tools-desktop，安装命令：\n1 2 sudo apt-get install open-vm-tools sudo apt-get install open-vm-tools-desktop 然后重启系统：\n1 sudo reboot 四、虚拟机关机与挂起 虚拟机关机就是不再占用资源，但是再次开启需要重启；挂起就是虚拟机保存挂起的状态，打开不需要重启。\n最重要的事情是记得自己虚拟机的路径.\n问题1：关机后找不到虚拟机咋办 点击扫描虚拟机，找到.vmx文件打开就行。\n五、虚拟机分盘扩容操作 有的时候给虚拟机分盘内存太小，当盘快满的时候会弹出警告，一定要提前采取措施来分盘，否则会启动不了虚拟机。\n1 lsblk #检查磁盘情况 1 df -h\t#检查磁盘占用情况 可以看到我主要的盘sda3占用了53%。\n分盘主要是两个操作\n划出内存\n编辑虚拟机设置-硬盘-拓展，然后选择扩展后的硬盘空间\n分配空间\n考虑两种方法可以，有一个是类似于windows的图形化分盘，下载并启动gparted，这个方法在VMware虚拟机扩容磁盘，有很详细图文_虚拟机硬盘空间-CSDN博客有提及。\n1 2 3 sudo apt-get update sudo apt install gparted sudo gparted 在图形界面中可以选择 /dev/sda3 分区，然后调整它的大小。\n或者利用fdisk（推荐），输入命令：\n1 sudo fdisk /dev/sda 再输入p得到分区列表预览：\nfdisk 中执行命令汇总如下\n输入 p 显示当前的分区列表，记下 /dev/sda3 的起始位置（例如 1054720）。\n输入 d 删除 /dev/sda3，并确保输入分区号（3）。注意，这不会删除数据，分区号只是从分区表中移除。\n输入 n 创建新分区，选择 3 为分区号，使用 1054720为起始扇区（与之前一致），并设置结束扇区为新的磁盘容量（可以选择最大可用空间）。\n输入 w 保存更改并退出 fdisk。\n可能遇见这种情况，但是如果默认系统是linux一般用不上：输入 t 设置分区类型，选择 83（Linux 文件系统）。\n问题1：虚拟机退出后再启动会卡在初始页面 类似于这样，进不去虚拟机，一直卡在这个地方：\n因为没注意虚拟机盘满了，卡在初始界面进不去，所以要在盘快满的时候提前分盘。\nVMware卡在命令行/dev/sda3 clean\u0026hellip; 界面不动的解决办法：\n参考https://blog.csdn.net/SunshineLiy/article/details/134372529\n显示分区已满，需要找到这个分区一些没用的文件删掉，先进去虚拟机能分盘再说。\n进入 grub 模式，重启虚拟机，在显示到这个界面的时候\n快速按下 Shift 不要松，直到出现grub界面（这一步需要反应快一些，多试几遍就可以，如果操作正确的话，grub界面很快就会出来，如果按Shift三秒没有出现，大概率是操作错误了。此方法如果进不去，也可以参考网上也有其他进入grub的方法）\n进入ubuntu(高级模式)，选择第一个advanced\n之后选择第二个\n选择root\n选择root后会弹出两行提示，直接回车就可以\n输入以下指令看到磁盘使用情况\n1 df -h sda3确实100%满了，所以我们需要在命令行来清理一些文件。\n查看根目录下所有文件和目录的磁盘使用情况\n1 du -sh /* 找到自己占用空间较多的文件目录\n1 rm -f /文件名/ 删除那些暂时没有用的大文件，reboot 重启。然后赶紧增加空间！！！\n六、Ubuntu桌面相关问题 1.桌面字标大小 调整分辨率和缩放就行。缩放到200%左右比较合适，在setting里面设置。有的时候会有桌面越来越小的bug，在设置里面改就可以。\n2.桌面卡死 输入以下命令重启桌面等一会就行：\n1 sudo restart lightdm 七、虚拟机没网设置网络图标消失 如果只是网络连接处显示问号，可以在终端输入：\n1 sudo vim /var/lib/NetworkManager/NetworkManager.state 保证这里是true。重启虚拟机，检查情况。如果还没有反应可以重启主机，再排查\n参考彻底解决VM ubuntu在虚拟机找不到网卡无法上网的问题 - 知乎\n还是不行在setting里面找network关了重开，而如果第一行开启按钮没有显示的话可能需要用以下方式：\n1 2 3 sudo service NetworkManager stop sudo rm /var/lib/NetworkManager/NetworkManager.state sudo service NetworkManager start 最后的办法是还原默认设置后再看看有没有，没有的话再进行上一步输入命令。\nFree5gc部署、UERANSIM安装 主要参考：Free5gc+UERANSIM模拟5G网络环境搭建及基本使用 - FreeBuf网络安全行业门户\n此处采用docker容器化部署，其他独立化部署可以看教程，根据实际情况同时参考教程和本文档。\n考虑实际情况，建议这里采用镜像源代理的方式，暂且不用vpn\n一、Free5gc部署 准备工作 使用命令：\n1 uname -a 此命令用于确认安装的虚拟机内核版本，要求的内核版本为5.0.0-23-generic或5.4.0及之后的版本,\n若当前虚拟机内核版本不符合要求，则需要更换内核，使用以下命令安装5.0.0-23-generic的内核，注意用sudo是管理员权限的操作，需要输入密码，为了安全，密码一般是不显示的但是可以输入，并不是bug，输入后按回车。\n1 2 sudo apt install \u0026#39;linux-image-5.0.0-23-generic\u0026#39; sudo apt install \u0026#39;linux-headers-5.0.0-23-generic 安装完成后，需要重启虚拟机，并在启动时连按shift键，进入grub引导页，更换启动的Linux内核。\n之后安装基本组件：\n1 2 3 4 5 6 7 8 9 10 sudo apt install git-all sudo apt-get install curl sudo apt install make sudo apt -y install gcc sudo apt -y install g++ sudo apt -y install autoconf sudo apt -y install libtool sudo apt -y install pkg-config sudo apt -y install libmnl-dev sudo apt -y install libyaml-dev 如果人为设置了vpn就不用按照教程里替换源了。之后安装go语言环境，注意安装go语言环境时必须为普通用户安装，否则会导致后续安装出现问题。输入命令：\n1 go 以确认是否存在其他版本的go，若存在，则通过以下命令删除\n1 sudo rm -rf /usr/local/go 之后安装最新版本的go：\n1 2 3 cd ~ wget https://dl.google.com/go/go1.20.4.linux-amd64.tar.gz sudo tar -C /usr/local -zxvf go1.20.4.linux-amd64.tar.gz 安装完成后，需要通过以下命令配置环境变量（此过程按回车不会有输出）\n1 2 3 4 5 mkdir -p ~/go/{bin,pkg,src} echo \u0026#39;export GOPATH=$HOME/go\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;export GOROOT=/usr/local/go\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;export PATH=$PATH:$GOPATH/bin:$GOROOT/bin\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc 之后输入命令：\n1 go #有版本号等输出就行。安装成功，再补充安装以下模块，该模块为free5gc独立部署的日志模块，容器化部署也可以安装：\n1 #go get -u github.com/sirupsen/logrus 通过官方安装脚本安装docker，\n1 curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 安装完成后，运行命令docker \u0026ndash;version验证。之后需要安装docker-compose，通过以下命令完成：\n1 sudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.28.5/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose 重启docker服务即可完成docker的部署：\n1 systemctl restart docker 完成后，需要将当前普通用户加入docker用户组，docker用户组在上述安装时自动创建，无需手动创建：\n1 2 sudo gpasswd -a $USER docker #将当前普通用户加入docker用户组 newgrp docker #更新docker用户组 此步目的在于防止后续free5gc容器化部署时，到make base步骤，出现permission denied。\n更换镜像源 这是很重要的一步，原理是部分镜像源起到类似代理的作用。在网上搜索最新docker镜像源，参考\n国内能用的Docker镜像源【2025最新持续更新】_docker 镜像-CSDN博客\n国内仍然可用docker镜像源汇总，长期维护，定期更新（2025年3月21日）_docker 国内镜像源-CSDN博客\nDocker换源加速(更换镜像源)详细教程（2025.3最新可用镜像，全网最详细） - 知乎\n然后输入类似于\n1 sudo nano /etc/docker/daemon.json 来创造或修改配置文件，在里面写入代理网站，但是下面这个是一开始的，现在被ban掉了好多，不推荐，\n1 2 3 4 5 6 7 8 { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://hub-mirror.c.163.com\u0026#34;, \u0026#34;https://mirror.baidubce.com\u0026#34;, \u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;, \u0026#34;https://mirror.ccs.tencentyun.com\u0026#34; ] } 推荐这些，或者去我给的参考链接找最新存活的：\n1 2 3 4 5 6 7 8 9 10 11 { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://docker-0.unsee.tech\u0026#34;, \u0026#34;https://docker-cf.registry.cyou\u0026#34;, \u0026#34;https://docker.1panel.live\u0026#34;, \u0026#34;https://docker.xuanyuan.me\u0026#34;, \u0026#34;https://1ms.run\u0026#34;, \u0026#34;https://hub.fast360.xyz\u0026#34;, \u0026#34;https://hub.littlediary.cn\u0026#34; ] } 然后保存离开，输入以下命令清除缓存、重启docker\n1 2 sudo systemctl daemon-reload sudo systemctl restart docker 然后可以查看docker源是否更改：\n1 docker info | grep -A 1 \u0026#34;Registry Mirrors\u0026#34; 最后可以尝试验证：\n1 docker pull hello-world 拉取成功即可以。\n继续安装其他组件 安装cmake：\n1 sudo snap install cmake –classic 安装mongodb\n1 2 3 sudo apt -y update sudo apt -y install mongodb wget git sudo systemctl start mongodb 此时可能会报错Package 'mongodb' has no installation candidate，有可能因为ubuntu没更新找不到安装包，可以试试导入mongodb的公钥，运行以下命令：\n1 wget -qO - https://www.mongodb.org/static/pgp/server-6.0.asc | sudo gpg --dearmor -o /usr/share/keyrings/mongodb-archive-keyring.gpg 并添加其到apt，\n1 echo \u0026#34;deb [signed-by=/usr/share/keyrings/mongodb-archive-keyring.gpg] https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/6.0 multiverse\u0026#34; | sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list 更新包列表：\n1 sudo apt-get update 安装mongodb：\n1 sudo apt-get install mongodb-org 之后可以选择性安装yarn**（独立化部署的话则是必须）**\n1 2 3 curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add - echo \u0026#34;deb https://dl.yarnpkg.com/debian/ stable main\u0026#34; | sudo tee /etc/apt/sources.list.d/yarn.list sudo apt update \u0026amp;\u0026amp; sudo apt install yarn 构建GTP5G模块 注意构建GTP5G模块时，需要用普通用户构建，否则后续使用时会出错\n1 2 3 cd~ git clone https://github.com/free5gc/gtp5g.git cd gtp5g 编译\n1 2 make sudo make install 此时可能会遇到报错，如果是类似于warning: the compiler differs from the one used to build the kernel等，原因是找不到那几个编译器。\n需要安装：\n1 2 sudo apt update sudo apt install gcc-12 然后重新编译：\n1 2 3 make clean make sudo make install 容器化部署free5gc模拟核心网 首先，通过git clone下载项目代码（注意这里和教程文章的不太一样，教程里面那个链接好像用不了）：\n1 2 3 cd ~ git clone https://github.com/free5gc/free5gc-compose.git cd free5gc-compose 如果有vpn就不用按照文章里说的改代理\n编译代码：\n1 2 3 cd ~/free5gc-compose make base docker-compose build 其中docker-compose build一步可能报版本错误，原因在于上面安装docker、docker-compose时可能安装了较低版本的docker、docker-compose，此时可以选择重装docker、docker-compose或者修改docker-compose.yaml文件中第一行版本号3.8为当前版本，建议优先选择重装docker、docker-compose，以回避未知错误，可以通过命令docker \u0026ndash;version命令查询当前版本。（不过如果是按教程里的话一般没问题）\n交叉编译 交叉编译指利用不同的平台进行处理，并把安装或编译好的东西转移到所需平台。这种思想不仅仅用于以下案例，可以用到很多地方。\n如果不按照刚才说法设置镜像代理的话，编译过程中也有可能遇到golang bullseye报错，\n=\u0026gt; ERROR [internal] load metadata for docker.io/library/golang: 21.5s ------ \u0026gt; [internal] load metadata for docker.io/library/golang:1.21.8-bullseye\n如果实在不打算使用镜像源，可以利用交叉编译在主机windows挂梯子下载docker desktop软件，下载好后在上面搜索golang，选1.24.0-bullseye（我用的1.23.6-bullseye，这俩都行），点击pull，即可把包下载到电脑里。\n然后在主机打开命令行，输入\n1 docker images ，可以看到包已经下载到了主机里，然后输入命令：\n1 docker save -o E:\\go\\golang_1.24.0-bullseye.tar golang:1.24.0-bullseye 可以把包保存到电脑路径里\n从主机把压缩包拷贝到虚拟机：\n在虚拟机输入\n1 2 cd ~/free5gc-compose/base vim Dockerfile 进入配置文件，\n输入I，进入修改，把版本号改成所用版本(1.24.0之类的)，然后Esc，输入命令:wq（带冒号）即可保存退出。\n然后虚拟机终端输入：\n1 sudo docker load \u0026lt; /home/golang_1.24.0-bullseye 之后重复原本步骤编译就可以。\n至此，free5gc容器化部署完成\n二、安装UERANSIM 1 2 cd ~ git clone https://github.com/aligungr/UERANSIM 然后：\n1 2 3 4 5 6 7 sudo apt update sudo apt upgrade sudo apt install make sudo apt install g++ sudo apt install libsctp-dev sudo apt install lksctp-tools sudo apt install iproute2 编译代码：\n1 2 cd ~/UERANSIM make 编译完成就安装成功了。\n三、启动free5gc和ueransim环境 Free5gc，启动\n1 2 cd ~/free5gc-compose docker-compose up -d 之后\n1 ifconfig 这是查看网卡地址，启动free5gc后，会在本地虚拟化出一系列的网卡，这一步需要关注的是原先虚拟机自带的网卡，通常这类网卡的ip地址均处于192.168.*.*网段，网卡名类似ens33，eth0之类，可以以此特征区分出来\n接下来需要查看并记录amf网元的ip地址：\n1 docker inspect amf 找到上面记录有\u0026quot;IPAddress\u0026quot;: 的一行，后面记录的即是amf的ip地址\n记录下这两个ip地址后，就可以完成UERANSIM中gnb的配置了，通过修改free5gc-gnb.yaml配置文件完成这一步操作：\n1 2 cd ~/UERANSIM/config/ vim free5gc-gnb.yaml 输入I进行修改模式，需要修改其中的ngapIp、gtpIp为本机ip\n修改其中的amfconfig一项下的address为amf的ip，然后Esc，再输入 :wq\n表示保存并退出，类似还有 :q :qa :exit :^X之类的。\n每次重启机器后，amf地址可能改变，注意更改。\n至此，UERANSIM的基站配置完成，接下来需要在free5gc中注册UERANSIM的UE部分：\n访问地址 http://localhost:5000/可进入到free5gc的webui处，登录：\n用户名：admin 密码：free5gc\n之后通过free5gc的webui新增一个ue的注册信息（否则会报错说无法注册），此处配置的UE信息原则上需要和~/UERANSIM/config/free5gc-ue.yaml中的信息一致，但由于此处UERANSIM的代码作者已经设置好，所以实际上无需做任何更改，直接拉到最下面点create就ok\n之后启动UERANSIM模拟设备\n1 2 cd ~/UERANSIM/build#启动一个shell，执行启动gnb的流程 ./nr-gnb -c ../config/free5gc-gnb.yaml#通过nr-gnb程序，指定使用的gnb配置文件，启动模拟基站 另起一个shell，执行启动UE的流程\n1 2 cd ~/UERANSIM/build #通过nr-ue程序，指定使用的ue配置文件，启动模拟用户设备 sudo ./nr-ue -c ../config/free5gc-ue.yaml #此处因为需要虚拟出一张ue的网卡，所以需要root权限执行 启动的两个shell不可关闭，可以后台执行，但建议前台执行方便实时查看状态信息。启动完成后，执行ifconfig可以看到多了一张名为uesimtun0的网卡；另外，在free5gc的webui处，查看REALTIME STATUS可以看到有一个UE处于连接状态，此时即证明UERANSIM的环境启动成功：\n之后测试一下\n1 ping www.baidu.com -I uesimtun0 能通就ok，在free5gc官网也可以看到connect信息。\n核心网的基站层测试 一、以基站配置测试ueransim软件层 修改PLMN值，IP不变，进行测试、注册\n先改文件里PLMN的mcc、mnc分别为001、01，按照自己的目录（我的涉及/home/wxy/free5gc-compose/config/amfcfg.yaml、gnbcfg.yaml、smfcfg.yaml、uecfg.yaml，/home/wxy/UERANSIM/config/free5gc-gnb.yaml、free5gc-ue.yaml，包括修改ue里supi的前五位为00101：\n还有nrfcfg文件的mcc、mnc\n改完save，然后关闭docker\n1 docker-compose down 再重新跑核心网流程wireshark抓包查看闪退原因\n启动核心网环境\n1 2 cd ~/free5gc-compose sudo docker-compose up -d 启动UERANSIM的gnb\n1 2 cd ~/UERANSIM/build ./nr-gnb -c ../config/free5gc-gnb.yaml 启动ue\n1 2 cd ~/UERANSIM/build sudo ./nr-ue -c ../config/free5gc-ue.yaml 并重新create，修改mcc、mnc、id后注册\n然后根据一般ueransim测试流程启动，查询有无报错，并用uesimtun0来ping一下百度。\n虚拟网卡测试\n1 ping www.baidu.com -I uesimtun0 之后需要修改ip： 分别在docker-compose文件里面添加upf的ip、设置amf的ip，还有network的范围\n地址范围subnet要可以覆盖，改为192.168.0.0/16\n由于n3iwue、free5gc-n3iwf两部分此时用不到，可以把这两段代码分别注释掉。我们要修改amf为192.168.2.198，smf内的upf与N3口192.168.8.198。\n在amfcfg将ngapip改为基站的192.168.2.198\nsmfcfg的upf ip改为基站upf 192.168.8.198\n以及upfcfg的N3 ip为192.168.8.198\n改完保存，把docker给down掉关闭，然后重复一般测试流程，成功标志为\n1 ping baidu.com -I uesimtun0 可以收到包。\n问题1：遇到ue、gnb成功连接且核心网成功配置但是不通网 这个问题比较随机，因为每个人虚拟机、或者linux子系统的默认配置不同。诊断方法可以考虑进入upf的网络空间进行调整；或者docker logs amf那几个看一下日志；或根据路由、配合抓包进行诊断。具体命令在本文档第二部分。\n查询UERANSIM内的UE和GNB有没有建立PDU连接：\n如图可见二者连接正常，说明ue与gnb连接正常。之后可以分别查看一下amf、upf有没有正常启动、报错，用以下命令检查日志：\n1 docker logs amf 1 docker logs upf 如果没有报错，排查gnb通过N3口连接upf：\n1 ping 192.168.8.198 -I uesimtun0 还是通的话，可以进入upf的网络空间，看upf联网如何，\n利用pid方法进入网络空间进行ifconfig或者ping操作\n1 pgrep -f upf #获取pid： 1 sudo nsenter -t \u0026lt;pid\u0026gt; -n #进入网络空间 之后，在里面输入：\n1 ifconfig 查找网络工具，若有upfgtp或者eth0就可以，之后输入ping命令\n1 ping 8.8.8.8 如果有包收发，那就证明upf可以上网，所以整个网络连接没有问题。\n问题出在哪里？IP 转发 和 NAT 配置\n我们需要启用 IPv4 数据包转发功能（将接收到的 IP 数据包从一个网络接口转发到另一个网络接口），以及开启NAT模式（数据包离开当前网络时进行源地址转换），并允许转发的数据包通过防火墙。ICMP\n把docker-compose文件的upf部分的command修改添加以下代码\n1 2 3 4 5 6 7 8 command: - /bin/bash - -c - | sysctl -w net.ipv4.ip_forward=1 iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE iptables -I FORWARD 1 -j ACCEPT ./upf -c /free5gc/config/upfcfg.yaml 修改后save，然后把ueransim关掉，docker给down掉，重新跑一遍启动流程，之后测试\n1 ping www.baidu.com -I uesimtun0 跑通成功。\n二、连接实体基站进行测试 用SSH来连接基站，需要下载ssh工具\n1 2 sudo apt update sudo apt install openssh-client 启动基站流程：\n分别打开三个终端shell\n在第一个shell输入\n1 ssh root@192.168.2.246 输入密码，然后输入\n1 cd /root/yzmm/rel/GNB/phy/bin ./run.sh 挂在后台，别关闭。\n在第二个shell输入\n1 ssh root@192.168.2.246 输入密码，然后输入\n1 cd /root/yzmm/rel/GNB/cu/cu/nr_hl_cu/build ./run.sh 在第三个shell输入\n1 ssh root@192.168.2.246 再\n1 cd /root/yzmm/rel/GNB/du/ran/DU/build/intel/du_bin/bin ./run.sh 需要关掉ueransim，防止ip干扰冲突。\n然后添加端口映射38412，此处对amf修改无严格要求。\n添加upf网口2152:2152 /udp，经测试ue无法注册信号，产生mac相关报错，原因可能是free5gc默认和ueransim的对齐导致一些文件配置有问题。于是采用修改的核心网，工程文件来源于师兄distributed-core-network-control-plane。\n写在结尾 特别鸣谢：两位师兄和两位老师\n后期工作：\n梳理流程思路，抓包分析\n深入理解代码、规范、抓包工具；实体基站和软件ueransim的不同\n步进调试环境搭建、分布式核心网改进\n本文只涉及基础的Free5GC内容，由于传统核心网的集中性、易受攻击的问题，可以采取分布式架构进行优化，下篇文章阐述何为分布式核心网、市场空间、技术路线等。\n","date":"2025-05-23T12:45:04+08:00","permalink":"https://mosfish.github.io/p/5g%E6%A0%B8%E5%BF%83%E7%BD%91%E9%83%A8%E7%BD%B2%E5%8F%8A%E6%B5%8B%E8%AF%95%E6%89%8B%E5%86%8C/","title":"5G核心网部署及测试手册"},{"content":"水木清华的深冬与初春 喜欢摄影，随快门声记录下那些难忘的时刻，一点一点凑成碎片，从流年中捞起那不变的永恒。\n记得刚到这里的时候，也才将将春节之后。京城的街道充满了三种氛围：节日的热闹，假期的冷清，外来旅客潮的繁忙——巧了，我也是这众多旅人中的一员，听着火车站大哥亲切的京腔，似乎很久都没回家了，今年有幸在华北（家的地方），感受到了发自内心的愉悦与放松。\n喜欢家里的饺子，喜欢家里的炒饭炒面，喜欢门外吆喝的小商小贩，喜欢小区门口的庆丰包子铺，喜欢地铁口的煎饼果子、加俩蛋。\n人间烟火气，最抚凡人心\n或者说，最抚凡人心的，是熟悉的、家乡的烟火气。五道口这里，是恩师的母校，也是故友求学的地方，虽时运不济恰恰错峰难以见一面故友，不过我相信，来日方长，未来我应该还会来五道口访问交流，希望到那时我们都摆脱了升学的压力，在饺子铺一叙过往吧。\n热情好客的寒潮与零下十度的京城 回想起来，倒是第一次因为学业而来到京城，不想麻烦亲朋好友，便匆匆租了个房了事。好巧不巧，海淀的初春也遭遇了难得一遇的大寒潮，尽管我裹得严严实实（但是面部、双耳没裹上），也是被冻得丢了半条命，肚子痛得打滚，点了一份疙瘩汤当晚饭（还有美团送药），草草了事。\n在清华忙碌的日子 相较于康乐园，似乎清华园也差不多大，当然如果康乐园的家属区感觉占比大一点。冬日（或者初春）的清华简直就像人民公园，一眼看上去和我家门口的公园感觉差不多，寥寥几个学生、打卡的游客，以及我这种无业游民哈哈（旅客？学生？应该算visiting student吧）。在这里的时候，每天上午9点多来，忙到晚上9点多10点回去，我摸鱼的时候学了Latex、Markdown，真的挺有意思；除此之外其实主线任务是学习Linux开发、Arm开发、free5GC核心网架构，其实第一次开会我真的啥也没听懂，倒是快走人的时候才知道——哦，原来我是这么干的啊！\n在FIT楼，五道口的一些碎片 在FIT楼，还挺热，在平常应该穿毛衣的情况下，我在里面基本都是短袖，以至于每次楼下取外卖的时候，门口大爷会一脸错愕的盯着我：“小伙子，火力是旺！”此外，我在知乎还看到了一个问题：《为什么FIT楼这么热》，倒是个性化推送了。\n学校大，食堂离我在的FIT楼远，因此我吃了20多天外卖（海淀的饭真的有点贵的\u0026hellip;）。其实有的生活过的挺苦逼的，比如：\nCase1 早上没有报备入校咋办？ 很正常，系统甚至有延迟，五道口旁边有一个咖啡店，也有喜茶、霸王茶姬，“欢迎来chang”是我这段时间听到最多的话，因为好喝、便宜、人少、离学校和车站近，所以奶茶店学习挺常见的哈\u0026hellip;\n奶茶办公让我想起了“学术酒吧” Case2 苦逼生活？咋个苦法？ 其实只是相对的苦不是绝对的苦，只是不如母校的生活罢了。压力大，任务繁重，好几次连外卖都没顾得上吃，楼道里自动售货机的面包、泡面凑合凑合\u0026hellip;\u0026hellip;\n和呆了一个月的地方合个影吧 但是好景不长，之后就被发配到基站屋子里，和一堆服务器大铁疙瘩待一块去了，一看就是我们臭理工男的工作室，鉴于FIT楼建成已久，所以基建也没那么新。\n我的工位与发配楼上的工位 吃啥 探店+食堂，海淀的饭不便宜。这几天主要还是在照澜园吃饭了，毕竟离得近；有些窗口很便宜，但是教职工自选那里确实是有点贵了（也有可能是我挑贵的拿了）\n饮食记录 还去了方砖厂炸酱面，免费续面条真不错，就是面一般般，可能网红属性就这样。\n有点腻的方砖厂炸酱面，一碗30块钱 结束与告别 用UERANSIM和free5GC、分布式核心网搭建了通信系统，学到了很多，写了个文档，我想想，等之后有时间我写给文档（脱敏版）上传github，就叫《全网最详细版free5gc和ueransim核心网通信链路部署搭建手册》啦！（如果我不懒没有鸽的话）\n汇报 清华的老师：恭喜你完成了一个有意义的short stay，希望你学到了东西！\n时间过得好快，中午被实验室的师兄们拉去清华的某个餐厅点菜聚餐（倒是挺贵，不过师兄们未来应该不会差钱的），当天晚上最后和师兄在金谷园吃了顿饺子，本来打算请师兄吃饭的，没想到师兄提前把单买好了。\n没有回眸，转身离开 告别 收拾东西，感慨诸多，感谢这一段经历，感谢老师、师兄的帮助。其实很多时候人都会被他人灌输的“高价值”事物洗脑，以为某些东西看上去“高级”或者“先进”，实际上祛魅的最好方式是真正去体验一下，去感受一下，才能知道是否和他人描述的相符，这也有点像小马过河吧。\n没有调查就没有发言权。\n这次实地的“考察”让我感觉到，清华，我国工科教育当之无愧的殿堂，事实上里面的学生和大家也没什么不同，只是一批更聚焦、更能坚守的同龄人，在深耕的领域有自己的taste，在朋辈身旁有更大的peer pressure（这可能有优有劣）；清华的设施也没想象中那么新规或者那么老旧，一切都是刚刚好，甚至和母校都很像。\n每一次来到这里，都能唤起许多美好的回忆，又能够发现许多新鲜的东西，心情不同，时间不同，景色也不同。\n说了这么多，权当老夫痴言乱语罢了，前途似海，来日方长。\n","date":"2025-03-12T10:52:03+08:00","image":"https://mosfish.github.io/p/days-in-tsinghua./10_hu_1d5a0457f3f45ccc.webp","permalink":"https://mosfish.github.io/p/days-in-tsinghua./","title":"Days in Tsinghua."},{"content":"突然告知要代表学院出差 事情是这样的，突然接到通知让我和其他几位（我是某校级科创协会会长，其他一块的有类似学生会主席、研会主席、团副这种）去西安交流，于是我请了假、上了车，去了机场。一切是那么的突然，似乎没给我纠结的时间，但是我听到“出差补贴”四个字的时候直接蹦了起来，学生群体真好拿捏呀。\n出行前的轶事：刚好DSP课点名了，我给李教授说请假了，结果教授说：\n不相信，班里总有不少人假冒假条，一点到名就说请假。\n我倒是没翘过课被抓，老师讲的比较带感，唯独我对此不感兴趣，甚至不知道自己是不是真正喜欢现在的EE专业。不过这次“请假”确实是真的，毕竟我都上飞机了。于是，迎着落日余晖和熟悉的干燥的冷气，我到了西安，感受到熟悉却又陌生的气息。\n西安的东西和我家很像，街角的包子铺、肉夹馍，面条饺子之类的，却都是我喜欢吃的东西。酒店有健身房，倒也是不错。\n且向长安那畔行 西电交流 首日，由于我们是第一批，天大寒、砚冰坚，雨夹雪实在有些冷人了。起初进不去，找了迪卡侬取取暖。首日去了西电的研究生校区进行交流，后来发现我们的交流具有现实意义——学硕、专硕与工程博士的区分设立。这里的冬天夹杂了一份秋的踪影，地上金黄色的落叶飞舞着。这段时光或许是人生里很惬意的时光之一了，跟着老师和师兄们，在迪卡侬躲避寒风，品尝泡馍\u0026hellip;\u0026hellip;\n不许动！说了不许动！ 也是有资格上桌交流了 西交交流——创新港，偷摸鱼 好吧这次就没资格上桌了，于是校园走走，嗯，还挺好的其实。\n创新港与电信楼 瞎逛 其实这个地方来了很多次，所以也不知道逛啥，会了会老友（我们仨），然后和大部队一块去了趟省博物馆、大唐不夜城啥的，买了一堆纪念币，除此之外就\u0026hellip;就只是吃吃吃了。\n结语 好吃，太冷，太干，下次不来了。\n当初若选大学的时候来了西交，那可能会有些不一样；不过我不后悔来我的母校，因为我这次访问的时候，他们说西交压力太大了。\n","date":"2024-12-17T18:29:48+08:00","image":"https://mosfish.github.io/p/%E8%A5%BF%E5%AE%89%E4%B8%A4%E4%B8%89%E4%BA%8B/1_hu_efcab814805c5b8e.webp","permalink":"https://mosfish.github.io/p/%E8%A5%BF%E5%AE%89%E4%B8%A4%E4%B8%89%E4%BA%8B/","title":"西安两三事"},{"content":"记一次话剧主角的经历 之前一直喜欢看剧，话剧、舞台剧、音乐剧、交响音乐会都有涉及，不过个人更喜欢音乐剧一些，从法红与黑、法扎、莫里哀（明年订票去），到德扎、伊丽莎白、蝴蝶梦，几乎看了个遍，自学了一丢丢德语、在学校学了法语，不为别的，就为了看剧；相反，话剧的兴趣可能没那么大。\n最近的汇总，被门票爆金币了 偶然进入话剧社 进入这个地方的原因多种多样，有为了扩(ren)大(shi)社(mei)交(zi)的，有喜欢搞剧的，像我这种陪好兄弟去玩结果兄弟被刷了、我莫名其妙的被录进去的还是蛮少见的。\n主角竟是我？ 作为完全零经验小白，被迫出演《控方证人》的威尔爵士，链接https://www.bilibili.com/video/BV1Rb4y1371f\n一直想着结束后说点啥感想，恰逢一周年吧，又看了看自己演的话剧的录播，其实感触颇多。记得学姐说：\n“你可以出师啦”\n是吗？或许是吧，一个没有经验的小白，坐排天天挨骂、念台词被各种批斗；为了话剧放弃了许多，不过想了想也还不错，虽然错过了很多机会，想来现在很多比赛费半天劲也就当玩玩，不如去试试research，这段经历倒是给我启发。\n排练的碎片 多少日夜，多少排练，多少绕口令，回忆涌上心头，可惜曾经的朋友慢慢四散而去。\n学好声韵辨四声，阴阳上去要分明， 部位方法须找准，开齐合撮属口形。 双唇班抱必百波，抵舌当地斗点钉， 舌根高狗工耕故，舌面机结教坚精， 翘舌主争真志照，平舌资责早在增。 擦音发翻飞分复，送气查柴产彻称。 合口忽午枯胡鼓，开口河坡哥安争。 嘴撮虚学寻徐剧，齐齿衣优摇业英。 抵颚恩音烟弯稳，穿鼻昂迎中拥生。 咬紧字头归字尾，不难达到纯和清。\n仍记得定妆照那天赶完ddl就睡了三个小时；早上穿着戏服上课当显眼包，下午提前做完实验赶到现场，依稀记得女搭档们忙前忙后给我化妆的样子，仍然记得学姐顶着发烧来给我们拍照\u0026hellip;\u0026hellip;太多太多瞬间。\n这是哪位呢？我不认识 临门一脚 前几天晚上最后一次联排，相当于演习。整体很仓促，大家都容易着急，演话剧最容易出现的问题就是急或者快；期待最后一天能超常发挥。\n啊？ 早上8点半到活动中心搬东西，我一个“老头”还得一步一步从那里把门扛到新传剧场，倒也不能说激动，主要还是紧张\u0026hellip;\n忙到乱成一团了 在聚光灯下 演出很顺利，起初面对聚光灯手抖的不行，逐渐到泰然自若、享受掌声，这是这段时间的成长。剧组每个人都很辛苦，在这短短的一个月每个人都舍弃了不少，但是收获的更多。\n从此，面对台下熙熙攘攘的观众，你是否有挺胸谈吐的决心？反正我还是害怕，嘿嘿。\n场照、合影与谢幕 岁月不居，时节如流。\n所以，青春永不落幕，对吗？\n在聚光灯下 ","date":"2024-12-08T12:25:21+08:00","image":"https://mosfish.github.io/p/%E5%9C%A8%E8%81%9A%E5%85%89%E7%81%AF%E4%B8%8B/12_hu_3f2c33362a33220b.jpg","permalink":"https://mosfish.github.io/p/%E5%9C%A8%E8%81%9A%E5%85%89%E7%81%AF%E4%B8%8B/","title":"在聚光灯下"}]